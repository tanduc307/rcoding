[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thống kê sinh học: Từ lý thuyết đến ứng dụng",
    "section": "",
    "text": "Giới thiệu\nMục tiêu của trang web là cung cấp bài tập và lời giải cho các tình huống thống kê sinh học thường gặp với trích dẫn cụ thể đến các nguồn tài liệu gốc (đến từng trang trong sách hoặc từng phút trong video hướng dẫn) nhằm giúp các bạn sinh viên, học viên cao học có cơ sở để tiếp tục tìm hiểu về chủ đề này nhằm củng cố sự tự tin trong việc đưa ra quyết định khi thiết kế nghiên cứu và biện luận kết quả thống kê cũng như các kỹ thuật vẽ đồ thị bằng R.\nCác trao đổi cụ thể hơn bạn có thể liên hệ qua email tuhocr.com@gmail.com hoặc group facebook Cộng Đồng Tự Học R để làm sáng tỏ thêm các chủ đề mình trình bày nhé. Mirror: [1]  [2]  [3]\nTrân trọng,\nDuc Nguyen\nData scientist training R Specialization\nFounder of tuhocr.com",
    "crumbs": [
      "Giới thiệu"
    ]
  },
  {
    "objectID": "cac-lenh-do-thi-can-ban-su-dung-base-r-graphics.html",
    "href": "cac-lenh-do-thi-can-ban-su-dung-base-r-graphics.html",
    "title": "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
    "section": "",
    "text": "Để nắm vững các kỹ thuật vẽ đồ thị thường gặp trong R thân mời bạn tham gia chuyên đề TRỰC QUAN HÓA DỮ LIỆU TRONG R.",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics"
    ]
  },
  {
    "objectID": "huong-dan-ve-do-thi-cot-base-r-graphics.html",
    "href": "huong-dan-ve-do-thi-cot-base-r-graphics.html",
    "title": "1  Hướng dẫn vẽ đồ thị cột bằng Base R Graphics",
    "section": "",
    "text": "1.1 Dữ liệu minh họa: Doanh thu bán hàng\n# https://tuhocr.netlify.app/flashr/loop/doanh_thu_ban_hang.xlsx\nlibrary(readxl)\n\ndoanh_thu &lt;- readxl::read_excel(\"doanh_thu_ban_hang.xlsx\")\n\ndoanh_thu &lt;- as.data.frame(doanh_thu)\n\ndoanh_thu &lt;- doanh_thu[ , c(1, 2, 5, 8, 6, 3, 4, 7, 9)]\n\ndoanh_thu \n\n                Họ    Tên Giới tính Tuổi Ngày vào làm       Chức vụ Chi nhánh   Lương Doanh thu bán hàng\n1      Nguyễn Diệp   Hạnh        Nữ   42   2022-02-04     Nhân viên        HN 1.7e+07          2.682e+09\n2         Trần Nam   Tuấn       Nam   28   2020-12-03       Quản lý        HN 2.5e+07          1.994e+09\n3       Hoàng Ngọc   Liên       Nam   20   2022-06-16 Thực tập sinh       HCM 1.7e+07          2.178e+07\n4   Nguyễn Thị Kim    Mai        Nữ   53   2021-11-27     Nhân viên        HN 2.5e+07          9.510e+08\n5        Phạm Hồng   Thúy       Nam   52   2022-03-11      Học việc        HN 7.0e+06          2.570e+07\n6          Vũ Việt    Thư        Nữ   35   2022-05-13 Thực tập sinh       HCM 1.5e+07          1.833e+07\n7        Phạm Ngọc    Trí        Nữ   36   2022-05-14     Nhân viên       HCM 1.7e+07          2.826e+09\n8         Đào Minh   Hạnh        Nữ   28   2021-09-16     Nhân viên        HN 2.5e+07          1.903e+09\n9          Đỗ Minh   Hưng       Nam   19   2021-11-11      Học việc        HN 5.0e+06          1.443e+07\n10       Lê Phương   Liên        Nữ   26   2021-11-12 Thực tập sinh       HCM 1.7e+07          8.790e+05\n11      Nguyễn Anh   Liên        Nữ   52   2021-11-13     Nhân viên       HCM 1.5e+07          2.181e+09\n12    Nguyễn Hoàng   Ngọc       Nam   25   2021-11-14     Nhân viên        HN 1.7e+07          2.659e+09\n13       Trần Minh    Nam       Nam   29   2021-11-15     Nhân viên       HCM 1.5e+07          7.840e+08\n14       Phạm Hồng     Hà        Nữ   22   2022-02-04     Nhân viên        HN 1.7e+07          2.764e+09\n15         Vũ Việt     Hà       Nam   35   2020-12-03     Nhân viên       HCM 3.0e+07          3.950e+08\n16       Trần Ngọc   Thúy        Nữ   38   2022-06-16     Nhân viên        HN 1.5e+07          2.202e+09\n17      Trịnh Minh    Hảo        Nữ   43   2021-11-27       Quản lý        HN 5.0e+07          2.180e+08\n18         Lê Minh    Trí       Nam   34   2022-03-11     Nhân viên       HCM 1.5e+07          1.587e+09\n19       Đinh Quốc  Trung       Nam   46   2022-05-13     Nhân viên        HN 1.7e+07          2.869e+09\n20        Vũ Quang   Vinh       Nam   26   2022-05-14     Nhân viên        HN 7.0e+06          1.271e+09\n21        Trần Nam  Thịnh       Nam   32   2021-09-16       Quản lý        HN 1.5e+07          2.191e+09\n22           Hoàng  Thắng       Nam   24   2022-06-16 Thực tập sinh       HCM 1.7e+07          7.350e+07\n23  Nguyễn Thị Kim   Xuân        Nữ   48   2021-11-27     Nhân viên        HN 1.5e+07          2.980e+09\n24       Phạm Hồng   Thúy       Nam   42   2021-11-27      Học việc        HN 1.1e+07          1.398e+07\n25       Phạm Việt    Thư        Nữ   52   2022-03-11 Thực tập sinh       HCM 1.7e+07          1.989e+08\n26       Trần Ngọc  Phước        Nữ   54   2022-05-13     Nhân viên       HCM 1.5e+07          2.749e+09\n27 Nguyễn Thị Minh   Hạnh        Nữ   39   2022-05-14     Nhân viên        HN 1.5e+07          1.439e+09\n28         Đỗ Quốc   Mạnh       Nam   38   2021-09-16      Học việc        HN 1.0e+07          9.530e+05\n29       Lê Phương   Liên        Nữ   47   2021-11-11 Thực tập sinh       HCM 1.5e+07          2.998e+07\n30      Nguyễn Anh   Liên        Nữ   38   2021-11-12     Nhân viên       HCM 1.7e+07          1.034e+09\n31    Nguyễn Hoàng    Mai       Nam   52   2021-11-14     Nhân viên        HN 1.7e+07          1.238e+09\n32      Nguyễn Kim  Tuyền       Nam   27   2021-11-15     Nhân viên       HCM 1.5e+07          2.176e+09\n33       Phạm Hồng   Linh        Nữ   55   2021-11-16     Nhân viên        HN 7.0e+06          2.614e+09\n34        Trần Nam   Hưng       Nam   19   2020-12-03       Quản lý        HN 1.5e+07          2.587e+09\n35      Nguyễn Thị   Liên       Nam   36   2022-06-16 Thực tập sinh       HCM 1.7e+07          1.001e+07\n36      Nguyễn Kim  Thanh        Nữ   54   2021-11-27     Nhân viên        HN 1.5e+07          1.870e+09\n37       Phạm Hồng   Thúy       Nam   33   2022-03-11      Học việc        HN 8.0e+06          1.039e+07\n38         Vũ Việt  Thanh        Nữ   23   2022-05-13 Thực tập sinh       HCM 1.7e+07          1.906e+08\n39            Trần    Trí        Nữ   38   2022-05-14     Nhân viên       HCM 1.5e+07          1.088e+09\n40       Trần Đanh   Thủy        Nữ   54   2022-05-13     Nhân viên        HN 1.5e+07          2.933e+09\n41     Nguyễn Quốc   Hưng       Nam   50   2022-05-14      Học việc        HN 7.0e+06          2.802e+06\n42       Lê Phương   Liên        Nữ   45   2021-09-16 Thực tập sinh       HCM 1.7e+07          1.421e+08\n43      Nguyễn Anh   Liên        Nữ   50   2021-09-16     Nhân viên       HCM 1.5e+07          2.535e+09\n44          Nguyễn    Mai       Nam   41   2021-11-14     Nhân viên        HN 1.7e+07          8.090e+08\n45  Nguyễn Thị Kim  Quỳnh       Nam   48   2021-11-15     Nhân viên       HCM 2.5e+07          1.326e+09\n46       Phạm Hồng     Hà        Nữ   29   2021-11-16     Nhân viên        HN 2.0e+07          1.118e+09\n47         Vũ Việt     Hà       Nam   31   2021-11-17     Nhân viên       HCM 1.5e+07          1.152e+09\n48       Trần Ngọc   Thúy        Nữ   45   2021-09-16     Nhân viên        HN 7.0e+06          3.900e+08\n49      Trịnh Minh    Thư        Nữ   28   2021-11-11       Quản lý        HN 1.5e+07          1.328e+09\n50         Lê Trần Khương       Nam   41   2021-11-12     Nhân viên       HCM 1.7e+07          1.313e+09\n51       Trần Quốc  Trung       Nam   21   2021-11-14     Nhân viên        HN 1.5e+07          8.310e+08\n52        Vũ Quang   Vinh       Nam   44   2021-11-15     Nhân viên        HN 1.5e+07          2.570e+09\n53        Trần Nam   Hưng       Nam   52   2021-11-16       Quản lý        HN 1.7e+07          9.730e+08\n54       Trần Minh    Tâm       Nam   28   2020-12-03 Thực tập sinh       HCM 1.5e+07          1.838e+09\n55    Phạm Thị Kim    Trí        Nữ   43   2021-11-27     Nhân viên        HN 1.7e+07          1.732e+09\n56       Phạm Trần   Thúy       Nam   48   2022-03-11      Học việc        HN 9.0e+06          2.074e+07\n57         Vũ Việt   Thủy        Nữ   44   2022-05-13 Thực tập sinh       HCM 1.7e+07          1.495e+08\n58       Trần Ngọc    Trí        Nữ   47   2022-05-14     Nhân viên       HCM 2.5e+07          8.720e+08\n59        Đào Minh   Hạnh        Nữ   53   2021-09-16     Nhân viên        HN 1.7e+07          8.070e+08\n60        Đào Đình   Binh        Nữ   29   2021-09-16     Nhân viên        HN 2.5e+07          2.687e+09",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><b>Hướng dẫn vẽ đồ thị cột bằng Base R Graphics</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-ve-do-thi-cot-base-r-graphics.html#dữ-liệu-minh-họa-doanh-thu-bán-hàng",
    "href": "huong-dan-ve-do-thi-cot-base-r-graphics.html#dữ-liệu-minh-họa-doanh-thu-bán-hàng",
    "title": "1  Hướng dẫn vẽ đồ thị cột bằng Base R Graphics",
    "section": "",
    "text": "1.1.1 Vẽ đồ thị cột cho số lượng nam và nữ\n\n1.1.1.1 Vẽ từ object thuộc class table\nCú pháp cơ bản\n\n# table(doanh_thu$`Giới tính`, useNA = \"always\") -&gt; gender\n\ntable(doanh_thu$`Giới tính`, useNA = \"no\") -&gt; gender\ngender\n\n\nNam  Nữ \n 29  31 \n\nclass(gender)\n\n[1] \"table\"\n\n# vẽ barplot từ kết quả của class table\nbarplot(height = gender,\n        col = c(\"coral\", \"aquamarine\"),\n        horiz = FALSE\n        )\n\n\n\n\n\n\n\nbarplot(height = gender,\n        col = c(\"coral\", \"aquamarine\"),\n        horiz = TRUE\n        )\n\n\n\n\n\n\n\n\nCú pháp nâng cao\n\nbarplot(height = gender,\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Số lượng nam nữ trong công ty\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        width = c(0.1, 0.1),\n        xlim = c(0, 0),\n        space = c(-6, 9),\n        col = c(\"coral\", \"aquamarine\"),\n        ylim = c(0, 50),\n        horiz = FALSE,\n        border = c(\"purple\", \"blue\")\n        )\n\nbox()\n\n\n\n\n\n\n\n\n\n\n1.1.1.2 Vẽ từ object thuộc class numeric vector\n\ngender_numeric &lt;- c(\"Nam\" = 29, \"Nữ\" = 31)\ngender_numeric\n\nNam  Nữ \n 29  31 \n\nclass(gender_numeric)\n\n[1] \"numeric\"\n\nbarplot(height = gender_numeric,\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Số lượng nam nữ trong công ty\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        width = c(0.1, 0.1),\n        xlim = c(0, 0),\n        space = c(-6, 9),\n        col = c(\"coral\", \"aquamarine\"),\n        ylim = c(0, 50),\n        horiz = FALSE,\n        border = c(\"purple\", \"blue\")\n        )\nbox()\n\n\n\n\n\n\n\n\n\n\n1.1.1.3 Vẽ từ object thuộc class character vector\n\ngender_character &lt;- c(\"Nam\" = \"29\", \"Nữ\" = \"31\")\ngender_character\n\n Nam   Nữ \n\"29\" \"31\" \n\nclass(gender_character)\n\n[1] \"character\"\n\nbarplot(height = gender_character,\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Số lượng nam nữ trong công ty\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        width = c(0.1, 0.1),\n        xlim = c(0, 0),\n        space = c(-6, 9),\n        col = c(\"coral\", \"aquamarine\"),\n        ylim = c(0, 50),\n        horiz = FALSE,\n        border = c(\"purple\", \"blue\")\n        )\n\nError in -0.01 * height: non-numeric argument to binary operator\n\n# box()\n\nKhông vẽ được!\n\n\n1.1.1.4 Vẽ từ object thuộc class numeric matrix\nBình thường nếu là kết quả từ class table ta đưa vào lệnh barplot sẽ vẽ ra đồ thị cột nhanh chóng.\n\ntable(doanh_thu$`Chức vụ`, useNA = \"no\") -&gt; position\n\nbarplot(position)\n\n\n\n\n\n\n\n\nTuy nhiên nếu ta có dữ liệu ở dạng matrix thì cách vẽ như sau:\n\nm &lt;- matrix(data = c(7, 36, 6, 11),\n            nrow = 4, ncol = 1)\n\nrownames(m) &lt;- c(\"Học việc\", \"Nhân viên\", \"Quản lý\", \"Thực tập sinh\")\n\nm\n\n              [,1]\nHọc việc         7\nNhân viên       36\nQuản lý          6\nThực tập sinh   11\n\nbarplot(m)\n\n\n\n\n\n\n\nbarplot(m, \n        beside = TRUE,\n        # names.arg = rownames(m),\n        names = rownames(m))\n\n\n\n\n\n\n\n\nCú pháp chi tiết\n\nb &lt;- barplot(height = m, \n        beside = TRUE,\n        names.arg = rownames(m),\n        space = 2,\n        ylim = c(0, 50),\n        xlab = \"Chức vụ\",\n        ylab = \"Số đếm\",\n        main = \"Số lượng nhân viên theo vị trí việc làm\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        density = c(30, 30, 30, 30),\n        angle = c(0, 30, 60, 90, 120), \n        col = terrain.colors(5)\n        )\nbox()\n\ntext(b, m + 3, m, font = 1, col = \"black\")\n\n\n\n\n\n\n\n\nTrong trường hợp khi xoay ma trận m, ta có ma trận n như sau:\n\nn &lt;- t(m)\n\nn\n\n     Học việc Nhân viên Quản lý Thực tập sinh\n[1,]        7        36       6            11\n\nbarplot(n, beside = FALSE) # ma trận xoay ngang thì các cột được vẽ. Không bị stacked lại như ở m.\n\n\n\n\n\n\n\nbarplot(n, beside = TRUE,\n        col = c(\"cyan\", \"yellow\", \"coral\", \"lightblue\"),\n        width = c(1, 1, 1, 1),\n        space = c(0.5, 0.5, 0.5, 0.5))\n\n\n\n\n\n\n\n\n\n\n1.1.1.5 Vẽ từ object thuộc class character matrix\n\ncharacter_matrix &lt;- apply(X = m, MARGIN = 2, FUN = as.character)\n\nrow.names(character_matrix) &lt;- row.names(m)\n\ncharacter_matrix\n\n              [,1]\nHọc việc      \"7\" \nNhân viên     \"36\"\nQuản lý       \"6\" \nThực tập sinh \"11\"\n\nbarplot(character_matrix, \n        beside = TRUE,\n        names.arg = rownames(character_matrix)\n        )\n\nError in -0.01 * height: non-numeric argument to binary operator\n\n\nKhông vẽ được!",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><b>Hướng dẫn vẽ đồ thị cột bằng Base R Graphics</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-cach-thay-doi-do-rong-cot-trong-barplot.html",
    "href": "huong-dan-cach-thay-doi-do-rong-cot-trong-barplot.html",
    "title": "2  Hướng dẫn cách thay đổi độ rộng cột trong barplot",
    "section": "",
    "text": "2.1 Dữ liệu minh họa\nShow the code\nlibrary(readxl)\n\ndoanh_thu &lt;- readxl::read_excel(\"doanh_thu_ban_hang.xlsx\")\n\ndoanh_thu &lt;- as.data.frame(doanh_thu)\n\ndoanh_thu &lt;- doanh_thu[ , c(1, 2, 5, 8, 6, 3, 4, 7, 9)]\n\ntable(doanh_thu$`Giới tính`, useNA = \"no\") -&gt; gender",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'><b>Hướng dẫn cách thay đổi độ rộng cột trong barplot</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-cach-thay-doi-do-rong-cot-trong-barplot.html#vẽ-1-cột",
    "href": "huong-dan-cach-thay-doi-do-rong-cot-trong-barplot.html#vẽ-1-cột",
    "title": "2  Hướng dẫn cách thay đổi độ rộng cột trong barplot",
    "section": "2.2 Vẽ 1 cột",
    "text": "2.2 Vẽ 1 cột\n\n2.2.1 Mặc định\n\n\nShow the code\nbarplot(height = gender[1],\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\"\n)\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Setup zero\n\n\nShow the code\n# library(precisePlacement)\n\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        ylim = c(0, 100),\n        horiz = FALSE,\n        border = c(\"yellow3\")\n)\n\npar(\"usr\") # tọa độ trục x và y\n\n\n[1]   0.2   1.2   0.0 100.0\n\n\nShow the code\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\n# showMarginLines()\n# showOuterMarginLines()\n# highlightDataRegion()\n# highlightDeviceRegion()\n# highlightFigureRegion()\n# highlightPlotRegion()\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 Điều chỉnh độ rộng cột\nĐồ thị được vẽ y chang đồ thị ban đầu\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(0.2, 1.2), # setup chính xác vị trí xlim\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nThay đổi giá trị xlim sẽ làm thay đổi độ lớn của cột\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nThêm tham số space với giá trị là đẩy cột ra một khoảng về phía bên phải\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        space = c(0),\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nChỉnh thêm chút\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        space = c(-0.5),\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[1]/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[2]/2), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nChỉnh thêm chút nữa\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        # width = c(1), # mặc định là 1\n        width = c(0.5), \n        space = c(-0.5),\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[1]/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[2]/2), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nNếu muốn đẩy cột qua khoảng x ~ (0, 0.5) thì ta thay đổi thông số space\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        # width = c(1), # mặc định là 1\n        width = c(0.5), \n        space = c(0),\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[1]/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[2]/2), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nTiếp tục giảm độ rộng của cột và canh giữa đồ thị\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        # width = c(1), # mặc định là 1\n        width = c(0.25), \n        space = c(-0.5), # tương ứng là tọa độ ở -0.125\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\n\n# par(\"usr\") # tọa độ trục x và y\n\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[1]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[1]/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\nabline(v = par(\"usr\")[2]/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2]/2, \n     y = 0, \n     labels = as.character(par(\"usr\")[2]/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2]/4, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2]/4, \n     y = 0, \n     labels = as.character(par(\"usr\")[2]/4), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1]/4, \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1]/4, \n     y = 0, \n     labels = as.character(par(\"usr\")[1]/4), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nĐồ thị 1 cột gọn gàng\n\nbarplot(height = gender[1],\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 1 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        col = c(\"coral\"),\n        xlim = c(-1, 1), \n        # width = c(1), # mặc định là 1\n        width = c(0.25), \n        space = c(-0.5), # tương ứng là tọa độ ở -0.125\n        ylim = c(0, 100),\n        horiz = FALSE,\n        beside = TRUE,\n        border = c(\"yellow3\")\n)\nbox()",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'><b>Hướng dẫn cách thay đổi độ rộng cột trong barplot</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-cach-thay-doi-do-rong-cot-trong-barplot.html#vẽ-2-cột",
    "href": "huong-dan-cach-thay-doi-do-rong-cot-trong-barplot.html#vẽ-2-cột",
    "title": "2  Hướng dẫn cách thay đổi độ rộng cột trong barplot",
    "section": "2.3 Vẽ 2 cột",
    "text": "2.3 Vẽ 2 cột\nThông số mặc định\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\n\nbarplot(height = gender,\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 2 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        ylim = c(0, 100)\n)\n\npar(\"usr\")\n\n\n[1]   0.2   2.4   0.0 100.0\n\n\nShow the code\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nNếu không set xlim thì dù thay đổi width và space như thế nào thì độ rộng cột vẫn không đổi (theo tỷ lệ hình).\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\n\nbarplot(height = gender,\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 2 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        ylim = c(0, 100), # không set xlim\n        width = c(0.1, 0.1), \n        space = c(0.4, 0.4), \n        horiz = FALSE,\n        beside = TRUE,\n        col = c(\"coral\", \"yellow\"),\n        border = c(\"black\", \"black\")\n)\n\npar(\"usr\")\n\n\n[1]   0.04   0.28   0.00 100.00\n\n\nShow the code\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)\n\n\n\n\n\n\n\n\n\nKhi set xlim thì thay đổi được chiều rộng của cột.\n\n\nShow the code\npar(pty = \"s\")\npar(mar = c(6, 6, 6, 6))\npar(oma = c(2, 2, 2, 2))\npar(xpd = TRUE)\n\n\nbarplot(height = gender,\n        las = 1,\n        xlab = \"Giới tính\",\n        ylab = \"Số đếm\",\n        main = \"Đồ thị 2 cột\",\n        sub = \"Nguồn: Dữ liệu mô phỏng\",\n        xaxs = \"i\", \n        yaxs = \"i\",\n        ylim = c(0, 100), # không set xlim\n        width = c(0.1, 0.1), \n        space = c(0.4, 0.4), \n        horiz = FALSE,\n        beside = TRUE,\n        col = c(\"coral\", \"yellow\"),\n        border = c(\"black\", \"black\")\n)\n\npar(\"usr\")\n\n\n[1]   0.04   0.28   0.00 100.00\n\n\nShow the code\nbox(which = \"plot\", col = \"purple\")\nbox(which = \"outer\", col = \"darkgreen\")\nbox(which = \"figure\", col = \"cyan\")\n\nabline(h = 50,\n       v = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n       col = \"red\", \n       lty = 2)\n\ntext(x = (par(\"usr\")[1] + par(\"usr\")[2])/2, \n     y = 0, \n     labels = as.character((par(\"usr\")[1] + par(\"usr\")[2])/2), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[1], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[1], \n     y = 0, \n     labels = as.character(par(\"usr\")[1]), \n     pos = 1, \n     font = 2)\n\n##\n\nabline(v = par(\"usr\")[2], \n       col = \"red\", \n       lty = 2)\n\ntext(x = par(\"usr\")[2], \n     y = 0, \n     labels = as.character(par(\"usr\")[2]), \n     pos = 1, \n     font = 2)",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'><b>Hướng dẫn cách thay đổi độ rộng cột trong barplot</b></span>"
    ]
  },
  {
    "objectID": "tinh-huong-base-r-graphics-thuong-gap.html",
    "href": "tinh-huong-base-r-graphics-thuong-gap.html",
    "title": "3  Tình huống Base R Graphics thường gặp",
    "section": "",
    "text": "3.1 Import dataset\nShow the code\nlibrary(tuhocr)\ncrop_production &lt;- system.file(\"extdata\",\n                               \"crop_production_all_data.rds\",\n                               package = \"tuhocr\")\n\ndf_1 &lt;- readRDS(crop_production)\n\nFAOSTAT_data_2023 &lt;- system.file(\"extdata\",\n                                 \"FAOSTAT_data_3-21-2023.csv\", \n                                 package = \"tuhocr\")\n\ndf_2 &lt;- read.csv(FAOSTAT_data_2023)\n\ncoffee_all &lt;- tuhocr::extract_faostat(input_rds = df_1,\n                                     input_region = df_2,\n                                     input_item = \"Coffee, green\")\n\ncoffee_all |&gt; subset(area == \"Viet Nam\") -&gt; coffee_vn\n\ncoffee_vn |&gt; subset(year &gt;= 2010) -&gt; coffee_vn_2010_2021\n\ncoffee_vn_2010_2021$production &lt;- coffee_vn_2010_2021$production / 1000000\n\ncoffee_vn_2010_2021$area_harvested &lt;- coffee_vn_2010_2021$area_harvested / 1000000\n\ncoffee_vn_2010_2021\n\n\n        area          item year production area_harvested yield\n178 Viet Nam Coffee, green 2021   1.845033       0.653192  2.82\n179 Viet Nam Coffee, green 2020   1.763476       0.637563  2.77\n180 Viet Nam Coffee, green 2019   1.686765       0.624100  2.70\n181 Viet Nam Coffee, green 2018   1.616307       0.618879  2.61\n182 Viet Nam Coffee, green 2017   1.542398       0.605178  2.55\n183 Viet Nam Coffee, green 2016   1.460800       0.597597  2.44\n184 Viet Nam Coffee, green 2015   1.452999       0.593800  2.45\n185 Viet Nam Coffee, green 2014   1.406469       0.589041  2.39\n186 Viet Nam Coffee, green 2013   1.326688       0.581381  2.28\n187 Viet Nam Coffee, green 2012   1.260463       0.572600  2.20\n188 Viet Nam Coffee, green 2011   1.276506       0.543865  2.35\n189 Viet Nam Coffee, green 2010   1.105700       0.511900  2.16",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'><b>Tình huống Base R Graphics thường gặp</b></span>"
    ]
  },
  {
    "objectID": "tinh-huong-base-r-graphics-thuong-gap.html#vẽ-đồ-thị-đường-linechart",
    "href": "tinh-huong-base-r-graphics-thuong-gap.html#vẽ-đồ-thị-đường-linechart",
    "title": "3  Tình huống Base R Graphics thường gặp",
    "section": "3.2 Vẽ đồ thị đường (linechart)",
    "text": "3.2 Vẽ đồ thị đường (linechart)\nThông số mặc định\n\n\nShow the code\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2010, 2021),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     main = \"Tình hình sản xuất cà phê ở Việt Nam giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\"\n     )\n\ntext(x = 2011, \n     y = 0.5, \n     labels = \"Bước 1: Vẽ đồ thị 1 đường dùng\\nthông số mặc định\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     pos = 4)\n\n\n\n\n\n\n\n\n\nTăng số lượng tick label\nhttps://www.sthda.com/english/wiki/add-custom-tick-mark-labels-to-a-plot-in-r-software\n\n\nShow the code\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2010, 2021),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     main = \"Tình hình sản xuất cà phê ở Việt Nam giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2010, to = 2021, by = 1) # x tick label\naxis(side = 1, at = xtick, labels = TRUE) # vẽ trục x (side = 1)\n\ntext(x = 2011, \n     y = 0.5, \n     labels = \"Bước 2: Tăng số lượng tick label trên trục X\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     pos = 4)\n\n\n\n\n\n\n\n\n\nXoay tick label\n\n\nShow the code\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2010, 2021),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     main = \"Tình hình sản xuất cà phê ở Việt Nam giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2010, to = 2021, by = 1) # x tick label\n\naxis(side = 1, at = xtick, labels = FALSE) # ẩn giá trị x tick label mặc định\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 45, \n     # pos = 1, \n     # adj = c(0.5, 3),\n     adj = c(1.5, 2),\n     xpd = TRUE)\n\n\n\n\n\n\n\n\n\nVẽ 2 đường linechart\n\n\nShow the code\ncoffee_all |&gt; subset(area == \"Indonesia\") -&gt; coffee_indo\n\ncoffee_indo |&gt; subset(year &gt;= 2010) -&gt; coffee_indo_2010_2021\n\ncoffee_indo_2010_2021$production &lt;- coffee_indo_2010_2021$production / 1000000\n\ncoffee_indo_2010_2021$area_harvested &lt;- coffee_indo_2010_2021$area_harvested / 1000000\n\ncoffee_indo_2010_2021\n\n\n         area          item year production area_harvested yield\n239 Indonesia Coffee, green 2021   0.765415       1.249615  0.61\n240 Indonesia Coffee, green 2020   0.762380       1.250452  0.61\n241 Indonesia Coffee, green 2019   0.752512       1.245359  0.60\n242 Indonesia Coffee, green 2018   0.756051       1.252826  0.60\n243 Indonesia Coffee, green 2017   0.717962       1.238598  0.58\n244 Indonesia Coffee, green 2016   0.639305       1.228512  0.52\n245 Indonesia Coffee, green 2015   0.639412       1.230001  0.52\n246 Indonesia Coffee, green 2014   0.643900       1.230500  0.52\n247 Indonesia Coffee, green 2013   0.675800       1.241700  0.54\n248 Indonesia Coffee, green 2012   0.691163       1.233900  0.56\n249 Indonesia Coffee, green 2011   0.638600       1.293000  0.49\n250 Indonesia Coffee, green 2010   0.684076       1.268476  0.54\n\n\nShow the code\ncoffee_vn_2010_2021\n\n\n        area          item year production area_harvested yield\n178 Viet Nam Coffee, green 2021   1.845033       0.653192  2.82\n179 Viet Nam Coffee, green 2020   1.763476       0.637563  2.77\n180 Viet Nam Coffee, green 2019   1.686765       0.624100  2.70\n181 Viet Nam Coffee, green 2018   1.616307       0.618879  2.61\n182 Viet Nam Coffee, green 2017   1.542398       0.605178  2.55\n183 Viet Nam Coffee, green 2016   1.460800       0.597597  2.44\n184 Viet Nam Coffee, green 2015   1.452999       0.593800  2.45\n185 Viet Nam Coffee, green 2014   1.406469       0.589041  2.39\n186 Viet Nam Coffee, green 2013   1.326688       0.581381  2.28\n187 Viet Nam Coffee, green 2012   1.260463       0.572600  2.20\n188 Viet Nam Coffee, green 2011   1.276506       0.543865  2.35\n189 Viet Nam Coffee, green 2010   1.105700       0.511900  2.16\n\n\n\n\nShow the code\n## dataset coffee_vn_2010_2021\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2010, 2021),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2010, to = 2021, by = 1) # x tick label\naxis(side = 1, at = xtick, labels = TRUE) # vẽ trục x (side = 1)\n\n# legend\n\nlegend(x = \"topleft\", \n       y = NULL,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 1,\n       y.intersp = 1.5,\n       inset = 0.02, # chỉ có tác dụng khi x là keyword\n       box.lty = 1,\n       horiz = FALSE\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 3: Chèn thêm đường thứ 2 và legend\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     pos = 4)\n\n\n\n\n\n\n\n\n\nThay đổi vị trí legend\nCách 1: Lấy tọa độ từ legend có sẵn\n\n\nShow the code\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2010, 2021),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2010, to = 2021, by = 1) # x tick label\naxis(side = 1, at = xtick, labels = TRUE) # vẽ trục x (side = 1)\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3)\n\n# legend\n\n#############\n# lấy tọa độ\n\nleg &lt;- legend(x = \"top\",\n              y = NULL,\n              legend = c(\"Việt Nam\", \"Indonesia\"),\n              col = c(\"#0000b3\", \"red\"),\n              lty = c(1, 1),\n              cex = 1,\n              pch = c(19, 17),\n              lwd = 2,\n              # x.intersp = 2,\n              # y.intersp = 2,\n              # inset = 0.02,\n              box.lty = 1,\n              horiz = TRUE,\n              xpd = TRUE,\n              plot = FALSE\n)\n#############\n\nlegend(x = leg$rect$left, \n       y = 2.25,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 1,\n       y.intersp = 1,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE\n       )\n\nabline(v = (2021 + 2010) / 2, col = \"purple\", lty = 2, xpd = TRUE)\n\n\n\n\n\n\n\n\n\nCách 2: Dùng tham số xjust và yjust trong lệnh legend()\n\n\nShow the code\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = TRUE) # vẽ trục x (side = 1)\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3)\n\n# legend\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       merge = TRUE # gộp pch và line\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 4: Chỉnh lại legend và trục X\\ngiúp đồ thị rõ ràng hơn\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     pos = 4)\n\n\n\n\n\n\n\n\n\nShow the code\n# abline(v = (2022 + 2009) / 2, col = \"purple\", lty = 2, xpd = TRUE)\n\n\n\n\nShow the code\npar(mar = c(6, 5, 5, 2))\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = FALSE) # vẽ trục x (side = 1)\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 0, \n     # pos = 1,\n     adj = c(0.5, 3),\n     xpd = TRUE)\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3)\n\n# legend\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2.5,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       merge = TRUE # gộp pch và line\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 5: Đồ thị cơ bản hoàn thiện\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     pos = 4)\n\npar(new = TRUE) # workaround for grid.raster\n\n# plot(production ~ year,\n#      data = coffee_vn_2010_2021,\n#      type = \"n\",\n#      xlab = \"\",\n#      ylab = \"\",\n#      xaxt = \"n\",\n#      yaxt = \"n\")\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"outer\")\n\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.92, y = 0.08, width = 0.1)\n\n\n\n\n\n\n\n\n\nShow the code\n# https://www.jumpingrivers.com/blog/r-knitr-markdown-png-pdf-graphics/\n# https://yihui.org/knitr/options/#plots",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'><b>Tình huống Base R Graphics thường gặp</b></span>"
    ]
  },
  {
    "objectID": "tinh-huong-base-r-graphics-thuong-gap.html#customize-thêm-cho-linechart",
    "href": "tinh-huong-base-r-graphics-thuong-gap.html#customize-thêm-cho-linechart",
    "title": "3  Tình huống Base R Graphics thường gặp",
    "section": "3.3 Customize thêm cho linechart",
    "text": "3.3 Customize thêm cho linechart\n\n\nShow the code\npar(mar = c(6, 5, 5, 2))\n\npar(font.lab = 2)\n\nwindowsFonts(font_1 = windowsFont(\"Times New Roman\"))\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     family = \"font_1\",\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = FALSE) # vẽ trục x (side = 1)\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 0, \n     # pos = 1,\n     adj = c(0.5, 3),\n     xpd = TRUE,\n     family = \"font_1\")\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3,\n      family = \"font_1\")\n\n# legend\n\npar(family = \"font_1\")\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2.5,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       seg.len = 3,\n       merge = TRUE # gộp pch và line\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 6: Set font Times New Roman\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     pos = 4,\n     family = \"font_1\")\n\npar(new = TRUE) # workaround for grid.raster\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"outer\")\n\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.92, y = 0.08, width = 0.1)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(mar = c(6, 5, 5, 2))\n\npar(font.lab = 2)\n\nwindowsFonts(font_1 = windowsFont(\"Times New Roman\"))\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     type = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     xaxt = \"n\",\n     yaxt = \"n\")\n\ngrid(nx = 13, \n     ny = 4,\n     lty = 2, \n     col = \"gray\", \n     lwd = 1)\n\npar(new = TRUE) # make grid line behind the plot\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     family = \"font_1\",\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = FALSE) # vẽ trục x (side = 1)\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 0, \n     # pos = 1,\n     adj = c(0.5, 3),\n     xpd = TRUE,\n     family = \"font_1\")\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3,\n      family = \"font_1\")\n\n# legend\n\npar(family = \"font_1\")\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2.5,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       seg.len = 3,\n       merge = TRUE # gộp pch và line\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 7: Thêm đường grid line\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     # pos = 4,\n     adj = c(0, 0),\n     family = \"font_1\")\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"outer\")\n\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.92, y = 0.08, width = 0.1)\n\n\n\n\n\n\n\n\n\nShow the code\n# https://r-charts.com/base-r/grid/\n\n\n\n\nShow the code\npar(bg = \"#f7dba7\")\n\npar(mar = c(6, 5, 5, 2))\n\npar(font.lab = 2)\n\nwindowsFonts(font_1 = windowsFont(\"Times New Roman\"))\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     type = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     xaxt = \"n\",\n     yaxt = \"n\")\n\nrect(par(\"usr\")[1], par(\"usr\")[3],\n     par(\"usr\")[2], par(\"usr\")[4],\n     col = \"white\")\n\ngrid(nx = 13, \n     ny = 4,\n     lty = 2, \n     col = \"gray\", \n     lwd = 1)\n\npar(new = TRUE) # make grid line behind the plot\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     family = \"font_1\",\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = FALSE) # vẽ trục x (side = 1)\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 0, \n     # pos = 1,\n     adj = c(0.5, 3),\n     xpd = TRUE,\n     family = \"font_1\")\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3,\n      family = \"font_1\")\n\n# legend\n\npar(family = \"font_1\")\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2.5,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       seg.len = 3,\n       merge = TRUE # gộp pch và line\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 8: Set background color\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     # pos = 4,\n     adj = c(0, 0),\n     family = \"font_1\")\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"outer\")\n\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.92, y = 0.08, width = 0.1)\n\n\n\n\n\n\n\n\n\nShow the code\n# https://r-charts.com/base-r/grid/\n\n\n\n\nShow the code\npar(bg = \"gray90\")\n\npar(mar = c(6, 5, 5, 2))\n\npar(font.lab = 2)\n\nwindowsFonts(font_1 = windowsFont(\"Times New Roman\"))\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     type = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     xaxt = \"n\",\n     yaxt = \"n\")\n\nrect(par(\"usr\")[1], par(\"usr\")[3],\n     par(\"usr\")[2], par(\"usr\")[4],\n     col = \"white\")\n\ngrid(nx = 13, \n     ny = 4,\n     lty = 2, \n     col = \"gray\", \n     lwd = 1)\n\npar(new = TRUE) # make grid line behind the plot\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     family = \"font_1\",\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = FALSE) # vẽ trục x (side = 1)\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 0, \n     # pos = 1,\n     adj = c(0.5, 3),\n     xpd = TRUE,\n     family = \"font_1\")\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3,\n      family = \"font_1\")\n\n# legend\n\npar(family = \"font_1\")\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2.5,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       seg.len = 3,\n       merge = TRUE # gộp pch và line\n       )\n\ntext(x = 2011, \n     y = 1, \n     labels = \"Bước 9: Thể hiện giá trị trên đồ thị\", \n     cex = 1.5,\n     col = \"#ff007b\", \n     font = 2,\n     # pos = 4,\n     adj = c(0, 0),\n     family = \"font_1\")\n\n###\n\ntext(x = coffee_vn_2010_2021$year, \n     y = coffee_vn_2010_2021$production, \n     labels = round(coffee_vn_2010_2021$production, digits = 2), \n     cex = 1,\n     col = \"#0000b3\", \n     font = 2,\n     pos = 3,\n     # adj = c(0, 0),\n     family = \"font_1\")\n\ntext(x = coffee_indo_2010_2021$year, \n     y = coffee_indo_2010_2021$production, \n     labels = round(coffee_indo_2010_2021$production, digits = 2), \n     cex = 1,\n     col = \"red\", \n     font = 2,\n     pos = 3,\n     # adj = c(0, 0),\n     family = \"font_1\")\n\n###\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"outer\")\n\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.92, y = 0.08, width = 0.1)\n\n\n\n\n\n\n\n\n\nShow the code\n# https://www.statology.org/label-scatterplot-points-r/\n\n\n\n\nShow the code\npar(bg = \"#fefc97\")\n\npar(mar = c(6, 5, 5, 2))\n\npar(font.lab = 2)\n\nwindowsFonts(font_1 = windowsFont(\"Times New Roman\"))\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     type = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     xaxt = \"n\",\n     yaxt = \"n\")\n\nrect(par(\"usr\")[1], par(\"usr\")[3],\n     par(\"usr\")[2], par(\"usr\")[4],\n     col = \"white\")\n\ngrid(nx = 13, \n     ny = 4,\n     lty = 2, \n     col = \"gray\", \n     lwd = 1)\n\npar(new = TRUE) # make grid line behind the plot\n\nplot(production ~ year, \n     data = coffee_vn_2010_2021,\n     family = \"font_1\",\n     las = 1,\n     xaxs = \"i\",\n     yaxs = \"i\",\n     col = \"#0000b3\",\n     xlim = c(2009, 2022),\n     ylim = c(0, 2),\n     pch = 19,\n     type = \"b\",\n     xlab = \"Năm\",\n     ylab = \"Sản lượng (triệu tấn)\",\n     # main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n     sub = \"Nguồn: FAOSTAT\",\n     xaxt = \"n\" # remove thông tin trục x\n     # yaxt=\"n\"\n     )\n\n## dataset coffee_indo_2010_2021\npoints(production ~ year, \n     data = coffee_indo_2010_2021,\n     col = \"red\",\n     pch = 17,\n     type = \"b\"\n     )\n\n# Changing x axis\n\nxtick &lt;- seq(from = 2009, to = 2022, by = 1) # x tick label\nxtick[1] &lt;- \"\"\nxtick[14] &lt;- \"\"\n\naxis(side = 1, at = xtick, labels = FALSE) # vẽ trục x (side = 1)\n\ntext(x = xtick,  \n     y = par(\"usr\")[3], \n     labels = xtick, \n     srt = 0, \n     # pos = 1,\n     adj = c(0.5, 3),\n     xpd = TRUE,\n     family = \"font_1\")\n\n# Thay đổi vị trí title\n\ntitle(main = \"Tình hình sản xuất cà phê ở Việt Nam và Indonesia giai đoạn 2010–2021\",\n      line = 3,\n      family = \"font_1\")\n\n# legend\n\npar(family = \"font_1\")\n\nlegend(x = (2022 + 2009) / 2, \n       y = 2.05,  \n       legend = c(\"Việt Nam\", \"Indonesia\"),\n       col = c(\"#0000b3\", \"red\"),\n       lty = c(1, 1), \n       cex = 1,\n       pt.cex = 1.5, # cex của point\n       pch = c(19, 17),\n       lwd = 2,\n       x.intersp = 2.5,\n       # y.intersp = 1,\n       xjust = 0.5,\n       yjust = 0,\n       box.lty = 0,\n       horiz = TRUE,\n       xpd = TRUE,\n       adj = c(0.4, 0.5), # chỉnh text legend\n       seg.len = 3,\n       merge = TRUE # gộp pch và line\n       )\n\n# text(x = 2011, \n#      y = 1, \n#      labels = \"Final plot\", \n#      cex = 1.5,\n#      col = \"#ff007b\", \n#      font = 2,\n#      # pos = 4,\n#      adj = c(0, 0),\n#      family = \"font_1\")\n\n###\n\ntext(x = coffee_vn_2010_2021$year, \n     y = coffee_vn_2010_2021$production, \n     labels = round(coffee_vn_2010_2021$production, digits = 2), \n     cex = 1,\n     col = \"#0000b3\", \n     font = 2,\n     pos = 3,\n     # adj = c(0, 0),\n     family = \"font_1\")\n\ntext(x = coffee_indo_2010_2021$year, \n     y = coffee_indo_2010_2021$production, \n     labels = round(coffee_indo_2010_2021$production, digits = 2), \n     cex = 1,\n     col = \"red\", \n     font = 2,\n     pos = 3,\n     # adj = c(0, 0),\n     family = \"font_1\")\n\n###\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"outer\")\n\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.92, y = 0.08, width = 0.1)",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'><b>Tình huống Base R Graphics thường gặp</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-ve-do-thi-nhieu-truc-y.html",
    "href": "huong-dan-ve-do-thi-nhieu-truc-y.html",
    "title": "4  Hướng dẫn vẽ đồ thị nhiều trục Y",
    "section": "",
    "text": "4.1 Tham khảo\nhttps://evolvingspaces.blogspot.com/2011/05/multiple-y-axis-in-r-plot.html\n#Create Dataset\n\ntime&lt;-seq(7000,3400,-200)\npop&lt;-c(200,400,450,500,300,100,400,700,830,1200,400,350,200,700,370,800,200,100,120)\ngrp&lt;-c(2,5,8,3,2,2,4,7,9,4,4,2,2,7,5,12,5,4,4)\nmed&lt;-c(1.2,1.3,1.2,0.9,2.1,1.4,2.9,3.4,2.1,1.1,1.2,1.5,1.2,0.9,0.5,3.3,2.2,1.1,1.2)\n\n#Define Margins. The trick is to use give as much space possible on the left margin (second value)\npar(mar=c(5, 12, 4, 4) + 0.1)\n\n#Plot the first time series. Notice that you don't have to draw the axis nor the labels\n\nplot(time, pop, axes=F, ylim=c(0,max(pop)), xlab=\"\", ylab=\"\",type=\"l\",col=\"black\", main=\"\",xlim=c(7000,3400))\npoints(time,pop,pch=20,col=\"black\")\naxis(2, ylim=c(0,max(pop)),col=\"black\",lwd=2)\nmtext(2,text=\"Population\",line=2)\n\n#Plot the second time series. The command par(new=T) is handy here. \n#If you just need to plot two timeseries, you could also use the right vertical axis as well. \n#In that case you have to substitute \"2\" with \"4\" in the functions axis() and mtext(). \n#Notice that in both functions lines is increased so that the new axis and \n#its label is placed to the left of the first one. \n#You don't need to increase the value if you use the right vertical axis.\n\npar(new=T)\nplot(time, med, axes=F, ylim=c(0,max(med)), xlab=\"\", ylab=\"\", \ntype=\"l\",lty=2, main=\"\",xlim=c(7000,3400),lwd=2)\naxis(2, ylim=c(0,max(med)),lwd=2,line=3.5)\npoints(time, med,pch=20)\nmtext(2,text=\"Median Group Size\",line=5.5)\n\n#Plot the third time series. Again the line parameter are both further increased.\n\npar(new=T)\nplot(time, grp, axes=F, ylim=c(0,max(grp)), xlab=\"\", ylab=\"\", \ntype=\"l\",lty=3, main=\"\",xlim=c(7000,3400),lwd=2)\naxis(2, ylim=c(0,max(grp)),lwd=2,line=7)\n\npoints(time, grp,pch=20)\nmtext(2,text=\"Number of Groups\",line=9)\n\n#We can now draw the X-axis, which is of course shared by all the three time-series.\n\naxis(1,pretty(range(time),10))\nmtext(\"cal BP\",side=1,col=\"black\",line=2)\n\n#And then plot the legend.\n\nlegend(x=7000,y=12,legend=c(\"Population\",\"Median Group Size\",\"Number of Groups\"),lty=c(1,2,3))",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'><b>Hướng dẫn vẽ đồ thị nhiều trục Y</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-ve-do-thi-nhieu-truc-y.html#vẽ-đồ-thị-nhiều-trục-y",
    "href": "huong-dan-ve-do-thi-nhieu-truc-y.html#vẽ-đồ-thị-nhiều-trục-y",
    "title": "4  Hướng dẫn vẽ đồ thị nhiều trục Y",
    "section": "4.2 Vẽ đồ thị nhiều trục Y",
    "text": "4.2 Vẽ đồ thị nhiều trục Y\nSử dụng dataset airquality. Daily readings of the following air quality values for May 1, 1973 (a Tuesday) to September 30, 1973.\n\nOzone: Mean ozone in parts per billion from 1300 to 1500 hours at Roosevelt Island\nSolar.R: Solar radiation in Langleys in the frequency band 4000–7700 Angstroms from 0800 to 1200 hours at Central Park\nWind: Average wind speed in miles per hour at 0700 and 1000 hours at LaGuardia Airport\nTemp: Maximum daily temperature in degrees Fahrenheit at La Guardia Airport.\n\n\nA data frame with 153 observations on 6 variables.\n[,1] Ozone numeric Ozone (ppb)\n[,2] Solar.R numeric Solar R (lang)\n[,3] Wind numeric Wind (mph)\n[,4] Temp numeric Temperature (degrees F)\n[,5] Month numeric Month (1–12)\n[,6] Day numeric Day of month (1–31)\n\nSource: The data were obtained from the New York State Department of Conservation (ozone data) and the National Weather Service (meteorological data).\n\nairquality\n\n    Ozone Solar.R Wind Temp Month Day\n1      41     190  7.4   67     5   1\n2      36     118  8.0   72     5   2\n3      12     149 12.6   74     5   3\n4      18     313 11.5   62     5   4\n5      NA      NA 14.3   56     5   5\n6      28      NA 14.9   66     5   6\n7      23     299  8.6   65     5   7\n8      19      99 13.8   59     5   8\n9       8      19 20.1   61     5   9\n10     NA     194  8.6   69     5  10\n11      7      NA  6.9   74     5  11\n12     16     256  9.7   69     5  12\n13     11     290  9.2   66     5  13\n14     14     274 10.9   68     5  14\n15     18      65 13.2   58     5  15\n16     14     334 11.5   64     5  16\n17     34     307 12.0   66     5  17\n18      6      78 18.4   57     5  18\n19     30     322 11.5   68     5  19\n20     11      44  9.7   62     5  20\n21      1       8  9.7   59     5  21\n22     11     320 16.6   73     5  22\n23      4      25  9.7   61     5  23\n24     32      92 12.0   61     5  24\n25     NA      66 16.6   57     5  25\n26     NA     266 14.9   58     5  26\n27     NA      NA  8.0   57     5  27\n28     23      13 12.0   67     5  28\n29     45     252 14.9   81     5  29\n30    115     223  5.7   79     5  30\n31     37     279  7.4   76     5  31\n32     NA     286  8.6   78     6   1\n33     NA     287  9.7   74     6   2\n34     NA     242 16.1   67     6   3\n35     NA     186  9.2   84     6   4\n36     NA     220  8.6   85     6   5\n37     NA     264 14.3   79     6   6\n38     29     127  9.7   82     6   7\n39     NA     273  6.9   87     6   8\n40     71     291 13.8   90     6   9\n41     39     323 11.5   87     6  10\n42     NA     259 10.9   93     6  11\n43     NA     250  9.2   92     6  12\n44     23     148  8.0   82     6  13\n45     NA     332 13.8   80     6  14\n46     NA     322 11.5   79     6  15\n47     21     191 14.9   77     6  16\n48     37     284 20.7   72     6  17\n49     20      37  9.2   65     6  18\n50     12     120 11.5   73     6  19\n51     13     137 10.3   76     6  20\n52     NA     150  6.3   77     6  21\n53     NA      59  1.7   76     6  22\n54     NA      91  4.6   76     6  23\n55     NA     250  6.3   76     6  24\n56     NA     135  8.0   75     6  25\n57     NA     127  8.0   78     6  26\n58     NA      47 10.3   73     6  27\n59     NA      98 11.5   80     6  28\n60     NA      31 14.9   77     6  29\n61     NA     138  8.0   83     6  30\n62    135     269  4.1   84     7   1\n63     49     248  9.2   85     7   2\n64     32     236  9.2   81     7   3\n65     NA     101 10.9   84     7   4\n66     64     175  4.6   83     7   5\n67     40     314 10.9   83     7   6\n68     77     276  5.1   88     7   7\n69     97     267  6.3   92     7   8\n70     97     272  5.7   92     7   9\n71     85     175  7.4   89     7  10\n72     NA     139  8.6   82     7  11\n73     10     264 14.3   73     7  12\n74     27     175 14.9   81     7  13\n75     NA     291 14.9   91     7  14\n76      7      48 14.3   80     7  15\n77     48     260  6.9   81     7  16\n78     35     274 10.3   82     7  17\n79     61     285  6.3   84     7  18\n80     79     187  5.1   87     7  19\n81     63     220 11.5   85     7  20\n82     16       7  6.9   74     7  21\n83     NA     258  9.7   81     7  22\n84     NA     295 11.5   82     7  23\n85     80     294  8.6   86     7  24\n86    108     223  8.0   85     7  25\n87     20      81  8.6   82     7  26\n88     52      82 12.0   86     7  27\n89     82     213  7.4   88     7  28\n90     50     275  7.4   86     7  29\n91     64     253  7.4   83     7  30\n92     59     254  9.2   81     7  31\n93     39      83  6.9   81     8   1\n94      9      24 13.8   81     8   2\n95     16      77  7.4   82     8   3\n96     78      NA  6.9   86     8   4\n97     35      NA  7.4   85     8   5\n98     66      NA  4.6   87     8   6\n99    122     255  4.0   89     8   7\n100    89     229 10.3   90     8   8\n101   110     207  8.0   90     8   9\n102    NA     222  8.6   92     8  10\n103    NA     137 11.5   86     8  11\n104    44     192 11.5   86     8  12\n105    28     273 11.5   82     8  13\n106    65     157  9.7   80     8  14\n107    NA      64 11.5   79     8  15\n108    22      71 10.3   77     8  16\n109    59      51  6.3   79     8  17\n110    23     115  7.4   76     8  18\n111    31     244 10.9   78     8  19\n112    44     190 10.3   78     8  20\n113    21     259 15.5   77     8  21\n114     9      36 14.3   72     8  22\n115    NA     255 12.6   75     8  23\n116    45     212  9.7   79     8  24\n117   168     238  3.4   81     8  25\n118    73     215  8.0   86     8  26\n119    NA     153  5.7   88     8  27\n120    76     203  9.7   97     8  28\n121   118     225  2.3   94     8  29\n122    84     237  6.3   96     8  30\n123    85     188  6.3   94     8  31\n124    96     167  6.9   91     9   1\n125    78     197  5.1   92     9   2\n126    73     183  2.8   93     9   3\n127    91     189  4.6   93     9   4\n128    47      95  7.4   87     9   5\n129    32      92 15.5   84     9   6\n130    20     252 10.9   80     9   7\n131    23     220 10.3   78     9   8\n132    21     230 10.9   75     9   9\n133    24     259  9.7   73     9  10\n134    44     236 14.9   81     9  11\n135    21     259 15.5   76     9  12\n136    28     238  6.3   77     9  13\n137     9      24 10.9   71     9  14\n138    13     112 11.5   71     9  15\n139    46     237  6.9   78     9  16\n140    18     224 13.8   67     9  17\n141    13      27 10.3   76     9  18\n142    24     238 10.3   68     9  19\n143    16     201  8.0   82     9  20\n144    13     238 12.6   64     9  21\n145    23      14  9.2   71     9  22\n146    36     139 10.3   81     9  23\n147     7      49 10.3   69     9  24\n148    14      20 16.6   63     9  25\n149    30     193  6.9   70     9  26\n150    NA     145 13.2   77     9  27\n151    14     191 14.3   75     9  28\n152    18     131  8.0   76     9  29\n153    20     223 11.5   68     9  30\n\n\n\nairquality -&gt; df\n\ndf$year &lt;- 1973\n\ndf$date &lt;- paste0(df$year, \"-\", df$Month, \"-\", df$Day)\n\ndf$date &lt;- as.Date(df$date)\n\ndf$time &lt;- row.names(df)\n\ndf$time &lt;- as.numeric(df$time)\n\n# options(max.print = 100000)\n\n# windows(width = 18, height = 6) # vẽ chuẩn trên này\n\n# save chuẩn, nếu không khớp cần chỉnh trực tiếp lại\npng(width = 18,\n    height = 6,\n    units = \"in\",\n    res = 300,\n    filename = \"do_thi_nhieu_truc_tung.png\")\n\n# oldpar &lt;- par(no.readonly = TRUE)\n\npar(oma = c(0, 0, 0, 0))\n\npar(mar = c(10, 20, 4, 4))\n\npar(xpd = TRUE)\n\n# par(bg = \"aliceblue\")\n\nplot(formula = Ozone ~ time, \n     data = na.omit(df[, c(\"Ozone\", \"time\")]), # nối liền NA\n     axes = FALSE, \n     ylim = c(0, max(df$Ozone, na.rm = TRUE)*3),\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xaxt = \"n\",\n     yaxt = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     lty = 2,\n     lwd = 2,\n     type = \"l\",\n     col = \"blue\", \n     main = \"\",\n     xlim = c(1, max(df$time))\n)\n\n# Change the plot region color\nrect(par(\"usr\")[1], par(\"usr\")[3],\n     par(\"usr\")[2], par(\"usr\")[4],\n     col = \"lightyellow\") # Color\n\n###\n\npar(new = TRUE)\n\nplot(formula = Ozone ~ time, \n     data = na.omit(df[, c(\"Ozone\", \"time\")]), # nối liền NA\n     axes = FALSE, \n     ylim = c(0, max(df$Ozone, na.rm = TRUE)*3),\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xaxt = \"n\",\n     yaxt = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     lty = 2,\n     lwd = 2,\n     type = \"l\",\n     col = \"blue\", \n     main = \"\",\n     xlim = c(1, max(df$time))\n     )\n\nbox(which = \"plot\")\nbox(which = \"figure\")\nbox(which = \"inner\")\nbox(which = \"outer\")\n\n# points(formula = Ozone ~ time, \n#        data = na.omit(df[, c(\"Ozone\", \"time\")]), \n#        pch = 20, \n#        col = \"black\")\n\n## trục Y1\n\naxis(side = 2, \n     # ylim = c(0, max(df$Ozone, na.rm = TRUE)*3),\n     at = c(0, 50, 100, 150, 200),\n     labels = c(0, 50, 100, 150, 200),\n     col = \"blue\",\n     col.axis = \"blue\",\n     font = 2,\n     lwd = 2,\n     las = 2)\n\nmtext(side = 2,\n      text = \"Ozone (ppb)\",\n      line = 3,\n      font = 2,\n      col = \"blue\",\n      adj = 0)\n\n## trục X1\n\n# axis(side = 1,\n#      at = pretty(range(df$time), 10) # tự chia khoảng cho hợp lý\n#      )\n\n## scale X1\n\ntime_1 &lt;- c(1, 10, 20, 30, 40, 50,\n            60, 70, 80, 90, 100, 110,\n            120, 130, 140, 153)\n\naxis(side = 1,\n     at = time_1,\n     labels = time_1,\n     font = 2,\n     lwd = 2\n)\n\nmtext(side = 1,\n      text = \"Tính theo ngày\",\n      line = 3,\n      font = 2)\n\n###\n\npar(new = TRUE)\n\nplot(formula = Ozone ~ date, \n     data = na.omit(df[, c(\"Ozone\", \"date\")]), # nối liền NA\n     axes = FALSE,\n     ylim = c(0, max(df$Ozone, na.rm = TRUE)),\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xaxt = \"n\",\n     yaxt = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     type = \"n\",\n     col = \"black\", \n     main = \"\"\n)\n\n## scale X2 (vì là datetime nên phải plot riêng cái mới,\n# do R vẽ datetime theo numeric tính từ 1970-01-01)\n\naxis(side = 1,\n     at = c(seq.Date(from = df$date[1], to = df$date[153], by = \"months\"), df$date[153]),\n     line = 5,\n     labels = c(seq.Date(from = df$date[1], to = df$date[153], by = \"months\"), df$date[153]),\n     font = 2,\n     lwd = 2,\n     col = \"darkgreen\",\n     col.axis = \"darkgreen\",\n)\n\nmtext(side = 1,\n      text = \"Thời gian thực đo (YYYY-MM-DD)\",\n      line = 8,\n      col = \"darkgreen\",\n      font = 2)\n\n### VẼ TRỤC Y2\n\npar(new = TRUE)\n\nplot(formula = Solar.R ~ time, \n     data = na.omit(df[, c(\"Solar.R\", \"time\")]), # nối liền NA\n     axes = FALSE, \n     ylim = c(0, max(df$Solar.R, na.rm = TRUE)*2),\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xaxt = \"n\",\n     yaxt = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     type = \"l\",\n     col = \"red\", \n     main = \"\",\n     xlim = c(1, max(df$time))\n)\n\n## trục Y2\n\naxis(side = 2, \n     # ylim = c(0, max(df$Solar.R, na.rm = TRUE)*2),\n     at = c(0, 100, 200, 300, 400),\n     labels = c(0, 100, 200, 300, 400),\n     col = \"red\",\n     col.axis = \"red\",\n     font = 2,\n     lwd = 2,\n     las = 2,\n     line = 5)\n\nmtext(side = 2,\n      text = \"Solar radiation (lang)\",\n      line = 8,\n      font = 2,\n      col = \"red\",\n      adj = 0)\n\n\n### VẼ TRỤC Y3\n\npar(new = TRUE)\n\nplot(formula = Wind ~ time, \n     data = na.omit(df[, c(\"Wind\", \"time\")]), # nối liền NA\n     axes = FALSE, \n     ylim = c(0, max(df$Wind, na.rm = TRUE)*1.1),\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xaxt = \"n\",\n     yaxt = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     type = \"l\",\n     col = \"black\", \n     lwd = 1,\n     lty = 1,\n     main = \"\",\n     xlim = c(1, max(df$time))\n)\n\n## trục Y3\n\naxis(side = 2, \n     ylim = c(0, max(df$Wind, na.rm = TRUE)*1.1),\n     col = \"black\",\n     col.axis = \"black\",\n     font = 2,\n     lwd = 2,\n     las = 2,\n     line = 10)\n\nmtext(side = 2,\n      text = \"Wind (mph)\",\n      line = 12,\n      font = 2,\n      adj = 0,\n      col = \"black\")\n\n### VẼ TRỤC Y4\n\npar(new = TRUE)\n\nplot(formula = Temp ~ time, \n     data = na.omit(df[, c(\"Temp\", \"time\")]), # nối liền NA\n     axes = FALSE, \n     ylim = c(0, max(df$Temp, na.rm = TRUE)*1.2),\n     xaxs = \"i\",\n     yaxs = \"i\",\n     xaxt = \"n\",\n     yaxt = \"n\",\n     xlab = \"\",\n     ylab = \"\",\n     type = \"l\",\n     lwd = 2,\n     lty = 1,\n     col = \"cyan2\", \n     main = \"\",\n     xlim = c(1, max(df$time))\n)\n\n## trục Y4\n\naxis(side = 2, \n     ylim = c(0, max(df$Temp, na.rm = TRUE)*1.2),\n     col = \"cyan2\",\n     col.axis = \"cyan2\",\n     font = 2,\n     lwd = 2,\n     las = 2,\n     line = 14)\n\nmtext(side = 2,\n      text = \"Temperature (\\u00B0F)\",\n      line = 17,\n      font = 2,\n      adj = 0,\n      col = \"cyan2\")\n\ntitle(main = \"Diễn tiến chất lượng không khí theo thời gian | Nguồn: dataset airquality in R\")\n\n###\nlibrary(png)\nlibrary(grid)\nlogor &lt;- readPNG(\"logor.png\")\ngrid.raster(logor, x = 0.05, y = 0.9, width = 0.05)\n\n###\nlibrary(unikn)\nlibrary(showtext)\n\npar(lheight = 1.15)\n\n###\n# https://cran.r-project.org/web/packages/unikn/vignettes/text.html\n\nmark_v1 &lt;- function (labels, x = 0, y = 0.55, x_layout = NA, y_layout = \"even\", \n                     col = \"black\", col_bg = Seeblau, cex = 2, font = 2, new_plot = \"none\", ...) \n{\n  if (new_plot == FALSE || tolower(new_plot) == \"false\" || \n      substr(tolower(new_plot), 1, 2) == \"no\") {\n    new_plot &lt;- \"none\"\n  }\n  unikn:::plot_text(labels = labels, x = x, y = y, x_layout = x_layout, \n                    y_layout = y_layout, col = col, col_bg = col_bg, cex = cex, \n                    font = font, new_plot = new_plot, col_bg_border = NA, \n                    pos = 4, mark = TRUE, ...)\n}\n###\n\nrect(-43, -68,\n     -7, -24,\n     col = \"gold\") # Color\n\nmark_v1(labels = c(\"Thực hiện: Duc Nguyen\", \n                   \"Website: www.tuhocr.com\", \n                   \"Chuyên đào tạo R căn bản\", \n                   \"Welcome to Tự Học R ;)\"), \n     x = -40, \n     y = -30,\n     family = \"mono\",\n     y_layout = \"flush\",\n     col_bg = \"transparent\",\n     col = \"#0000b3\",\n     cex = 1.2)\n\n# par(oldpar)\n\ndev.off()\n\n\nknitr::include_graphics(\"do_thi_nhieu_truc_tung.png\") \n\n\n\n\n\n\n\n\nFull-size: https://thongkesinhhoc.com/do_thi_nhieu_truc_tung.png",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'><b>Hướng dẫn vẽ đồ thị nhiều trục Y</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-ve-do-thi-bang-package-lattice.html",
    "href": "huong-dan-ve-do-thi-bang-package-lattice.html",
    "title": "5  Hướng dẫn vẽ đồ thị bằng package lattice",
    "section": "",
    "text": "File example https://applyr.netlify.app/qbook1/doanh_thu_ban_hang.xlsx\n\nlibrary(readxl)\ndf &lt;- read_excel(\"doanh_thu_ban_hang.xlsx\")\ndf &lt;- as.data.frame(df)\n\ndf\n\n                Họ    Tên       Chức vụ Chi nhánh Giới tính Ngày vào làm   Lương Tuổi Doanh thu bán hàng\n1      Nguyễn Diệp   Hạnh     Nhân viên        HN        Nữ   2022-02-04 1.7e+07   42          2.682e+09\n2         Trần Nam   Tuấn       Quản lý        HN       Nam   2020-12-03 2.5e+07   28          1.994e+09\n3       Hoàng Ngọc   Liên Thực tập sinh       HCM       Nam   2022-06-16 1.7e+07   20          2.178e+07\n4   Nguyễn Thị Kim    Mai     Nhân viên        HN        Nữ   2021-11-27 2.5e+07   53          9.510e+08\n5        Phạm Hồng   Thúy      Học việc        HN       Nam   2022-03-11 7.0e+06   52          2.570e+07\n6          Vũ Việt    Thư Thực tập sinh       HCM        Nữ   2022-05-13 1.5e+07   35          1.833e+07\n7        Phạm Ngọc    Trí     Nhân viên       HCM        Nữ   2022-05-14 1.7e+07   36          2.826e+09\n8         Đào Minh   Hạnh     Nhân viên        HN        Nữ   2021-09-16 2.5e+07   28          1.903e+09\n9          Đỗ Minh   Hưng      Học việc        HN       Nam   2021-11-11 5.0e+06   19          1.443e+07\n10       Lê Phương   Liên Thực tập sinh       HCM        Nữ   2021-11-12 1.7e+07   26          8.790e+05\n11      Nguyễn Anh   Liên     Nhân viên       HCM        Nữ   2021-11-13 1.5e+07   52          2.181e+09\n12    Nguyễn Hoàng   Ngọc     Nhân viên        HN       Nam   2021-11-14 1.7e+07   25          2.659e+09\n13       Trần Minh    Nam     Nhân viên       HCM       Nam   2021-11-15 1.5e+07   29          7.840e+08\n14       Phạm Hồng     Hà     Nhân viên        HN        Nữ   2022-02-04 1.7e+07   22          2.764e+09\n15         Vũ Việt     Hà     Nhân viên       HCM       Nam   2020-12-03 3.0e+07   35          3.950e+08\n16       Trần Ngọc   Thúy     Nhân viên        HN        Nữ   2022-06-16 1.5e+07   38          2.202e+09\n17      Trịnh Minh    Hảo       Quản lý        HN        Nữ   2021-11-27 5.0e+07   43          2.180e+08\n18         Lê Minh    Trí     Nhân viên       HCM       Nam   2022-03-11 1.5e+07   34          1.587e+09\n19       Đinh Quốc  Trung     Nhân viên        HN       Nam   2022-05-13 1.7e+07   46          2.869e+09\n20        Vũ Quang   Vinh     Nhân viên        HN       Nam   2022-05-14 7.0e+06   26          1.271e+09\n21        Trần Nam  Thịnh       Quản lý        HN       Nam   2021-09-16 1.5e+07   32          2.191e+09\n22           Hoàng  Thắng Thực tập sinh       HCM       Nam   2022-06-16 1.7e+07   24          7.350e+07\n23  Nguyễn Thị Kim   Xuân     Nhân viên        HN        Nữ   2021-11-27 1.5e+07   48          2.980e+09\n24       Phạm Hồng   Thúy      Học việc        HN       Nam   2021-11-27 1.1e+07   42          1.398e+07\n25       Phạm Việt    Thư Thực tập sinh       HCM        Nữ   2022-03-11 1.7e+07   52          1.989e+08\n26       Trần Ngọc  Phước     Nhân viên       HCM        Nữ   2022-05-13 1.5e+07   54          2.749e+09\n27 Nguyễn Thị Minh   Hạnh     Nhân viên        HN        Nữ   2022-05-14 1.5e+07   39          1.439e+09\n28         Đỗ Quốc   Mạnh      Học việc        HN       Nam   2021-09-16 1.0e+07   38          9.530e+05\n29       Lê Phương   Liên Thực tập sinh       HCM        Nữ   2021-11-11 1.5e+07   47          2.998e+07\n30      Nguyễn Anh   Liên     Nhân viên       HCM        Nữ   2021-11-12 1.7e+07   38          1.034e+09\n31    Nguyễn Hoàng    Mai     Nhân viên        HN       Nam   2021-11-14 1.7e+07   52          1.238e+09\n32      Nguyễn Kim  Tuyền     Nhân viên       HCM       Nam   2021-11-15 1.5e+07   27          2.176e+09\n33       Phạm Hồng   Linh     Nhân viên        HN        Nữ   2021-11-16 7.0e+06   55          2.614e+09\n34        Trần Nam   Hưng       Quản lý        HN       Nam   2020-12-03 1.5e+07   19          2.587e+09\n35      Nguyễn Thị   Liên Thực tập sinh       HCM       Nam   2022-06-16 1.7e+07   36          1.001e+07\n36      Nguyễn Kim  Thanh     Nhân viên        HN        Nữ   2021-11-27 1.5e+07   54          1.870e+09\n37       Phạm Hồng   Thúy      Học việc        HN       Nam   2022-03-11 8.0e+06   33          1.039e+07\n38         Vũ Việt  Thanh Thực tập sinh       HCM        Nữ   2022-05-13 1.7e+07   23          1.906e+08\n39            Trần    Trí     Nhân viên       HCM        Nữ   2022-05-14 1.5e+07   38          1.088e+09\n40       Trần Đanh   Thủy     Nhân viên        HN        Nữ   2022-05-13 1.5e+07   54          2.933e+09\n41     Nguyễn Quốc   Hưng      Học việc        HN       Nam   2022-05-14 7.0e+06   50          2.802e+06\n42       Lê Phương   Liên Thực tập sinh       HCM        Nữ   2021-09-16 1.7e+07   45          1.421e+08\n43      Nguyễn Anh   Liên     Nhân viên       HCM        Nữ   2021-09-16 1.5e+07   50          2.535e+09\n44          Nguyễn    Mai     Nhân viên        HN       Nam   2021-11-14 1.7e+07   41          8.090e+08\n45  Nguyễn Thị Kim  Quỳnh     Nhân viên       HCM       Nam   2021-11-15 2.5e+07   48          1.326e+09\n46       Phạm Hồng     Hà     Nhân viên        HN        Nữ   2021-11-16 2.0e+07   29          1.118e+09\n47         Vũ Việt     Hà     Nhân viên       HCM       Nam   2021-11-17 1.5e+07   31          1.152e+09\n48       Trần Ngọc   Thúy     Nhân viên        HN        Nữ   2021-09-16 7.0e+06   45          3.900e+08\n49      Trịnh Minh    Thư       Quản lý        HN        Nữ   2021-11-11 1.5e+07   28          1.328e+09\n50         Lê Trần Khương     Nhân viên       HCM       Nam   2021-11-12 1.7e+07   41          1.313e+09\n51       Trần Quốc  Trung     Nhân viên        HN       Nam   2021-11-14 1.5e+07   21          8.310e+08\n52        Vũ Quang   Vinh     Nhân viên        HN       Nam   2021-11-15 1.5e+07   44          2.570e+09\n53        Trần Nam   Hưng       Quản lý        HN       Nam   2021-11-16 1.7e+07   52          9.730e+08\n54       Trần Minh    Tâm Thực tập sinh       HCM       Nam   2020-12-03 1.5e+07   28          1.838e+09\n55    Phạm Thị Kim    Trí     Nhân viên        HN        Nữ   2021-11-27 1.7e+07   43          1.732e+09\n56       Phạm Trần   Thúy      Học việc        HN       Nam   2022-03-11 9.0e+06   48          2.074e+07\n57         Vũ Việt   Thủy Thực tập sinh       HCM        Nữ   2022-05-13 1.7e+07   44          1.495e+08\n58       Trần Ngọc    Trí     Nhân viên       HCM        Nữ   2022-05-14 2.5e+07   47          8.720e+08\n59        Đào Minh   Hạnh     Nhân viên        HN        Nữ   2021-09-16 1.7e+07   53          8.070e+08\n60        Đào Đình   Binh     Nhân viên        HN        Nữ   2021-09-16 2.5e+07   29          2.687e+09\n\n\nSố liệu nhân viên theo giới tính và chức vụ ở các chi nhánh\n\nlibrary(lattice)\n\ntable(df$`Giới tính`,\n      df$`Chức vụ`,\n      df$`Chi nhánh`) -&gt; ok_1\n\nok_2 &lt;- as.data.frame(ok_1)\n\nnames(ok_2) &lt;- c(\"gioi_tinh\", \"chuc_vu\", \"chi_nhanh\", \"count\")\n\nok_2\n\n   gioi_tinh       chuc_vu chi_nhanh count\n1        Nam      Học việc       HCM     0\n2         Nữ      Học việc       HCM     0\n3        Nam     Nhân viên       HCM     7\n4         Nữ     Nhân viên       HCM     7\n5        Nam       Quản lý       HCM     0\n6         Nữ       Quản lý       HCM     0\n7        Nam Thực tập sinh       HCM     4\n8         Nữ Thực tập sinh       HCM     7\n9        Nam      Học việc        HN     7\n10        Nữ      Học việc        HN     0\n11       Nam     Nhân viên        HN     7\n12        Nữ     Nhân viên        HN    15\n13       Nam       Quản lý        HN     4\n14        Nữ       Quản lý        HN     2\n15       Nam Thực tập sinh        HN     0\n16        Nữ Thực tập sinh        HN     0\n\n\n\nlattice::barchart(count ~ gioi_tinh | chuc_vu + chi_nhanh, \n                  groups = gioi_tinh,\n                  data = ok_2,\n                  \n                  horizontal = FALSE,\n                  stack = TRUE,\n                  col = c(\"lightblue\", \"lightyellow\"),\n                  \n                  ## edit xy axis\n                  scales = list(axs = \"i\",\n                                draw = TRUE,\n                                x = list(relation = \"free\"), # relation = free | same\n                                y = list(relation = \"same\",\n                                         limits = c(0, 20))\n                                ),\n                  \n                  ## axis label and title\n                  xlab = list(label = \"Đặc điểm phân loại\", fontsize = 16, col = \"darkgreen\", font = 2),\n                  ylab = list(label = \"Số lượng nhân viên\", fontsize = 16, col = \"#FF1694\", font = 2),\n                  main = \"Số liệu nhân viên theo giới tính và chức vụ ở các chi nhánh\",\n                  sub = \"Nguồn: Phòng nhân sự cung cấp\",\n                  \n                  ## value above bar\n                  par.settings = list(strip.background = list(col = c(\"lightgreen\", \"yellow\"))),\n                  \n                  panel = function(x, y, subscripts, ...){\n                    \n                    panel.grid(h = -1,v = 0)\n                    \n                    panel.barchart(x, y, subscripts = subscripts,...)\n                    \n                    t &lt;- aggregate(y ~ x, data.frame(x, y), FUN = sum)\n                    \n                    panel.text(t$x, t$y, \n                               labels = t$y, \n                               pos = 3, \n                               col = \"blue\",\n                               fontsize = 13,\n                               font = 2\n                               \n                               )\n                    \n                  }\n                  \n                  )\n\n\n\n\n\n\n\n\nDoanh số theo chi nhánh ở các độ tuổi khác nhau\n\ndf$doanh_so &lt;- df$`Doanh thu bán hàng` / 1000000\n\nxyplot(doanh_so ~ `Tuổi` |`Chức vụ` + `Chi nhánh` , \n       data = df,\n       groups = `Giới tính`,\n       # layout = c(1, 2), # thay đổi vị trí các panel con\n       pch = 19,\n       col = c(\"red\", \"blue\"),\n\n       key = list (space = \"top\", column = 2,\n                   text = list(c(\"Nam\", \"Nữ\")),\n                   points = list(pch = c(19, 19),\n                                 col = c(\"red\", \"blue\"))\n\n                   ),\n       \n       ## axis label and title\n       xlab = list(label = \"Tuổi\", fontsize = 16, col = \"darkgreen\", font = 2),\n       ylab = list(label = \"Doanh số (triệu VNĐ)\", fontsize = 16, col = \"#FF1694\", font = 2),\n       main = \"Doanh số theo chi nhánh ở các độ tuổi khác nhau\",\n       sub = \"Nguồn: Phòng nhân sự cung cấp\",\n       \n       scales = list(axs = \"i\",\n                     draw = TRUE,\n                     x = list(relation = \"free\", # relation = free | same\n                              limits = c(0, 100)), \n                     y = list(relation = \"same\",\n                              limits = c(-300, 3500)\n                              )\n                     ),\n       \n       ## value above bar\n       par.settings = list(strip.background = list(col = c(\"lightgreen\", \"yellow\"))),\n       \n       type = c(\"g\", \"p\") ## \"g\"rid and \"p\"oints\n       \n       )",
    "crumbs": [
      "Các lệnh đồ thị căn bản sử dụng Base R Graphics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'><b>Hướng dẫn vẽ đồ thị bằng package <code>lattice</code></b></span>"
    ]
  },
  {
    "objectID": "co-so-ly-thuyet.html",
    "href": "co-so-ly-thuyet.html",
    "title": "Cơ sở lý thuyết",
    "section": "",
    "text": "Nội dung của phần này sẽ điểm qua các định nghĩa nền tảng về xác suất và thống kê vốn cũng vừa quen vừa lạ với phần lớn mọi người. Vì các định nghĩa này rất quan trọng nên mình sẽ không trình bày lại ở đây mà sẽ dẫn nguồn đến các tài liệu gốc để các bạn xem trực tiếp từ nhận định của chuyên gia trong lĩnh vực xác suất thống kê, sau đó bạn sẽ tự rút ra được kết luận cho mình. Các chủ đề còn lại mình sẽ trình bày theo cách hiểu của mình để giúp bạn có thêm 1 góc nhìn từ người trong cuộc đang tìm cách ứng dụng R để xử lý bài toán thống kê cho các tình huống thường gặp.\nNội dung các chủ đề này được thường xuyên sắp xếp để đảm bảo tính logic và hệ thống. Các chủ đề được xây dựng theo module để dần bao quát toàn bộ chương trình.\n\nXác suất là gì?\nThống kê là gì?\nCách tính số cỡ mẫu như thế nào để đạt ý nghĩa thống kê?\nKhoảng tin cậy (confidence interval) độ tin cậy (confidence level), mức ý nghĩa (significant level) là gì?\nPhân bố chuẩn (có tham số) và phân bố không chuẩn (phi tham số) là gì?\nPhương sai, độ lệch chuẩn, sai số chuẩn là gì?\nHệ số biến thiên (CV) và p-value là gì?\nR2 và R2 điều chỉnh khác nhau ra sao?\nQuy trình để lựa chọn các phương pháp kiểm định thống kê phù hợp với dataset (statistical selection tool for raw data)\nHồi quy là gì? Phân biệt giữa hồi quy đơn biến tuyến tính và phi tuyến. Phân biệt giữa hồi quy đơn biến và đa biến.\nHiệp phương sai (covariance) và độ tương quan (correlation) là gì?\nPhân tích phương sai ANOVA 1 yếu tố\nĐịnh nghĩa MANOVA, ANCOVA, MANCOVA\nPhân tích ANOVA 2 yếu tố kiểu RCBD trong R\nPhân tích ANCOVA trong R\nĐịnh nghĩa về nested design analysis\nHồi quy logistic\nPhân tích Power Analysis\nPhương pháp bootstrap\nPhương pháp clustering\nPhương pháp PCA\nFactor analysis\nCách tính chỉ số OR\nPhương pháp tối ưu hóa\nPooled sample standard error\nWorkflow phân tích thống kê qua dataset iris",
    "crumbs": [
      "Cơ sở lý thuyết"
    ]
  },
  {
    "objectID": "khoang-tin-cay.html",
    "href": "khoang-tin-cay.html",
    "title": "7  Khoảng tin cậy là gì?",
    "section": "",
    "text": "Về bản chất khoảng tin cậy là giá trị thực (real value) của con số trung bình tính được từ mẫu, nếu giả sử lặp lại quá trình lấy mẫu rất nhiều lần thì các con số trung bình này dao động trong một khoảng giá trị nào đó, thì đó là khoảng tin cậy (confidence interval).\nĐộ tin cậy 95% (confidence level) có nghĩa là giá trị cận trên và cận dưới mà bao phủ 95% giá trị trung bình của các lần lấy mẫu này.\nChi tiết tham khảo: (Crawley 2015, 61)\n\n(Starmer, n.d.)\n\n(Lam, n.d.)\n\n\n\n\nCrawley, Michael J. 2015. Statistics - an Introduction in r (2nd Edition). 2nd ed. Wiley. https://studyr.netlify.app/ref/crawley_2015_statistics_an_introduction_in_r_2nd_edition.pdf#page=77.\n\n\nLam, Nguyen Van. n.d. “Khoảng Tin Cậy (Confidence Interval) Là Gì?” https://youtu.be/TqOeMYtOc1w.\n\n\nStarmer, Josh. n.d. “Confidence Intervals, Clearly Explained!!!” https://youtu.be/TqOeMYtOc1w.",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'><b>Khoảng tin cậy là gì?</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-phan-tich-t-test-trong-r.html",
    "href": "huong-dan-phan-tich-t-test-trong-r.html",
    "title": "8  Hướng dẫn phân tích t-test trong R",
    "section": "",
    "text": "8.0.0.1 Bước 1: Cơ sở lý thuyết\nhttps://www.jmp.com/en_ch/statistics-knowledge-portal/t-test.html\n\nWhat is a t-test?\nA t-test (also known as Student’s t-test) is a tool for evaluating the means of one or two populations using hypothesis testing. A t-test may be used to evaluate whether a single group differs from a known value (a one-sample t-test), whether two groups differ from each other (an independent two-sample t-test), or whether there is a significant difference in paired measurements (a paired, or dependent samples t-test).\nHow are t-tests used?\nFirst, you define the hypothesis you are going to test and specify an acceptable risk of drawing a faulty conclusion. For example, when comparing two populations, you might hypothesize that their means are the same, and you decide on an acceptable probability of concluding that a difference exists when that is not true. Next, you calculate a test statistic from your data and compare it to a theoretical value from a t-distribution. Depending on the outcome, you either reject or fail to reject your null hypothesis.\nWhat if I have more than two groups?\nYou cannot use a t-test. Use a multiple comparison method. Examples are analysis of variance (ANOVA), Tukey-Kramer pairwise comparison, Dunnett’s comparison to a control, and analysis of means (ANOM).\n\n\n\n8.0.0.2 Bước 2: Đề bài về so sánh hai loài hoa qua các chỉ tiêu định lượng để tìm ra sự khác biệt bằng kiểm định t-test\n\n8.0.0.2.1 Bước 2.1: Đặt giả thuyết thống kê cho kiểm định t-test 2 đuôi\n\n\\({H_0}\\) : Trung bình tổng thể giữa hai mẫu không khác nhau về chỉ tiêu quan tâm \\(\\mu_1 = \\mu_2\\)\n\\({H_\\alpha }\\) : Trung bình tổng thể giữa hai mẫu khác nhau về chỉ tiêu quan tâm \\(\\mu_1 \\ne \\mu_2\\)\n\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix)\n\nflower &lt;- read.csv(\"flower.csv\")\nflower$Species &lt;- factor(flower$Species)\nflower \n\n   No.  Species   LBL  LBW  LBAR   LBC    PL   CTL   CLL\n1    1 Flower A 11.00 3.30 3.663 0.616 0.770 0.220 0.352\n2    2 Flower A  9.90 2.20 4.950 0.517 0.550 0.253 0.385\n3    3 Flower A 10.45 2.75 4.180 0.572 0.605 0.275 0.385\n4    4 Flower A 11.55 3.30 3.850 0.594 0.792 0.220 0.330\n5    5 Flower A 12.10 3.85 3.454 0.627 0.825 0.231 0.352\n6    6 Flower A 13.20 3.85 3.773 0.605 0.880 0.220 0.330\n7    7 Flower A 13.20 4.40 3.300 0.649 0.880 0.253 0.418\n8    8 Flower A  9.90 3.30 3.300 0.649 0.550 0.275 0.462\n9    9 Flower A 11.55 3.85 3.300 0.649 0.825 0.242 0.440\n10  10 Flower A 12.10 4.18 3.179 0.660 0.825 0.264 0.495\n11  11 Flower A 13.20 4.40 3.300 0.649 0.825 0.242 0.440\n12  12 Flower A 10.45 3.30 3.487 0.627 0.605 0.231 0.418\n13  13 Flower A  9.90 2.20 4.950 0.517 0.550 0.220 0.330\n14  14 Flower A 11.00 2.75 4.400 0.550 0.660 0.275 0.495\n15  15 Flower A 12.10 3.85 3.454 0.627 0.814 0.275 0.495\n16  16 Flower A 13.20 4.40 3.300 0.649 0.880 0.264 0.462\n17  17 Flower A 12.76 4.07 3.454 0.638 0.825 0.242 0.451\n18  18 Flower A 11.00 3.41 3.553 0.627 0.770 0.231 0.440\n19  19 Flower A 11.44 3.85 3.267 0.649 0.792 0.253 0.440\n20  20 Flower A  9.90 2.75 3.960 0.583 0.550 0.242 0.418\n21  21 Flower A 11.77 3.85 3.366 0.638 0.715 0.231 0.385\n22  22 Flower A 12.10 3.85 3.454 0.627 0.792 0.264 0.495\n23  23 Flower A 12.65 4.18 3.333 0.649 0.825 0.242 0.440\n24  24 Flower A 13.20 4.40 3.300 0.649 0.880 0.264 0.473\n25  25 Flower A 11.66 3.52 3.641 0.616 0.748 0.231 0.418\n26  26 Flower A 12.65 4.18 3.333 0.649 0.847 0.275 0.495\n27   1 Flower B 12.10 3.52 3.784 0.605 0.660 0.110 0.880\n28   2 Flower B 11.00 3.30 3.663 0.616 0.550 0.165 0.990\n29   3 Flower B 11.55 3.30 3.850 0.594 0.550 0.220 1.210\n30   4 Flower B 13.20 3.41 4.257 0.561 0.770 0.220 1.320\n31   5 Flower B 13.20 3.41 4.257 0.561 0.715 0.132 0.990\n32   6 Flower B 15.40 3.74 4.532 0.539 0.770 0.165 0.990\n33   7 Flower B 15.40 3.52 4.818 0.528 0.770 0.198 1.100\n34   8 Flower B 16.50 3.85 4.719 0.528 0.825 0.176 1.034\n35   9 Flower B 16.50 3.74 4.851 0.517 0.880 0.209 1.320\n36  10 Flower B 16.50 3.74 4.851 0.517 0.880 0.110 0.880\n37  11 Flower B 14.30 3.52 4.466 0.550 0.660 0.132 0.935\n38  12 Flower B 14.30 3.52 4.466 0.550 0.660 0.198 1.100\n39  13 Flower B 13.75 3.41 4.433 0.550 0.616 0.176 1.045\n40  14 Flower B 13.20 3.52 4.125 0.572 0.660 0.165 0.990\n41  15 Flower B 12.65 3.30 4.213 0.572 0.605 0.209 1.320\n42  16 Flower B 12.87 3.52 4.026 0.583 0.605 0.220 1.320\n43  17 Flower B 14.30 3.30 4.763 0.528 0.660 0.220 1.320\n44  18 Flower B 14.85 3.74 4.367 0.550 0.660 0.220 1.210\n45  19 Flower B 15.95 3.85 4.554 0.539 0.792 0.187 1.100\n46  20 Flower B 16.50 3.85 4.719 0.528 0.880 0.176 0.990\n\n\n\n\n8.0.0.2.2 Bước 2.2: Thống kê mô tả\nThực hiện cho 1 chỉ tiêu LBL\n\nflower  &lt;- flower[, -1]\n\nflower %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    count = n(),\n    mean = mean(LBL, na.rm = TRUE),\n    sd = sd(LBL, na.rm = TRUE),\n    median = median(LBL, na.rm = TRUE),\n    IQR = IQR(LBL, na.rm = TRUE)\n  )\n\n# A tibble: 2 × 6\n  Species  count  mean    sd median   IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Flower A    26  11.7  1.14   11.7  1.65\n2 Flower B    20  14.2  1.73   14.3  2.42\n\n\nNếu thực hiện tính toán các chỉ số thống kê cho lần lượt các cột trong data frame thì ta sẽ áp dụng lệnh họ apply.\n\n### khi sử dụng function với các lệnh trong dplyr thì bạn cần lưu ý quote string tham số \n# https://shixiangwang.github.io/tidyeval-chinese/dplyr.html\n# https://stackoverflow.com/questions/67382081/how-to-pass-column-name\n#-as-argument-to-function-for-dplyr-verbs\n\nthong_ke_mo_ta &lt;- function(input, group_input, chi_tieu) {\n  \n  input |&gt; \n    group_by(.data[[group_input]]) %&gt;%\n    summarise(\n      count = n(),\n      mean = mean(.data[[chi_tieu]], na.rm = TRUE),\n      sd = sd(.data[[chi_tieu]], na.rm = TRUE),\n      median = median(.data[[chi_tieu]], na.rm = TRUE),\n      IQR = IQR(.data[[chi_tieu]], na.rm = TRUE)\n    ) -&gt; df_ok\n  \n  return(df_ok)\n  \n}\n\nlapply(names(flower)[-1], FUN = thong_ke_mo_ta,\n       input = flower, group_input = \"Species\") -&gt; ok\n\nnames(ok) &lt;- names(flower)[-1]\n\nok\n\n$LBL\n# A tibble: 2 × 6\n  Species  count  mean    sd median   IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Flower A    26  11.7  1.14   11.7  1.65\n2 Flower B    20  14.2  1.73   14.3  2.42\n\n$LBW\n# A tibble: 2 × 6\n  Species  count  mean    sd median   IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Flower A    26  3.61 0.655   3.85 0.852\n2 Flower B    20  3.55 0.196   3.52 0.33 \n\n$LBAR\n# A tibble: 2 × 6\n  Species  count  mean    sd median   IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Flower A    26  3.63 0.488   3.45 0.446\n2 Flower B    20  4.39 0.361   4.45 0.528\n\n$LBC\n# A tibble: 2 × 6\n  Species  count  mean     sd median    IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Flower A    26 0.619 0.0404  0.627 0.0413\n2 Flower B    20 0.554 0.0286  0.55  0.0440\n\n$PL\n# A tibble: 2 × 6\n  Species  count  mean    sd median   IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Flower A    26 0.753 0.115  0.792 0.151\n2 Flower B    20 0.708 0.106  0.66  0.127\n\n$CTL\n# A tibble: 2 × 6\n  Species  count  mean     sd median    IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Flower A    26 0.248 0.0195  0.242 0.033 \n2 Flower B    20 0.180 0.0366  0.182 0.0467\n\n$CLL\n# A tibble: 2 × 6\n  Species  count  mean     sd median   IQR\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Flower A    26 0.425 0.0544   0.44 0.077\n2 Flower B    20 1.10  0.155    1.07 0.248\n\n\n\nlibrary(lattice)\n\nfor(i in 1:length(names(flower)[-1])){\n  \n  print(histogram( as.formula(paste(\"~\", names(flower)[-1][i], \"|\", \"Species\")), data = flower,\n             type = \"density\",\n             panel = function(x, ...) {\n               panel.histogram(x, ...)\n               panel.mathdensity(dmath = dnorm, col = \"black\",\n                                 args = list(mean=mean(x),sd=sd(x)))\n             } ))\n  \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.0.0.3 Bước 3:Kiểm tra giả thuyết cho t-test\nTừ chỗ này trở đi ta sẽ tính riêng chỉ tiêu “LBL” cho “Flower A” và “Flower B”. Các chỉ tiêu còn lại thực hiện tương tự.\nGiả thuyết cho t-test 1 sample\nWhile t-tests are relatively robust to deviations from assumptions, t-tests do assume that:\n\nThe data are continuous.\nThe sample data have been randomly sampled from a population.\nThe distribution is approximately normal.\nThere is homogeneity of variance (i.e., the variability of the data in each group is similar).\n\nthe standard Student’s t-test, which assumes that the variance of the two groups are equal.\nthe Welch’s t-test, which is less restrictive compared to the original Student’s test. This is the test where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom.\n\n\nGiả thuyết cho t-test 2 sample\nhttps://www.jmp.com/en_is/statistics-knowledge-portal/t-test/two-sample-t-test.html\n\nFor two-sample t-tests, we must have independent samples. If the samples are not independent, then a paired t-test may be appropriate. \\(\\Rightarrow\\) Trong dataset này thì đây là 2 mẫu độc lập, unpaired\nData values must be independent. Measurements for one observation do not affect measurements for any other observation. \\(\\Rightarrow\\) OK\nData in each group must be obtained via a random sample from the population. \\(\\Rightarrow\\) OK\nData in each group are normally distributed.\nData values are continuous. \\(\\Rightarrow\\) OK\nThe variances for the two independent groups are equal.\n\n\n8.0.0.3.1 Bước 3.1: Thực hiện kiểm tra giả thuyết về phân bố chuẩn\nCách 1: Sử dụng Q-Q plot\nQ-Q plot cho theo từng group.\n\n# test cho toàn bộ các group\n# qqnorm(flower$LBL, pch = 1, frame = FALSE)\n# qqline(flower$LBL, col = \"steelblue\", lwd = 2)\n\npar(mfrow = c(1, 2))\n\nflower |&gt; subset(Species == \"Flower A\") -&gt; flower_a\nqqnorm(flower_a$LBL, pch = 1, frame = FALSE, main = \"Q-Q plot for Flower A\")\nqqline(flower_a$LBL, col = \"steelblue\", lwd = 2)\n\nflower |&gt; subset(Species == \"Flower B\") -&gt; flower_b\nqqnorm(flower_b$LBL, pch = 1, frame = FALSE, main = \"Q-Q plot for Flower B\")\nqqline(flower_b$LBL, col = \"steelblue\", lwd = 2)\n\n\n\n\n\n\n\n\nQuantile-Quantile plots for comparing two Distributions\n\nlattice::qq(Species ~ LBL, aspect = 1, data = flower,\n   subset = (Species == \"Flower A\" | Species == \"Flower B\"))\n\n\n\n\n\n\n\n\nCách 2: Shapiro-Wilk Test for Normality (sample size must be between 3 and 5000)\n\nshapiro.test(x = flower_a$LBL)\n\n\n    Shapiro-Wilk normality test\n\ndata:  flower_a$LBL\nW = 0.91731, p-value = 0.0389\n\nshapiro.test(x = flower_b$LBL)\n\n\n    Shapiro-Wilk normality test\n\ndata:  flower_b$LBL\nW = 0.94162, p-value = 0.2572\n\n\nTrong Shapiro–Wilk test thì p-value nhỏ hơn 0.05 thì KHÔNG có phân bố chuẩn (do đó vi phạm giả thuyết). p-value lớn hơn 0.05 thì CÓ phân bố chuẩn.\nCách 3: Two-sample Kolmogorov-Smirnov’s test for Normality\n\nks.test(flower_a$LBL, flower_b$LBL)\n\n\n    Exact two-sample Kolmogorov-Smirnov test\n\ndata:  flower_a$LBL and flower_b$LBL\nD = 0.60769, p-value = 0.0001406\nalternative hypothesis: two-sided\n\n\nBiện luận kết quả theo p-value của Kolmogorov-Smirnov’s test.\nTham khảo: https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n\n\n8.0.0.3.2 Bước 3.2: Thực hiện kiểm tra giả thuyết về khác biệt phương sai\nWe will check whether the variances across the two groups are same or not. Performs an F-test to compare the variances of two samples from normal populations.\nhttps://www.datanovia.com/en/lessons/homogeneity-of-variance-test-in-r/\nThere are different variance tests that can be used to assess the equality of variances. These include:\n\nF-test: Compare the variances of two groups. The data must be normally distributed.\nBartlett’s test: Compare the variances of two or more groups. The data must be normally distributed.\nLevene’s test: A robust alternative to the Bartlett’s test that is less sensitive to departures from normality.\nFligner-Killeen’s test: a non-parametric test which is very robust against departures from normality.\n\nCách 1: Áp dụng F-test\n\n# The statistical hypotheses are:\n# \n# Null hypothesis (H0): the variances of the two groups are equal.\n# Alternative hypothesis (Ha): the variances are different.\n\nvar.test(flower_a$LBL, flower_b$LBL)\n\n\n    F test to compare two variances\n\ndata:  flower_a$LBL and flower_b$LBL\nF = 0.43625, num df = 25, denom df = 19, p-value = 0.05311\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1787345 1.0114015\nsample estimates:\nratio of variances \n         0.4362495 \n\n\n\nInterpretation. The p-value is p = 0.05311 which is greater than the significance level 0.05. In conclusion, there is no significant difference between the two variances.\n\np-value lớn hơn 0.05 nên bác bỏ H1 chấp nhận H0, tức là phương sai của hai nhóm này không khác biệt nhau.\nCách 2: Bartlett’s test with one independent variable\n\nbar_test &lt;- bartlett.test(LBL ~ Species, data = flower)\nbar_test\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  LBL by Species\nBartlett's K-squared = 3.6638, df = 1, p-value = 0.05561\n\n\np-value lớn hơn 0.05 nên bác bỏ H1 chấp nhận H0, tức là phương sai của hai nhóm này không khác biệt nhau.\nCách 3: Áp dụng Levene’s test\n\nlibrary(car)\nleveneTest(LBL ~ Species, data = flower)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  1  4.3445 0.04297 *\n      44                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTrong Levene’s test thì p-value nhỏ hơn 0.05 thì CÓ sự khác biệt về phương sai giữa 2 nhóm. p-value lớn hơn 0.05 thì KHÔNG CÓ sự khác biệt về phương sai giữa 2 nhóm.\nCách 4: Áp dụng Fligner-Killeen’s test\nThe Fligner-Killeen’s test is one of the many tests for homogeneity of variances which is most robust against departures from normality.\n\nfligner.test(LBL ~ Species, data = flower)\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  LBL by Species\nFligner-Killeen:med chi-squared = 4.5799, df = 1, p-value = 0.03235\n\n\n\n\n\n8.0.0.4 Bước 3: Thực hiện kiểm định t-test\n\nRecall that, by default, R computes the Welch t-test, which is the safer one. This is the test where you do not assume that the variance is the same in the two groups, which results in the fractional degrees of freedom. If you want to assume the equality of variances (Student t-test), specify the option var.equal = TRUE.\n\nTrường hợp phương sai không bằng nhau\n\nres_1 &lt;- t.test(LBL ~ Species, data = flower, \n              conf.level = 0.95,\n              paired = FALSE,\n              var.equal = FALSE)\nres_1\n\n\n    Welch Two Sample t-test\n\ndata:  LBL by Species\nt = -5.6306, df = 31.22, p-value = 3.44e-06\nalternative hypothesis: true difference in means between group Flower A and group Flower B is not equal to 0\n95 percent confidence interval:\n -3.420793 -1.601976\nsample estimates:\nmean in group Flower A mean in group Flower B \n              11.68962               14.20100 \n\n\nTrường hợp phương sai bằng nhau\n\nres_2 &lt;- t.test(LBL ~ Species, data = flower, \n              conf.level = 0.95,\n              paired = FALSE,\n              var.equal = TRUE)\nres_2\n\n\n    Two Sample t-test\n\ndata:  LBL by Species\nt = -5.934, df = 44, p-value = 4.219e-07\nalternative hypothesis: true difference in means between group Flower A and group Flower B is not equal to 0\n95 percent confidence interval:\n -3.364333 -1.658436\nsample estimates:\nmean in group Flower A mean in group Flower B \n              11.68962               14.20100 \n\n\nTrường hợp nếu không thỏa điều kiện cho phân tích t-test thì ta áp dụng two-samples Wilcoxon test.\n\nThe unpaired two-samples Wilcoxon test (also known as Wilcoxon rank sum test or Mann-Whitney test) is a non-parametric alternative to the unpaired two-samples t-test, which can be used to compare two independent groups of samples. It’s used when your data are not normally distributed.\n\n\n\n8.0.0.5 Bước 4: Tính effect size\nSalvatore S. Mangiafico. Summary and Analysis of Extension Program Evaluation in R. https://rcompanion.org/documents/RHandbookProgramEvaluation.pdf\n\nCohen’s d can be used as an effect size statistic for a two-sample t-test. It is calculated as the difference between the means of each group, all divided by the pooled standard deviation of the data.\nIt ranges from 0 to infinity, with 0 indicating no effect where the means are equal. In some versions, Cohen’s d can be positive or negative depending on which mean is greater.\nA Cohen’s d of 0.5 suggests that the means differ by one-half the standard deviation of the data. A Cohen’s d of 1.0 suggests that the means differ by one standard deviation of the data.\n\n\nlibrary(lsr)\n\nlsr::cohensD(LBL ~ Species, data = flower)\n\n[1] 1.764908\n\n\n\n\n8.0.0.6 Bước 5: Kiểm tra giả thuyết cho t-test cho cùng lúc nhiều cột\nTa cần chuyển dữ liệu về dạng long để thuận tiện xử lý và vẽ đồ thị.\n\n# Transform the data into long format\n# Put all variables in the same column except `Species`, the grouping variable\n\nmydata &lt;- flower\n\nmydata.long &lt;- mydata %&gt;%\n  pivot_longer(-Species, names_to = \"variables\", values_to = \"value\")\n\nmydata.long &lt;- as.data.frame(mydata.long)\n\nmydata.long\n\n     Species variables  value\n1   Flower A       LBL 11.000\n2   Flower A       LBW  3.300\n3   Flower A      LBAR  3.663\n4   Flower A       LBC  0.616\n5   Flower A        PL  0.770\n6   Flower A       CTL  0.220\n7   Flower A       CLL  0.352\n8   Flower A       LBL  9.900\n9   Flower A       LBW  2.200\n10  Flower A      LBAR  4.950\n11  Flower A       LBC  0.517\n12  Flower A        PL  0.550\n13  Flower A       CTL  0.253\n14  Flower A       CLL  0.385\n15  Flower A       LBL 10.450\n16  Flower A       LBW  2.750\n17  Flower A      LBAR  4.180\n18  Flower A       LBC  0.572\n19  Flower A        PL  0.605\n20  Flower A       CTL  0.275\n21  Flower A       CLL  0.385\n22  Flower A       LBL 11.550\n23  Flower A       LBW  3.300\n24  Flower A      LBAR  3.850\n25  Flower A       LBC  0.594\n26  Flower A        PL  0.792\n27  Flower A       CTL  0.220\n28  Flower A       CLL  0.330\n29  Flower A       LBL 12.100\n30  Flower A       LBW  3.850\n31  Flower A      LBAR  3.454\n32  Flower A       LBC  0.627\n33  Flower A        PL  0.825\n34  Flower A       CTL  0.231\n35  Flower A       CLL  0.352\n36  Flower A       LBL 13.200\n37  Flower A       LBW  3.850\n38  Flower A      LBAR  3.773\n39  Flower A       LBC  0.605\n40  Flower A        PL  0.880\n41  Flower A       CTL  0.220\n42  Flower A       CLL  0.330\n43  Flower A       LBL 13.200\n44  Flower A       LBW  4.400\n45  Flower A      LBAR  3.300\n46  Flower A       LBC  0.649\n47  Flower A        PL  0.880\n48  Flower A       CTL  0.253\n49  Flower A       CLL  0.418\n50  Flower A       LBL  9.900\n51  Flower A       LBW  3.300\n52  Flower A      LBAR  3.300\n53  Flower A       LBC  0.649\n54  Flower A        PL  0.550\n55  Flower A       CTL  0.275\n56  Flower A       CLL  0.462\n57  Flower A       LBL 11.550\n58  Flower A       LBW  3.850\n59  Flower A      LBAR  3.300\n60  Flower A       LBC  0.649\n61  Flower A        PL  0.825\n62  Flower A       CTL  0.242\n63  Flower A       CLL  0.440\n64  Flower A       LBL 12.100\n65  Flower A       LBW  4.180\n66  Flower A      LBAR  3.179\n67  Flower A       LBC  0.660\n68  Flower A        PL  0.825\n69  Flower A       CTL  0.264\n70  Flower A       CLL  0.495\n71  Flower A       LBL 13.200\n72  Flower A       LBW  4.400\n73  Flower A      LBAR  3.300\n74  Flower A       LBC  0.649\n75  Flower A        PL  0.825\n76  Flower A       CTL  0.242\n77  Flower A       CLL  0.440\n78  Flower A       LBL 10.450\n79  Flower A       LBW  3.300\n80  Flower A      LBAR  3.487\n81  Flower A       LBC  0.627\n82  Flower A        PL  0.605\n83  Flower A       CTL  0.231\n84  Flower A       CLL  0.418\n85  Flower A       LBL  9.900\n86  Flower A       LBW  2.200\n87  Flower A      LBAR  4.950\n88  Flower A       LBC  0.517\n89  Flower A        PL  0.550\n90  Flower A       CTL  0.220\n91  Flower A       CLL  0.330\n92  Flower A       LBL 11.000\n93  Flower A       LBW  2.750\n94  Flower A      LBAR  4.400\n95  Flower A       LBC  0.550\n96  Flower A        PL  0.660\n97  Flower A       CTL  0.275\n98  Flower A       CLL  0.495\n99  Flower A       LBL 12.100\n100 Flower A       LBW  3.850\n101 Flower A      LBAR  3.454\n102 Flower A       LBC  0.627\n103 Flower A        PL  0.814\n104 Flower A       CTL  0.275\n105 Flower A       CLL  0.495\n106 Flower A       LBL 13.200\n107 Flower A       LBW  4.400\n108 Flower A      LBAR  3.300\n109 Flower A       LBC  0.649\n110 Flower A        PL  0.880\n111 Flower A       CTL  0.264\n112 Flower A       CLL  0.462\n113 Flower A       LBL 12.760\n114 Flower A       LBW  4.070\n115 Flower A      LBAR  3.454\n116 Flower A       LBC  0.638\n117 Flower A        PL  0.825\n118 Flower A       CTL  0.242\n119 Flower A       CLL  0.451\n120 Flower A       LBL 11.000\n121 Flower A       LBW  3.410\n122 Flower A      LBAR  3.553\n123 Flower A       LBC  0.627\n124 Flower A        PL  0.770\n125 Flower A       CTL  0.231\n126 Flower A       CLL  0.440\n127 Flower A       LBL 11.440\n128 Flower A       LBW  3.850\n129 Flower A      LBAR  3.267\n130 Flower A       LBC  0.649\n131 Flower A        PL  0.792\n132 Flower A       CTL  0.253\n133 Flower A       CLL  0.440\n134 Flower A       LBL  9.900\n135 Flower A       LBW  2.750\n136 Flower A      LBAR  3.960\n137 Flower A       LBC  0.583\n138 Flower A        PL  0.550\n139 Flower A       CTL  0.242\n140 Flower A       CLL  0.418\n141 Flower A       LBL 11.770\n142 Flower A       LBW  3.850\n143 Flower A      LBAR  3.366\n144 Flower A       LBC  0.638\n145 Flower A        PL  0.715\n146 Flower A       CTL  0.231\n147 Flower A       CLL  0.385\n148 Flower A       LBL 12.100\n149 Flower A       LBW  3.850\n150 Flower A      LBAR  3.454\n151 Flower A       LBC  0.627\n152 Flower A        PL  0.792\n153 Flower A       CTL  0.264\n154 Flower A       CLL  0.495\n155 Flower A       LBL 12.650\n156 Flower A       LBW  4.180\n157 Flower A      LBAR  3.333\n158 Flower A       LBC  0.649\n159 Flower A        PL  0.825\n160 Flower A       CTL  0.242\n161 Flower A       CLL  0.440\n162 Flower A       LBL 13.200\n163 Flower A       LBW  4.400\n164 Flower A      LBAR  3.300\n165 Flower A       LBC  0.649\n166 Flower A        PL  0.880\n167 Flower A       CTL  0.264\n168 Flower A       CLL  0.473\n169 Flower A       LBL 11.660\n170 Flower A       LBW  3.520\n171 Flower A      LBAR  3.641\n172 Flower A       LBC  0.616\n173 Flower A        PL  0.748\n174 Flower A       CTL  0.231\n175 Flower A       CLL  0.418\n176 Flower A       LBL 12.650\n177 Flower A       LBW  4.180\n178 Flower A      LBAR  3.333\n179 Flower A       LBC  0.649\n180 Flower A        PL  0.847\n181 Flower A       CTL  0.275\n182 Flower A       CLL  0.495\n183 Flower B       LBL 12.100\n184 Flower B       LBW  3.520\n185 Flower B      LBAR  3.784\n186 Flower B       LBC  0.605\n187 Flower B        PL  0.660\n188 Flower B       CTL  0.110\n189 Flower B       CLL  0.880\n190 Flower B       LBL 11.000\n191 Flower B       LBW  3.300\n192 Flower B      LBAR  3.663\n193 Flower B       LBC  0.616\n194 Flower B        PL  0.550\n195 Flower B       CTL  0.165\n196 Flower B       CLL  0.990\n197 Flower B       LBL 11.550\n198 Flower B       LBW  3.300\n199 Flower B      LBAR  3.850\n200 Flower B       LBC  0.594\n201 Flower B        PL  0.550\n202 Flower B       CTL  0.220\n203 Flower B       CLL  1.210\n204 Flower B       LBL 13.200\n205 Flower B       LBW  3.410\n206 Flower B      LBAR  4.257\n207 Flower B       LBC  0.561\n208 Flower B        PL  0.770\n209 Flower B       CTL  0.220\n210 Flower B       CLL  1.320\n211 Flower B       LBL 13.200\n212 Flower B       LBW  3.410\n213 Flower B      LBAR  4.257\n214 Flower B       LBC  0.561\n215 Flower B        PL  0.715\n216 Flower B       CTL  0.132\n217 Flower B       CLL  0.990\n218 Flower B       LBL 15.400\n219 Flower B       LBW  3.740\n220 Flower B      LBAR  4.532\n221 Flower B       LBC  0.539\n222 Flower B        PL  0.770\n223 Flower B       CTL  0.165\n224 Flower B       CLL  0.990\n225 Flower B       LBL 15.400\n226 Flower B       LBW  3.520\n227 Flower B      LBAR  4.818\n228 Flower B       LBC  0.528\n229 Flower B        PL  0.770\n230 Flower B       CTL  0.198\n231 Flower B       CLL  1.100\n232 Flower B       LBL 16.500\n233 Flower B       LBW  3.850\n234 Flower B      LBAR  4.719\n235 Flower B       LBC  0.528\n236 Flower B        PL  0.825\n237 Flower B       CTL  0.176\n238 Flower B       CLL  1.034\n239 Flower B       LBL 16.500\n240 Flower B       LBW  3.740\n241 Flower B      LBAR  4.851\n242 Flower B       LBC  0.517\n243 Flower B        PL  0.880\n244 Flower B       CTL  0.209\n245 Flower B       CLL  1.320\n246 Flower B       LBL 16.500\n247 Flower B       LBW  3.740\n248 Flower B      LBAR  4.851\n249 Flower B       LBC  0.517\n250 Flower B        PL  0.880\n251 Flower B       CTL  0.110\n252 Flower B       CLL  0.880\n253 Flower B       LBL 14.300\n254 Flower B       LBW  3.520\n255 Flower B      LBAR  4.466\n256 Flower B       LBC  0.550\n257 Flower B        PL  0.660\n258 Flower B       CTL  0.132\n259 Flower B       CLL  0.935\n260 Flower B       LBL 14.300\n261 Flower B       LBW  3.520\n262 Flower B      LBAR  4.466\n263 Flower B       LBC  0.550\n264 Flower B        PL  0.660\n265 Flower B       CTL  0.198\n266 Flower B       CLL  1.100\n267 Flower B       LBL 13.750\n268 Flower B       LBW  3.410\n269 Flower B      LBAR  4.433\n270 Flower B       LBC  0.550\n271 Flower B        PL  0.616\n272 Flower B       CTL  0.176\n273 Flower B       CLL  1.045\n274 Flower B       LBL 13.200\n275 Flower B       LBW  3.520\n276 Flower B      LBAR  4.125\n277 Flower B       LBC  0.572\n278 Flower B        PL  0.660\n279 Flower B       CTL  0.165\n280 Flower B       CLL  0.990\n281 Flower B       LBL 12.650\n282 Flower B       LBW  3.300\n283 Flower B      LBAR  4.213\n284 Flower B       LBC  0.572\n285 Flower B        PL  0.605\n286 Flower B       CTL  0.209\n287 Flower B       CLL  1.320\n288 Flower B       LBL 12.870\n289 Flower B       LBW  3.520\n290 Flower B      LBAR  4.026\n291 Flower B       LBC  0.583\n292 Flower B        PL  0.605\n293 Flower B       CTL  0.220\n294 Flower B       CLL  1.320\n295 Flower B       LBL 14.300\n296 Flower B       LBW  3.300\n297 Flower B      LBAR  4.763\n298 Flower B       LBC  0.528\n299 Flower B        PL  0.660\n300 Flower B       CTL  0.220\n301 Flower B       CLL  1.320\n302 Flower B       LBL 14.850\n303 Flower B       LBW  3.740\n304 Flower B      LBAR  4.367\n305 Flower B       LBC  0.550\n306 Flower B        PL  0.660\n307 Flower B       CTL  0.220\n308 Flower B       CLL  1.210\n309 Flower B       LBL 15.950\n310 Flower B       LBW  3.850\n311 Flower B      LBAR  4.554\n312 Flower B       LBC  0.539\n313 Flower B        PL  0.792\n314 Flower B       CTL  0.187\n315 Flower B       CLL  1.100\n316 Flower B       LBL 16.500\n317 Flower B       LBW  3.850\n318 Flower B      LBAR  4.719\n319 Flower B       LBC  0.528\n320 Flower B        PL  0.880\n321 Flower B       CTL  0.176\n322 Flower B       CLL  0.990\n\n\nRun multiple t-tests\n\nstat.test &lt;- mydata.long %&gt;%\n  group_by(variables) %&gt;%\n  t_test(value ~ Species) %&gt;%\n  adjust_pvalue(method = \"BH\") %&gt;%\n  add_significance()\nstat.test &lt;- as.data.frame(stat.test)\nstat.test\n\n  variables   .y.   group1   group2 n1 n2  statistic       df        p        p.adj p.adj.signif\n1       CLL value Flower A Flower B 26 20 -18.651023 22.60898 3.19e-15 2.233000e-14         ****\n2       CTL value Flower A Flower B 26 20   7.421902 27.19379 5.29e-08 1.851500e-07         ****\n3      LBAR value Flower A Flower B 26 20  -5.999057 43.95851 3.40e-07 5.950000e-07         ****\n4       LBC value Flower A Flower B 26 20   6.299147 43.76586 1.25e-07 2.916667e-07         ****\n5       LBL value Flower A Flower B 26 20  -5.630632 31.21960 3.44e-06 4.816000e-06         ****\n6       LBW value Flower A Flower B 26 20   0.442909 30.60858 6.61e-01 6.610000e-01           ns\n7        PL value Flower A Flower B 26 20   1.362387 42.49847 1.80e-01 2.100000e-01           ns\n\n\nCreate individual boxplots with t-test p-values\n\n# multi-panel\n# # Create the plot\n# myplot &lt;- ggboxplot(\n#   mydata.long, x = \"Species\", y = \"value\",\n#   fill = \"Species\", palette = \"npg\", legend = \"none\",\n#   ggtheme = theme_pubr(border = TRUE)\n#   ) +\n#   facet_wrap(~variables)\n# # Add statistical test p-values\n# stat.test &lt;- stat.test %&gt;% add_xy_position(x = \"Species\")\n# myplot + stat_pvalue_manual(stat.test, label = \"p.adj.signif\")\n\n###\n\n# Group the data by variables and do a graph for each variable\n\nstat.test &lt;- stat.test %&gt;% add_xy_position(x = \"Species\")\n\ngraphs &lt;- mydata.long %&gt;%\n  group_by(variables) %&gt;%\n  doo(\n    ~ggboxplot(\n      data =., x = \"Species\", y = \"value\",\n      fill = \"Species\", palette = \"npg\", legend = \"none\",\n      ggtheme = theme_pubr()\n      ), \n    result = \"plots\"\n  )\n\n# graphs\n\n# Add statitistical tests to each corresponding plot\nvariables &lt;- graphs$variables\nfor(i in 1:length(variables)){\n  graph.i &lt;- graphs$plots[[i]] + \n    labs(title = variables[i]) + \n    stat_pvalue_manual(stat.test[i, ], label = \"p.adj.signif\")\n  print(graph.i)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.0.0.7 Tài liệu tham khảo\n\nhttps://www.sthda.com/english/wiki/unpaired-two-samples-t-test-in-r\nhttps://www.datanovia.com/en/lessons/how-to-do-a-t-test-in-r-calculation-and-reporting/\nhttps://www.datanovia.com/en/blog/how-to-perform-multiple-t-test-in-r-for-different-variables/\nhttps://rpubs.com/SameerMathur/t-testAssumptions\nhttps://cran.r-project.org/web/packages/qqplotr/vignettes/introduction.html\nhttps://astrostatistics.psu.edu/su07/R/html/lattice/html/qq.html\nhttps://adiradaniel.netlify.app/post/ggmultipane/\nTính diff mean trong t-test two samples",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'><b>Hướng dẫn phân tích t-test trong R</b></span>"
    ]
  },
  {
    "objectID": "phan-tich-anova-2-yeu-to-trong-r.html",
    "href": "phan-tich-anova-2-yeu-to-trong-r.html",
    "title": "9  Phân tích ANOVA 2 yếu tố trong R",
    "section": "",
    "text": "Câu hỏi nghiên cứu: Xác định tổ hợp giữa cơ chất và vi sinh vật để thu được hoạt tính enzyme cao\n\n9.0.1 Bước 1: Import dữ liệu\n\nlibrary(readxl)\n\nenzyme_df &lt;- readxl::read_excel(\"activity.xlsx\", col_names = TRUE)\n\nenzyme_df &lt;- as.data.frame(enzyme_df)\n\nenzyme_df\n\n     substrate bacillus  enzyme\n1  substrate_a     AB12 26.4125\n2  substrate_a     AB12 32.4125\n3  substrate_a     AB12 27.3000\n4  substrate_b     AB12 12.7500\n5  substrate_b     AB12 11.9625\n6  substrate_b     AB12  8.9500\n7  substrate_c     AB12 23.2000\n8  substrate_c     AB12 25.8625\n9  substrate_c     AB12 24.2750\n10 substrate_d     AB12 48.1375\n11 substrate_d     AB12 45.9125\n12 substrate_d     AB12 47.7750\n13 substrate_e     AB12 43.7250\n14 substrate_e     AB12 44.6000\n15 substrate_e     AB12 42.3875\n16 substrate_a     CD47 32.2750\n17 substrate_a     CD47 30.2250\n18 substrate_a     CD47 32.5125\n19 substrate_b     CD47 10.4750\n20 substrate_b     CD47  9.9250\n21 substrate_b     CD47 10.0375\n22 substrate_c     CD47 15.4625\n23 substrate_c     CD47 19.7250\n24 substrate_c     CD47 17.9125\n25 substrate_d     CD47 24.0625\n26 substrate_d     CD47 25.4750\n27 substrate_d     CD47 24.8375\n28 substrate_e     CD47 22.6500\n29 substrate_e     CD47 22.1625\n30 substrate_e     CD47 21.5500\n31 substrate_a     ER12 40.2375\n32 substrate_a     ER12 36.1750\n33 substrate_a     ER12 39.2125\n34 substrate_b     ER12 14.7250\n35 substrate_b     ER12 15.1750\n36 substrate_b     ER12 16.0625\n37 substrate_c     ER12 20.1875\n38 substrate_c     ER12 21.5125\n39 substrate_c     ER12 21.7250\n40 substrate_d     ER12 53.1875\n41 substrate_d     ER12 53.1000\n42 substrate_d     ER12 52.5750\n43 substrate_e     ER12 45.6625\n44 substrate_e     ER12 45.3625\n45 substrate_e     ER12 44.7000\n46 substrate_a     MS16 36.1500\n47 substrate_a     MS16 35.0625\n48 substrate_a     MS16 33.5375\n49 substrate_b     MS16 16.5250\n50 substrate_b     MS16 21.4375\n51 substrate_b     MS16 18.6750\n52 substrate_c     MS16 25.1875\n53 substrate_c     MS16 25.5375\n54 substrate_c     MS16 26.6250\n55 substrate_d     MS16 43.2500\n56 substrate_d     MS16 43.6000\n57 substrate_d     MS16 40.4625\n58 substrate_e     MS16 52.4125\n59 substrate_e     MS16 52.9375\n60 substrate_e     MS16 53.0125\n\ntable(enzyme_df$substrate, enzyme_df$bacillus)\n\n             \n              AB12 CD47 ER12 MS16\n  substrate_a    3    3    3    3\n  substrate_b    3    3    3    3\n  substrate_c    3    3    3    3\n  substrate_d    3    3    3    3\n  substrate_e    3    3    3    3\n\n\nChuyển dạng factor cho các biến substrate và bacillus.\n\nenzyme_df$substrate &lt;- as.factor(enzyme_df$substrate)\nenzyme_df$bacillus &lt;- as.factor(enzyme_df$bacillus)\n\n\n\n9.0.2 Bước 2: Giả thuyết cho ANOVA 2 yếu tố\nNguồn: https://statistics.laerd.com/spss-tutorials/two-way-anova-using-spss-statistics.php\n\nAssumption #1: Your dependent variable should be measured at the continuous level \\(\\Rightarrow\\) OK\nAssumption #2: Your two independent variables should each consist of two or more categorical, independent groups \\(\\Rightarrow\\) OK\nAssumption #3: You should have independence of observations, which means that there is no relationship between the observations in each group or between the groups themselves. \\(\\Rightarrow\\) OK\nAssumption #4: There should be no significant outliers.\nAssumption #5: Your dependent variable should be approximately normally distributed for each combination of the groups of the two independent variables.\nAssumption #6: There needs to be homogeneity of variances for each combination of the groups of the two independent variables. Again, whilst this sounds a little tricky, you can easily test this assumption in SPSS Statistics using Levene’s test for homogeneity of variances.\n\n\n\n9.0.3 Bước 3: Kiểm tra giả thuyết cho ANOVA\n\n9.0.3.1 Bước 3.1: Kiểm tra giả thuyết Assumption #5 normally distributed for each combination of the groups\n\n# Compute two-way ANOVA test with interaction effect\nres.aov &lt;- aov(enzyme ~ substrate * bacillus, data = enzyme_df)\naov_residuals &lt;- residuals(object = res.aov)\nshapiro.test(x = aov_residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  aov_residuals\nW = 0.96772, p-value = 0.1127\n\n\nKết quả Shapiro-Wilk normality test cho thấy p-value là 0.1127 lớn hơn 0.05. Do đó bộ dataset này có sự phân bố chuẩn \\(\\Rightarrow\\) OK\nhttps://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test\n\nThe Shapiro–Wilk test is a test of normality. The null-hypothesis of this test is that the population is normally distributed. Thus, if the p value is less than the chosen alpha level, then the null hypothesis is rejected and there is evidence that the data tested are not normally distributed. On the other hand, if the p value is greater than the chosen alpha level, then the null hypothesis (that the data came from a normally distributed population) can not be rejected (e.g., for an alpha level of .05, a data set with a p value of less than .05 rejects the null hypothesis that the data are from a normally distributed population – consequently, a data set with a p value more than the .05 alpha value fails to reject the null hypothesis that the data is from a normally distributed population).\n\nTóm lại trong Shapiro–Wilk test thì p-value nhỏ hơn 0.05 thì KHÔNG có phân bố chuẩn (do đó vi phạm giả thuyết). p-value lớn hơn 0.05 thì CÓ phân bố chuẩn.\n\n\n9.0.3.2 Bước 3.2: Kiểm tra giả thuyết Assumption #6 homogeneity of variances\n\nlibrary(car)\nleveneTest(enzyme ~ substrate * bacillus, data = enzyme_df) \n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup 19  0.6694 0.8254\n      40               \n\n\nKết quả Levene’s test cho thấy p-value là 0.8254 lớn hơn 0.05. Do đó bộ dataset này có không có sự khác biệt về phương sai giữa các tổ hợp các mức khác nhau của 2 biến \\(\\Rightarrow\\) OK\nhttps://en.wikipedia.org/wiki/Levene%27s_test\n\nIn statistics, Levene’s test is an inferential statistic used to assess the equality of variances for a variable calculated for two or more groups. Some common statistical procedures assume that variances of the populations from which different samples are drawn are equal. Levene’s test assesses this assumption. It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). If the resulting p-value of Levene’s test is less than some significance level (typically 0.05), the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances. Thus, the null hypothesis of equal variances is rejected and it is concluded that there is a difference between the variances in the population.\n\nTóm lại trong Levene’s test thì p-value nhỏ hơn 0.05 thì CÓ sự khác biệt về phương sai giữa các tổ hợp yếu tố (do đó vi phạm giả thuyết). p-value lớn hơn 0.05 thì KHÔNG CÓ sự khác biệt về phương sai giữa các tổ hợp các mức của 2 yếu tố.\n\n\n9.0.3.3 Bước 3.3: Kiểm tra giả thuyết Assumption #4 kiểm tra outlier\nCó nhiều phương pháp để detect outliers trong dataset.\nCách 1: Multivariate Model Approach - Cook’s Distance\n\nmod &lt;- lm(enzyme ~ substrate * bacillus, data = enzyme_df)\ncooksd &lt;- cooks.distance(mod)\n\nplot(cooksd, pch = \"*\", \n     cex = 2, main = \"Influential Obs by Cooks distance\")  # plot cook's distance\n\nabline(h = 4*mean(cooksd, na.rm = TRUE), col=\"red\")  # add cutoff line\n\ntext(x = 1:length(cooksd) + 1, y = cooksd, \n     labels = ifelse(cooksd &gt; 4*mean(cooksd, na.rm = TRUE),\n                     names(cooksd), \"\"), col = \"red\")  # add labels\n\n\n\n\n\n\n\ninfluential &lt;- cooksd &gt; 4 * mean(cooksd, na.rm = TRUE)\n\nenzyme_df[influential, ] ## giá trị outlier\n\n     substrate bacillus  enzyme\n2  substrate_a     AB12 32.4125\n50 substrate_b     MS16 21.4375\n\n\nCách 2: Dùng function car::outlierTest\n\nlibrary(car)\ncar::outlierTest(mod) -&gt; ok\n# names(ok$p)\nenzyme_df[names(ok$p), ] ## giá trị outlier\n\n    substrate bacillus  enzyme\n2 substrate_a     AB12 32.4125\n\n\nCách 3: Dùng package outliers\n\n### sử dụng function outlier() cho vector enzyme activity\nlibrary(outliers)\noutliers::outlier(enzyme_df$enzyme, opposite = TRUE) -&gt; yes_1\n\nenzyme_df |&gt; subset(enzyme == yes_1) # vị trí outlier\n\n    substrate bacillus enzyme\n6 substrate_b     AB12   8.95\n\n### sử dụng function scores() cho vector enzyme activity\n\n# outliers::scores(enzyme_df$enzyme, type = \"chisq\", prob = 0.95) \n# outliers::scores(enzyme_df$enzyme, type = \"t\", prob = 0.95) \n\noutliers::scores(enzyme_df$enzyme, type = \"z\", prob = 0.95) -&gt; yes_2\n\nenzyme_df[yes_2, ]\n\n     substrate bacillus  enzyme\n40 substrate_d     ER12 53.1875\n41 substrate_d     ER12 53.1000\n42 substrate_d     ER12 52.5750\n58 substrate_e     MS16 52.4125\n59 substrate_e     MS16 52.9375\n60 substrate_e     MS16 53.0125\n\n\nCách 4: Dùng đồ thị Q-Q plot\n\nmod &lt;- lm(enzyme ~ substrate * bacillus, data = enzyme_df)\n\npar(mar = c(3, 3, 3, 3))\n\nplot(mod, 1)\n\n\n\n\n\n\n\nplot(mod, 2)\n\n\n\n\n\n\n\nplot(mod, 3)\n\n\n\n\n\n\n\nplot(mod, 4)\n\n\n\n\n\n\n\nplot(mod, 5)\n\n\n\n\n\n\n\nplot(mod, 6)\n\n\n\n\n\n\n\n# sort(abs(residuals(mod)), decreasing = TRUE) # save the residuals\n\nenzyme_df[c(2, 32, 50), ]\n\n     substrate bacillus  enzyme\n2  substrate_a     AB12 32.4125\n32 substrate_a     ER12 36.1750\n50 substrate_b     MS16 21.4375\n\n\nCách 5: Dùng function car::influencePlot\n\nlibrary(car)\nouts &lt;- car::influencePlot(mod)\n\n\n\n\n\n\n\nenzyme_df[row.names(outs), ]\n\n     substrate bacillus  enzyme\n2  substrate_a     AB12 32.4125\n3  substrate_a     AB12 27.3000\n4  substrate_b     AB12 12.7500\n50 substrate_b     MS16 21.4375\n\n\n\n\n\n9.0.4 Bước 4: Kiểm tra đặc điểm dữ liệu\nHistogram theo các mức trong substrate\n\nlibrary(lattice)\nhistogram( ~ enzyme | substrate, data = enzyme_df,\n           xlab = \"Enzyme activity (FU/mL)\", type = \"density\",\n           panel = function(x, ...) {\n             panel.histogram(x, ...)\n             panel.mathdensity(dmath = dnorm, col = \"black\",\n                               args = list(mean=mean(x),sd=sd(x)))\n           } )\n\n\n\n\n\n\n\n\nHistogram theo các mức trong bacillus\n\nlibrary(lattice)\nhistogram( ~ enzyme | bacillus, data = enzyme_df,\n           xlab = \"Enzyme activity (FU/mL)\", type = \"density\",\n           panel = function(x, ...) {\n             panel.histogram(x, ...)\n             panel.mathdensity(dmath = dnorm, col = \"black\",\n                               args = list(mean=mean(x),sd=sd(x)))\n           } )\n\n\n\n\n\n\n\n\nBoxplot với tổ hợp các nghiệm thức\n\nlibrary(ggpubr)\nggboxplot(enzyme_df, x = \"bacillus\", y = \"enzyme\", color = \"substrate\", ylab = \"Enzyme activity (FU/mL)\")\n\n\n\n\n\n\n\n\nLineplot với tổ hợp các nghiệm thức\n\nlibrary(\"ggpubr\")\nggline(enzyme_df, x = \"bacillus\", y = \"enzyme\", color = \"substrate\", ylab = \"Enzyme activity (FU/mL)\",\n       add = c(\"mean_sd\", \"dotplot\"))\n\n\n\n\n\n\n\n\nBox plot with two factor variables\n\nenzyme_df$substrate &lt;- reorder(enzyme_df$substrate, enzyme_df$enzyme, decreasing = FALSE) \nenzyme_df$bacillus &lt;- reorder(enzyme_df$bacillus, enzyme_df$enzyme, decreasing = FALSE) \n\npar(mar = c(3, 12, 1, 1))\n\nboxplot(enzyme ~ substrate * bacillus, data = enzyme_df, frame = TRUE,\n        horizontal = TRUE, las = 1,\n        axisnames = TRUE, ylab = \"\", xlab = \"Enzyme activity (FU/mL)\")\n\n\n\n\n\n\n\n\nTwo-way interaction plot\n\ninteraction.plot(x.factor = enzyme_df$bacillus, trace.factor = enzyme_df$substrate, \n                 trace.label = \"Substrate\",\n                 response = enzyme_df$enzyme, fun = mean, \n                 type = \"b\", legend = TRUE, \n                 xlab = expression(italic(Bacillus) ~ \".sp\"), ylab =\"Enzyme activity (FU/mL)\",\n                 pch = c(15, 16, 8, 17, 19), \n                 col = c(\"red\", \"blue\", \"darkgreen\", \"purple\", \"yellow4\"))\n\n\n\n\n\n\n\n\n\ninteraction.plot(x.factor = enzyme_df$substrate, trace.factor = enzyme_df$bacillus, \n                 trace.label = \"Bacillus .sp\",\n                 response = enzyme_df$enzyme, fun = mean, \n                 type = \"b\", legend = TRUE, \n                 xlab = \"Substrate\", ylab =\"Enzyme activity (FU/mL)\",\n                 pch = c(15, 16, 8, 17, 19), \n                 col = c(\"red\", \"blue\", \"darkgreen\", \"purple\", \"yellow4\"))\n\n\n\n\n\n\n\n\n\n\n9.0.5 Bước 5: Phân tích ANOVA 2 yếu tố CRD\nTính p-value\n\n# Compute two-way ANOVA test\nres.aov2 &lt;- aov(enzyme ~ substrate + bacillus, data = enzyme_df)\n# summary(res.aov2)\nanova(res.aov2)\n\nAnalysis of Variance Table\n\nResponse: enzyme\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsubstrate  4 7083.7 1770.92  58.712 &lt; 2.2e-16 ***\nbacillus   3 1833.5  611.17  20.263 7.869e-09 ***\nResiduals 52 1568.5   30.16                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Compute two-way ANOVA test with interaction effect\nres.aov3 &lt;- aov(enzyme ~ substrate * bacillus, data = enzyme_df)\nanova(res.aov3)\n\nAnalysis of Variance Table\n\nResponse: enzyme\n                   Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsubstrate           4 7083.7 1770.92 816.050 &lt; 2.2e-16 ***\nbacillus            3 1833.5  611.17 281.632 &lt; 2.2e-16 ***\nsubstrate:bacillus 12 1481.7  123.47  56.896 &lt; 2.2e-16 ***\nResiduals          40   86.8    2.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPhân hạng\n\nlibrary(agricolae)\nLSD.test(res.aov2, c(\"substrate\", \"bacillus\"), console = TRUE) \n\n\nStudy: res.aov2 ~ c(\"substrate\", \"bacillus\")\n\nLSD t Test for enzyme \n\nMean Square Error:  30.16264 \n\nsubstrate:bacillus,  means and individual ( 95 %) CI\n\n                   enzyme       std r       se       LCL      UCL     Min     Max      Q25     Q50      Q75\nsubstrate_a:AB12 28.70833 3.2384490 3 3.170838 22.345581 35.07109 26.4125 32.4125 26.85625 27.3000 29.85625\nsubstrate_a:CD47 31.67083 1.2577468 3 3.170838 25.308081 38.03359 30.2250 32.5125 31.25000 32.2750 32.39375\nsubstrate_a:ER12 38.54167 2.1126972 3 3.170838 32.178914 44.90442 36.1750 40.2375 37.69375 39.2125 39.72500\nsubstrate_a:MS16 34.91667 1.3123413 3 3.170838 28.553914 41.27942 33.5375 36.1500 34.30000 35.0625 35.60625\nsubstrate_b:AB12 11.22083 2.0056301 3 3.170838  4.858081 17.58359  8.9500 12.7500 10.45625 11.9625 12.35625\nsubstrate_b:CD47 10.14583 0.2905634 3 3.170838  3.783081 16.50859  9.9250 10.4750  9.98125 10.0375 10.25625\nsubstrate_b:ER12 15.32083 0.6805711 3 3.170838  8.958081 21.68359 14.7250 16.0625 14.95000 15.1750 15.61875\nsubstrate_b:MS16 18.87917 2.4626058 3 3.170838 12.516414 25.24192 16.5250 21.4375 17.60000 18.6750 20.05625\nsubstrate_c:AB12 24.44583 1.3394456 3 3.170838 18.083081 30.80859 23.2000 25.8625 23.73750 24.2750 25.06875\nsubstrate_c:CD47 17.70000 2.1391806 3 3.170838 11.337248 24.06275 15.4625 19.7250 16.68750 17.9125 18.81875\nsubstrate_c:ER12 21.14167 0.8331354 3 3.170838 14.778914 27.50442 20.1875 21.7250 20.85000 21.5125 21.61875\nsubstrate_c:MS16 25.78333 0.7496180 3 3.170838 19.420581 32.14609 25.1875 26.6250 25.36250 25.5375 26.08125\nsubstrate_d:AB12 47.27500 1.1937991 3 3.170838 40.912248 53.63775 45.9125 48.1375 46.84375 47.7750 47.95625\nsubstrate_d:CD47 24.79167 0.7073645 3 3.170838 18.428914 31.15442 24.0625 25.4750 24.45000 24.8375 25.15625\nsubstrate_d:ER12 52.95417 0.3312697 3 3.170838 46.591414 59.31692 52.5750 53.1875 52.83750 53.1000 53.14375\nsubstrate_d:MS16 42.43750 1.7193294 3 3.170838 36.074748 48.80025 40.4625 43.6000 41.85625 43.2500 43.42500\nsubstrate_e:AB12 43.57083 1.1142776 3 3.170838 37.208081 49.93359 42.3875 44.6000 43.05625 43.7250 44.16250\nsubstrate_e:CD47 22.12083 0.5511824 3 3.170838 15.758081 28.48359 21.5500 22.6500 21.85625 22.1625 22.40625\nsubstrate_e:ER12 45.24167 0.4924958 3 3.170838 38.878914 51.60442 44.7000 45.6625 45.03125 45.3625 45.51250\nsubstrate_e:MS16 52.78750 0.3269174 3 3.170838 46.424748 59.15025 52.4125 53.0125 52.67500 52.9375 52.97500\n\nAlpha: 0.05 ; DF Error: 52\nCritical Value of t: 2.006647 \n\nleast Significant Difference: 8.998291 \n\nTreatments with the same letter are not significantly different.\n\n                   enzyme groups\nsubstrate_d:ER12 52.95417      a\nsubstrate_e:MS16 52.78750      a\nsubstrate_d:AB12 47.27500     ab\nsubstrate_e:ER12 45.24167     ab\nsubstrate_e:AB12 43.57083     bc\nsubstrate_d:MS16 42.43750     bc\nsubstrate_a:ER12 38.54167    bcd\nsubstrate_a:MS16 34.91667    cde\nsubstrate_a:CD47 31.67083    def\nsubstrate_a:AB12 28.70833    efg\nsubstrate_c:MS16 25.78333    fgh\nsubstrate_d:CD47 24.79167    fgh\nsubstrate_c:AB12 24.44583    fgh\nsubstrate_e:CD47 22.12083    ghi\nsubstrate_c:ER12 21.14167    ghi\nsubstrate_b:MS16 18.87917    hij\nsubstrate_c:CD47 17.70000    hij\nsubstrate_b:ER12 15.32083     ij\nsubstrate_b:AB12 11.22083      j\nsubstrate_b:CD47 10.14583      j\n\nduncan.test(res.aov2, c(\"substrate\", \"bacillus\"), console = TRUE) \n\n\nStudy: res.aov2 ~ c(\"substrate\", \"bacillus\")\n\nDuncan's new multiple range test\nfor enzyme \n\nMean Square Error:  30.16264 \n\nsubstrate:bacillus,  means\n\n                   enzyme       std r       se     Min     Max      Q25     Q50      Q75\nsubstrate_a:AB12 28.70833 3.2384490 3 3.170838 26.4125 32.4125 26.85625 27.3000 29.85625\nsubstrate_a:CD47 31.67083 1.2577468 3 3.170838 30.2250 32.5125 31.25000 32.2750 32.39375\nsubstrate_a:ER12 38.54167 2.1126972 3 3.170838 36.1750 40.2375 37.69375 39.2125 39.72500\nsubstrate_a:MS16 34.91667 1.3123413 3 3.170838 33.5375 36.1500 34.30000 35.0625 35.60625\nsubstrate_b:AB12 11.22083 2.0056301 3 3.170838  8.9500 12.7500 10.45625 11.9625 12.35625\nsubstrate_b:CD47 10.14583 0.2905634 3 3.170838  9.9250 10.4750  9.98125 10.0375 10.25625\nsubstrate_b:ER12 15.32083 0.6805711 3 3.170838 14.7250 16.0625 14.95000 15.1750 15.61875\nsubstrate_b:MS16 18.87917 2.4626058 3 3.170838 16.5250 21.4375 17.60000 18.6750 20.05625\nsubstrate_c:AB12 24.44583 1.3394456 3 3.170838 23.2000 25.8625 23.73750 24.2750 25.06875\nsubstrate_c:CD47 17.70000 2.1391806 3 3.170838 15.4625 19.7250 16.68750 17.9125 18.81875\nsubstrate_c:ER12 21.14167 0.8331354 3 3.170838 20.1875 21.7250 20.85000 21.5125 21.61875\nsubstrate_c:MS16 25.78333 0.7496180 3 3.170838 25.1875 26.6250 25.36250 25.5375 26.08125\nsubstrate_d:AB12 47.27500 1.1937991 3 3.170838 45.9125 48.1375 46.84375 47.7750 47.95625\nsubstrate_d:CD47 24.79167 0.7073645 3 3.170838 24.0625 25.4750 24.45000 24.8375 25.15625\nsubstrate_d:ER12 52.95417 0.3312697 3 3.170838 52.5750 53.1875 52.83750 53.1000 53.14375\nsubstrate_d:MS16 42.43750 1.7193294 3 3.170838 40.4625 43.6000 41.85625 43.2500 43.42500\nsubstrate_e:AB12 43.57083 1.1142776 3 3.170838 42.3875 44.6000 43.05625 43.7250 44.16250\nsubstrate_e:CD47 22.12083 0.5511824 3 3.170838 21.5500 22.6500 21.85625 22.1625 22.40625\nsubstrate_e:ER12 45.24167 0.4924958 3 3.170838 44.7000 45.6625 45.03125 45.3625 45.51250\nsubstrate_e:MS16 52.78750 0.3269174 3 3.170838 52.4125 53.0125 52.67500 52.9375 52.97500\n\nAlpha: 0.05 ; DF Error: 52 \n\nCritical Range\n        2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20 \n 8.998291  9.464564  9.771386  9.993980 10.164993 10.301439 10.413258 10.506735 10.586085 10.654261 10.713409 10.765131 10.810657 10.850946 10.886760 10.918716 10.947317 10.972979 10.996050 \n\nMeans with the same letter are not significantly different.\n\n                   enzyme groups\nsubstrate_d:ER12 52.95417      a\nsubstrate_e:MS16 52.78750      a\nsubstrate_d:AB12 47.27500     ab\nsubstrate_e:ER12 45.24167     ab\nsubstrate_e:AB12 43.57083    abc\nsubstrate_d:MS16 42.43750     bc\nsubstrate_a:ER12 38.54167    bcd\nsubstrate_a:MS16 34.91667    cde\nsubstrate_a:CD47 31.67083    def\nsubstrate_a:AB12 28.70833    efg\nsubstrate_c:MS16 25.78333   efgh\nsubstrate_d:CD47 24.79167   fghi\nsubstrate_c:AB12 24.44583   fghi\nsubstrate_e:CD47 22.12083   fghi\nsubstrate_c:ER12 21.14167   ghij\nsubstrate_b:MS16 18.87917  ghijk\nsubstrate_c:CD47 17.70000   hijk\nsubstrate_b:ER12 15.32083    ijk\nsubstrate_b:AB12 11.22083     jk\nsubstrate_b:CD47 10.14583      k\n\nHSD.test(res.aov2, c(\"substrate\", \"bacillus\"), console = TRUE) \n\n\nStudy: res.aov2 ~ c(\"substrate\", \"bacillus\")\n\nHSD Test for enzyme \n\nMean Square Error:  30.16264 \n\nsubstrate:bacillus,  means\n\n                   enzyme       std r       se     Min     Max      Q25     Q50      Q75\nsubstrate_a:AB12 28.70833 3.2384490 3 3.170838 26.4125 32.4125 26.85625 27.3000 29.85625\nsubstrate_a:CD47 31.67083 1.2577468 3 3.170838 30.2250 32.5125 31.25000 32.2750 32.39375\nsubstrate_a:ER12 38.54167 2.1126972 3 3.170838 36.1750 40.2375 37.69375 39.2125 39.72500\nsubstrate_a:MS16 34.91667 1.3123413 3 3.170838 33.5375 36.1500 34.30000 35.0625 35.60625\nsubstrate_b:AB12 11.22083 2.0056301 3 3.170838  8.9500 12.7500 10.45625 11.9625 12.35625\nsubstrate_b:CD47 10.14583 0.2905634 3 3.170838  9.9250 10.4750  9.98125 10.0375 10.25625\nsubstrate_b:ER12 15.32083 0.6805711 3 3.170838 14.7250 16.0625 14.95000 15.1750 15.61875\nsubstrate_b:MS16 18.87917 2.4626058 3 3.170838 16.5250 21.4375 17.60000 18.6750 20.05625\nsubstrate_c:AB12 24.44583 1.3394456 3 3.170838 23.2000 25.8625 23.73750 24.2750 25.06875\nsubstrate_c:CD47 17.70000 2.1391806 3 3.170838 15.4625 19.7250 16.68750 17.9125 18.81875\nsubstrate_c:ER12 21.14167 0.8331354 3 3.170838 20.1875 21.7250 20.85000 21.5125 21.61875\nsubstrate_c:MS16 25.78333 0.7496180 3 3.170838 25.1875 26.6250 25.36250 25.5375 26.08125\nsubstrate_d:AB12 47.27500 1.1937991 3 3.170838 45.9125 48.1375 46.84375 47.7750 47.95625\nsubstrate_d:CD47 24.79167 0.7073645 3 3.170838 24.0625 25.4750 24.45000 24.8375 25.15625\nsubstrate_d:ER12 52.95417 0.3312697 3 3.170838 52.5750 53.1875 52.83750 53.1000 53.14375\nsubstrate_d:MS16 42.43750 1.7193294 3 3.170838 40.4625 43.6000 41.85625 43.2500 43.42500\nsubstrate_e:AB12 43.57083 1.1142776 3 3.170838 42.3875 44.6000 43.05625 43.7250 44.16250\nsubstrate_e:CD47 22.12083 0.5511824 3 3.170838 21.5500 22.6500 21.85625 22.1625 22.40625\nsubstrate_e:ER12 45.24167 0.4924958 3 3.170838 44.7000 45.6625 45.03125 45.3625 45.51250\nsubstrate_e:MS16 52.78750 0.3269174 3 3.170838 52.4125 53.0125 52.67500 52.9375 52.97500\n\nAlpha: 0.05 ; DF Error: 52 \nCritical Value of Studentized Range: 5.276872 \n\nMinimun Significant Difference: 16.73211 \n\nTreatments with the same letter are not significantly different.\n\n                   enzyme groups\nsubstrate_d:ER12 52.95417      a\nsubstrate_e:MS16 52.78750      a\nsubstrate_d:AB12 47.27500     ab\nsubstrate_e:ER12 45.24167    abc\nsubstrate_e:AB12 43.57083    abc\nsubstrate_d:MS16 42.43750   abcd\nsubstrate_a:ER12 38.54167  abcde\nsubstrate_a:MS16 34.91667  bcdef\nsubstrate_a:CD47 31.67083 bcdefg\nsubstrate_a:AB12 28.70833  cdefg\nsubstrate_c:MS16 25.78333  defgh\nsubstrate_d:CD47 24.79167   efgh\nsubstrate_c:AB12 24.44583   efgh\nsubstrate_e:CD47 22.12083   efgh\nsubstrate_c:ER12 21.14167    fgh\nsubstrate_b:MS16 18.87917    fgh\nsubstrate_c:CD47 17.70000     gh\nsubstrate_b:ER12 15.32083     gh\nsubstrate_b:AB12 11.22083      h\nsubstrate_b:CD47 10.14583      h\n\n\n\n9.0.5.1 Tài liệu tham khảo\n\nhttps://statsandr.com/blog/two-way-anova-in-r/\nAnalysis of a Two-Factor Completely Randomized Design in R\nOutliers detection in R\nhttps://www.r-bloggers.com/2016/12/outlier-detection-and-treatment-with-r/\nhttps://stats.stackexchange.com/questions/61055/r-how-to-interpret-the-qqplots-outlier-numbers\nhttp://www.sthda.com/english/wiki/two-way-anova-test-in-r\nhttps://stackoverflow.com/questions/43123462/how-to-obtain-rmse-out-of-lm-result\nhttps://online.stat.psu.edu/stat501/lesson/2/2.6\nhttps://rcompanion.org/handbook/G_14.html\nRMSE (Root Mean Square Error) https://agronomy4future.org/?p=15930\nhttps://stats.stackexchange.com/questions/445200/coefficient-of-variation-for-beween-groups",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'><b>Phân tích ANOVA 2 yếu tố trong R</b></span>"
    ]
  },
  {
    "objectID": "so-sanh-ket-qua-giua-parametric-va-non-parametric-anova.html",
    "href": "so-sanh-ket-qua-giua-parametric-va-non-parametric-anova.html",
    "title": "10  So sánh kết quả giữa phân tích parametric và non-parametric ANOVA",
    "section": "",
    "text": "10.0.1 Bước 1: Đặt vấn đề\nKhi bộ dataset của bạn không thỏa các điều kiện cho ANOVA như ở link này thì bạn cần thực hiện phân tích non-parametric ANOVA.\nQuy trình chọn test thống kê phù hợp với đặc điểm dataset. Tham khảo mcelreath_2020_statistical_rethinking\n\nĐể làm rõ về quy trình phân tích theo hai hướng parametric (có các tham số như trung bình và phương sai của phân bố chuẩn) và non-parametric (không có các tham số cho phân bố chuẩn) ta sẽ xét cách làm trên cùng 1 bộ dataset.\nDataset minh họa: Dữ liệu đo khối lượng cây ở các nghiệm thức khác nhau.\nGiả thuyết:\n\n\\({H_0}\\) : Giữa các nghiệm thức không khác nhau về khối lượng cây\n\\({H_\\alpha }\\) : Giữa các nghiệm thức khác nhau về khối lượng cây\n\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix)\n\n### sửa lại dữ liệu từ dataset PlantGrowth để trở thành dữ liệu không có phân bố chuẩn.\nPlantGrowth -&gt; df\ndf[1, 1] &lt;- 6.39\ndf[2, 1] &lt;- 6.14\ndf[3, 1] &lt;- 7.39\ndf[4, 1] &lt;- 7.55\ndf[5, 1] &lt;- 9.32\ndf[6, 1] &lt;- 8.39\ndf[21, 1] &lt;- 1.39\ndf[22, 1] &lt;- 1.14\ndf[23, 1] &lt;- 1.39\ndf[24, 1] &lt;- 0.55\ndf[25, 1] &lt;- 1.32\ndf[12, 1] &lt;- 2.39\ndf[13, 1] &lt;- 1.14\ndf[14, 1] &lt;- 1.39\ndf[15, 1] &lt;- 0.55\ndf[16, 1] &lt;- 1.32\ndf\n\n   weight group\n1    6.39  ctrl\n2    6.14  ctrl\n3    7.39  ctrl\n4    7.55  ctrl\n5    9.32  ctrl\n6    8.39  ctrl\n7    5.17  ctrl\n8    4.53  ctrl\n9    5.33  ctrl\n10   5.14  ctrl\n11   4.81  trt1\n12   2.39  trt1\n13   1.14  trt1\n14   1.39  trt1\n15   0.55  trt1\n16   1.32  trt1\n17   6.03  trt1\n18   4.89  trt1\n19   4.32  trt1\n20   4.69  trt1\n21   1.39  trt2\n22   1.14  trt2\n23   1.39  trt2\n24   0.55  trt2\n25   1.32  trt2\n26   5.29  trt2\n27   4.92  trt2\n28   6.15  trt2\n29   5.80  trt2\n30   5.26  trt2\n\nsapply(df, class)\n\n   weight     group \n\"numeric\"  \"factor\" \n\ndf %&gt;%\n  group_by(group) %&gt;%\n  summarise(\n    count = n(),\n    mean = mean(weight, na.rm = TRUE),\n    sd = sd(weight, na.rm = TRUE),\n    median = median(weight, na.rm = TRUE),\n    IQR = IQR(weight, na.rm = TRUE)\n  )\n\n# A tibble: 3 × 6\n  group count  mean    sd median   IQR\n  &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 ctrl     10  6.54  1.58   6.26  2.3 \n2 trt1     10  3.15  1.99   3.36  3.44\n3 trt2     10  3.32  2.32   3.16  3.95\n\ndf %&gt;%\n  group_by(group) %&gt;%\n  ggpubr::get_summary_stats(weight, type = \"common\")\n\n# A tibble: 3 × 11\n  group variable     n   min   max median   iqr  mean    sd    se    ci\n  &lt;fct&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ctrl  weight      10  4.53  9.32   6.26  2.3   6.54  1.58 0.499  1.13\n2 trt1  weight      10  0.55  6.03   3.36  3.44  3.15  1.99 0.629  1.42\n3 trt2  weight      10  0.55  6.15   3.16  3.94  3.32  2.32 0.732  1.66\n\n\n\n\n10.0.2 Bước 2: Phân tích ANOVA 1 yếu tố cho trường hợp parametric\nTham khảo: https://www.statsmadeasy.com/tutorial-4-inferential-stats-test-of-difference/one-way-anova-parametric-non-parametric\nBước 2.1: Parametric One-Way ANOVA Assumptions\n\nIndependence: Your observations in each sample should be independent. \\(\\Rightarrow\\) OK\nIndependent Variable: This variable must have 3 or more outcomes. (mỗi chỉ tiêu cần đo lặp lại ít nhất 3 lần) \\(\\Rightarrow\\) OK\nRandom Sampling: Your data should be a random sample of the target population. \\(\\Rightarrow\\) OK\nEqual Variance (Homogeneity): Both groups should have approximately the same variance.\nNormality: Your Dependent variable should be approximately normally distributed.\n\nBước 2.2: Kiểm tra giả thuyết\n\n# Kiểm tra giả thuyết Normality\nres.aov &lt;- aov(weight ~ group, data = df)\naov_residuals &lt;- residuals(object = res.aov)\nshapiro.test(x = aov_residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  aov_residuals\nW = 0.88797, p-value = 0.00432\n\n\nKết quả Shapiro-Wilk normality test cho thấy p-value là 0.00432 nhỏ hơn 0.05. Do đó bộ dataset này KHÔNG phân bố chuẩn. \\(\\Rightarrow\\) VIOLATE\n\n# Kiểm tra giả thuyết Normality qua Q-Q plot\nmod &lt;- lm(weight ~ group, data = df)\n\nplot(mod, 2)\n\n\n\n\n\n\n\n\nNhìn đồ thị Q-Q lot ta thấy các giá trị không có phân bố chuẩn.\n\n# Kiểm tra giả thuyết Equal Variance (Homogeneity)\nlibrary(car)\nleveneTest(weight ~ group, data = df)  \n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  2  4.3203 0.02356 *\n      27                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nKết quả Levene’s test cho thấy p-value là 0.02356 nhỏ hơn 0.05. Do đó bộ dataset này có sự khác biệt về phương sai giữa các tổ hợp các mức khác nhau của 2 biến \\(\\Rightarrow\\) VIOLATE\nIt’s also possible to use Bartlett’s test or Levene’s test to check the homogeneity of variances.\nBước 2.3: Mô tả đặc điểm dữ liệu qua đồ thị\n\nlibrary(lattice)\nhistogram( ~ weight | group, data =df,\n           type = \"density\",\n           panel = function(x, ...) {\n             panel.histogram(x, ...)\n             panel.mathdensity(dmath = dnorm, col = \"black\",\n                               args = list(mean=mean(x),sd=sd(x)))\n           } )\n\n\n\n\n\n\n\n###\n\nggpubr::ggboxplot(df, x = \"group\", y = \"weight\")\n\n\n\n\n\n\n\nggpubr::ggline(df, x = \"group\", y = \"weight\", order = c(\"ctrl\", \"trt1\", \"trt2\"), add = c(\"mean_sd\", \"dotplot\"))\n\n\n\n\n\n\n\n###\n\ndf$group &lt;- reorder(df$group, df$weight, decreasing = FALSE) \nboxplot(weight ~ group, data = df, frame = TRUE,\n        horizontal = TRUE, las = 1,\n        axisnames = TRUE)\n\n\n\n\n\n\n\n\nBước 2.4: Thực hiện ANOVA 1 yếu tố\nCho dù đã vi phạm giả thuyết, nếu ta vẫn tiếp tục thực hiện ANOVA 1 yếu tố như bình thường thì kết quả sẽ như sau.\n\nres.aov &lt;- aov(weight ~ group, data = df)\nanova(res.aov)\n\nAnalysis of Variance Table\n\nResponse: weight\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ngroup      2  72.653  36.327  9.2271 0.0008834 ***\nResiduals 27 106.298   3.937                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nKết quả cho thấy p-value = 0.0008834 nhỏ hơn 0.05 nên có ý nghĩa thống kê, dù rằng dataset này đã vi phạm giả thuyết về phân bố chuẩn!\nTham khảo thêm:\nANOVA test with no assumption of equal variances\n\noneway.test(weight ~ group, data = df)\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  weight and group\nF = 11.087, num df = 2.000, denom df = 17.548, p-value = 0.0007708\n\n\nPairwise t-tests with no assumption of equal variances\n\npairwise.t.test(df$weight, df$group,\n                 p.adjust.method = \"BH\", pool.sd = FALSE)\n\n\n    Pairwise comparisons using t tests with non-pooled SD \n\ndata:  df$weight and df$group \n\n     trt1   trt2  \ntrt2 0.8638 -     \nctrl 0.0017 0.0034\n\nP value adjustment method: BH \n\n\nBước 2.5: Phân hạng trong trường hợp parametric\nCách 1: Sử dụng function trong base R\n\nTukeyHSD(res.aov) -&gt; tukey_yes\nplot(tukey_yes)\n\n\n\n\n\n\n\n\nCách 2: Sử dụng function trong package agricolae\n\nlibrary(agricolae)\nHSD.test(res.aov, \"group\", console = TRUE) -&gt; tukey_ok\n\n\nStudy: res.aov ~ \"group\"\n\nHSD Test for weight \n\nMean Square Error:  3.936961 \n\ngroup,  means\n\n     weight      std  r        se  Min  Max    Q25   Q50    Q75\nctrl  6.535 1.578215 10 0.6274521 4.53 9.32 5.2100 6.265 7.5100\ntrt1  3.153 1.990037 10 0.6274521 0.55 6.03 1.3375 3.355 4.7800\ntrt2  3.321 2.315141 10 0.6274521 0.55 6.15 1.3375 3.155 5.2825\n\nAlpha: 0.05 ; DF Error: 27 \nCritical Value of Studentized Range: 3.506426 \n\nMinimun Significant Difference: 2.200114 \n\nTreatments with the same letter are not significantly different.\n\n     weight groups\nctrl  6.535      a\ntrt2  3.321      b\ntrt1  3.153      b\n\nplot(tukey_ok)\n\n\n\n\n\n\n\n\nKết quả cho thấy vẫn thực hiện được phân hạng theo Tukey như bình thường, dù rằng dataset này đã vi phạm giả thuyết về phân bố chuẩn!\nCách 4: Sử dụng function trong package multcomp\n\nlibrary(multcomp)\nsummary(glht(res.aov, linfct = mcp(group = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = weight ~ group, data = df)\n\nLinear Hypotheses:\n                 Estimate Std. Error t value Pr(&gt;|t|)   \ntrt2 - trt1 == 0   0.1680     0.8874   0.189  0.98045   \nctrl - trt1 == 0   3.3820     0.8874   3.811  0.00197 **\nctrl - trt2 == 0   3.2140     0.8874   3.622  0.00335 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nCách 5: Thể hiện phân hạng qua đồ thị boxplot\nhttps://statsandr.com/blog/kruskal-wallis-test-nonparametric-version-anova/\n\nlibrary(dplyr)\nlibrary(ggstatsplot)\n\ndf$group &lt;- factor(df$group, levels = c(\"ctrl\", \"trt1\", \"trt2\"))\n\nggbetweenstats(\n  data = df,\n  x = group,\n  y = weight,\n  type = \"parametric\",\n  plot.type = \"box\",\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"significant\",\n  centrality.plotting = TRUE,\n  bf.message = TRUE\n) \n\n\n\n\n\n\n\n\n\n\n10.0.3 Bước 3: Phân tích ANOVA 1 yếu tố cho trường hợp non-parametric\nTham khảo: https://www.statsmadeasy.com/tutorial-4-inferential-stats-test-of-difference/one-way-anova-parametric-non-parametric\nBước 3.1: Non-parametric One-Way ANOVA Assumptions\n\nIndependence: Your observations in each sample should be independent. \\(\\Rightarrow\\) OK\nIndependent Variable: This variable must have 3 or more outcomes. (mỗi chỉ tiêu cần đo lặp lại ít nhất 3 lần) \\(\\Rightarrow\\) OK\nRandom Sampling: Your data should be a random sample of the target population. \\(\\Rightarrow\\) OK\n\nBước 3.2: Kiểm tra giả thuyết\nThực tế cả 3 giả thuyết cho non-parametric thì bộ dataset này đã đáp ứng đủ nên không cần làm bước này.\nBước 3.3: Thực hiện ANOVA 1 yếu tố non-parametric\n\n# kruskal.test(weight ~ group, data = df)\n\nres.kruskal &lt;- df %&gt;% rstatix::kruskal_test(weight ~ group)\nres.kruskal\n\n# A tibble: 1 × 6\n  .y.        n statistic    df       p method        \n* &lt;chr&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;         \n1 weight    30      11.9     2 0.00265 Kruskal-Wallis\n\n\nKết quả cho thấy p-value = 0.00265 nhỏ hơn 0.05 nên có ý nghĩa thống kê. Đây cũng trùng hợp với kết quả từ ANOVA parametric ở trên!\n\nVề lý thuyết, Kruskal-Wallis test có thể áp dụng cho two groups. Nhưng trong thực tế ta sẽ dùng the Mann-Whitney test for two groups and Kruskal-Wallis for three or more groups.\n\nBước 3.4: Tính effect size\nhttps://www.datanovia.com/en/lessons/kruskal-wallis-test-in-r/\n\nThe eta squared, based on the H-statistic, can be used as the measure of the Kruskal-Wallis test effect size. It is calculated as follow : eta2[H] = (H - k + 1)/(n - k); where H is the value obtained in the Kruskal-Wallis test; k is the number of groups; n is the total number of observations (M. T. Tomczak and Tomczak 2014).\n\n\nThe eta-squared estimate assumes values from 0 to 1 and multiplied by 100 indicates the percentage of variance in the dependent variable explained by the independent variable.\n\n\nThe interpretation values commonly in published literature are: 0.01- &lt; 0.06 (small effect), 0.06 - &lt; 0.14 (moderate effect) and &gt;= 0.14 (large effect).\n\n\ndf |&gt; rstatix::kruskal_effsize(weight ~ group)\n\n# A tibble: 1 × 5\n  .y.        n effsize method  magnitude\n* &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;ord&gt;    \n1 weight    30   0.365 eta2[H] large    \n\n\nÝ nghĩa của effect size\nhttps://lbecker.uccs.edu/glm_effectsize\nBước 3.5: Phân hạng trong trường hợp non-parametric\nLưu ý: Phân hạng theo parametric (Tukey’s test) thì ta căn cứ vào mean nên tính được diff mean (sự khác biệt giữa các trung bình) nên có thể phân ra theo từng hạng a, b, c, … còn phân hạng theo non-parametric ta căn cứ vào median nên chỉ phân hạng theo từng cặp, theo sign test +/- cho thấy sự khác biệt giữa các cặp nghiệm thức với nhau.\nCách 1: Pairwise comparisons using Dunn’s test (most common post-hoc test)\n\npwc &lt;- df %&gt;% rstatix::dunn_test(weight ~ group, p.adjust.method = \"bonferroni\") \npwc\n\n# A tibble: 3 × 9\n  .y.    group1 group2    n1    n2 statistic       p   p.adj p.adj.signif\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 weight ctrl   trt1      10    10    -3.24  0.00119 0.00357 **          \n2 weight ctrl   trt2      10    10    -2.63  0.00851 0.0255  *           \n3 weight trt1   trt2      10    10     0.610 0.542   1       ns          \n\n\nKết quả so sánh theo cặp theo Dunn’s test cho thấy cặp nghiệm thức trt1-trt2 không khác nhau về mặt ý nghĩa thống kê p-value là ns. Còn lại giữa 2 cặp nghiệm thức ctrl-trt1 và ctrl-trt2 khác biệt có ý nghĩa thống kê vì p-value nhỏ hơn 0.05.\nCách 2: Pairwise comparisons using Dunn’s test trong package FSA\n\nlibrary(FSA)\n\nFSA::dunnTest(weight ~ group,\n  data = df,\n  method = \"holm\"\n)\n\n   Comparison          Z     P.unadj       P.adj\n1 ctrl - trt1  3.2410278 0.001190996 0.003572987\n2 ctrl - trt2  2.6309520 0.008514606 0.017029212\n3 trt1 - trt2 -0.6100758 0.541811579 0.541811579\n\n# Note that there are other p-value adjustment methods. See ?dunnTest for more options\n\n\nIt is the last column (the adjusted p-values, adjusted for multiple comparisons) that is of interest. These p-values should be compared to your desired significance level (usually 5%).\n\n\nBased on the output, we conclude that:\n\n\nctrl and trt1 differ significantly (p &lt; 0.05)\n\n\nctrl and trt2 differ significantly (p &lt; 0.05)\n\n\ntrt1 and trt2 NOT differ significantly (p &gt; 0.05)\n\n\nTherefore, based on the Dunn’s test, we can now conclude that only ctrl-trt1 and ctrl-trt2 differ in terms of weight.\n\nCách 3: Pairwise comparisons using Wilcoxon’s test\n\npwc2 &lt;- df %&gt;% rstatix::wilcox_test(weight ~ group, p.adjust.method = \"bonferroni\")\npwc2\n\n# A tibble: 3 × 9\n  .y.    group1 group2    n1    n2 statistic        p p.adj p.adj.signif\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       \n1 weight ctrl   trt1      10    10      93   0.000487 0.001 **          \n2 weight ctrl   trt2      10    10      84   0.011    0.034 *           \n3 weight trt1   trt2      10    10      42.5 0.596    1     ns          \n\n\nKết quả so sánh theo cặp theo Wilcoxon’s test cho thấy cặp nghiệm thức trt1-trt2 không khác nhau về mặt ý nghĩa thống kê p-value là ns. Còn lại giữa 2 cặp nghiệm thức ctrl-trt1 và ctrl-trt2 khác biệt có ý nghĩa thống kê vì p-value nhỏ hơn 0.05.\nCách 3: Thể hiện phân hạng qua đồ thị boxplot\n\n## Dunn's test\n\npwc &lt;- pwc %&gt;% add_xy_position(x = \"group\")\n\nggboxplot(df, x = \"group\", y = \"weight\") +\n  stat_pvalue_manual(pwc, hide.ns = TRUE) +\n  labs(\n    subtitle = get_test_label(res.kruskal, detailed = TRUE),\n    caption = get_pwc_label(pwc)\n    )\n\n\n\n\n\n\n\n# Wilcoxon's test\npwc2 &lt;- pwc2 %&gt;% add_xy_position(x = \"group\")\n\nggboxplot(df, x = \"group\", y = \"weight\") +\n  stat_pvalue_manual(pwc2, hide.ns = TRUE) +\n  labs(\n    subtitle = get_test_label(res.kruskal, detailed = TRUE),\n    caption = get_pwc_label(pwc2)\n    )\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = df,\n  x = group,\n  y = weight,\n  type = \"nonparametric\",\n  plot.type = \"box\",\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"significant\",\n  centrality.plotting = TRUE,\n  bf.message = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n10.0.4 Tài liệu tham khảo\n\nhttps://bookdown.org/mike/data_analysis/nonparametric-anova.html\nhttps://jbhender.github.io/Stats506/F18/GP/Group3.html\nhttps://www.datanovia.com/en/lessons/kruskal-wallis-test-in-r/\nhttps://influentialpoints.com/Training/Kruskal-Wallis_ANOVA_use_and_misuse.htm#:~:text=The%20Kruskal%2DWallis%20one%2Dway,test%20of%20dominance%20between%20distributions.\nhttps://statsandr.com/blog/hypothesis-test-by-hand/",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'><b>So sánh kết quả giữa phân tích parametric và non-parametric ANOVA</b></span>"
    ]
  },
  {
    "objectID": "phan-tich-ancova-trong-r.html",
    "href": "phan-tich-ancova-trong-r.html",
    "title": "11  Phân tích ANCOVA trong R",
    "section": "",
    "text": "11.0.1 Phân biệt giữa ANCOVA và ANOVA\nPhân tích hiệp phương sai Analysis of Covariance (ANCOVA) là trường hợp mở rộng của phân tích phương sai Analysis of Variance (ANOVA) khi cho phép phân tích thêm biến C (continuous) tác động lên biến Y (continuous) để tìm ra sự khác biệt giữa các nhóm trong biến X (category).\nỨng dụng dễ thấy nhất là nếu thực hiện phân tích phương sai ANOVA 1 yếu tố thông thường, giữa các nhóm trong biến X tác động lên biến Y mà có p-value &gt; 0.05 chẳng hạn, tức là không thỏa điều kiện về ý nghĩa thống kê, thì ta có thể đánh giá thêm xem biến Y bản chất có bị ảnh hưởng bởi 1 biến C nào đó (ở dạng continuous) hay không, khi đó ta đưa biến C vào để hiệu chỉnh lại kết quả từ Y, rồi thực hiện phép phân tích ANCOVA để tìm ra p-value lúc này ở dạng kết quả hiệu chỉnh cho phép đánh giá chính xác hơn sự khác biệt giữa các nhóm trong biến X (category).\nANCOVA có hai loại one-way và two-way tương tự như ANOVA, tương ứng cho số lượng yếu tố X trong mô hình.\nCác giả định của ANCOVA\n\nLinearity between the covariate and the outcome variable at each level of the grouping variable. This can be checked by creating a grouped scatter plot of the covariate and the outcome variable.\nHomogeneity of regression slopes. The slopes of the regression lines, formed by the covariate and the outcome variable, should be the same for each group. This assumption evaluates that there is no interaction between the outcome and the covariate. The plotted regression lines by groups should be parallel.\nThe outcome variable should be approximately normally distributed. This can be checked using the Shapiro-Wilk test of normality on the model residuals.\nHomoscedasticity or homogeneity of residuals variance for all groups. The residuals are assumed to have a constant variance (homoscedasticity)\nNo significant outliers in the groups\n\n\n\n11.0.2 Case study cho one-way ANCOVA\n\nResearchers investigated the effect of exercises in reducing the level of anxiety. Therefore, they conducted an experiment, where they measured the anxiety score of three groups of individuals practicing physical exercises at different levels (grp1: low, grp2: moderate and grp3: high). The anxiety score was measured pre- and 6-months post-exercise training programs. It is expected that any reduction in the anxiety by the exercises programs would also depend on the participant’s basal level of anxiety score. In this analysis we use the pretest anxiety score as the covariate and are interested in possible differences between group with respect to the post-test anxiety scores.\n\nTạm dịch: Nghiên cứu này từ dataset anxiety của package datarium. Mục tiêu của nghiên cứu là khảo sát ảnh hưởng của việc tập thể dục lên khả năng giảm căng thẳng của sinh viên.\nTrong đó theo dõi 45 sinh viên, chia làm 3 nhóm (15 bạn/nhóm) ở 3 mức độ khác nhau về việc tập thể dục, ký hiệu tương ứng là grp1 tập thể dục ít, grp2 tập thể dục trung bình, grp3 tập thể dục nhiều. Sau đó các nhà nghiên cứu đo điểm căng thẳng của từng bạn sinh viên xem như thế nào ở 6 tháng trước khi bắt đầu tập thể dục (pretest) và 6 tháng sau khi tập thể dụng (postest).\nCâu hỏi đặt ra là: kết quả của việc tập thể dục theo các cường độ khác nhau như vậy (ít, vừa, nhiều) có làm giảm căng thẳng hay không?\nNếu bình thường chỉ phân tích ANOVA thì ta chỉ lấy biến postest là biến y để làm cơ sở đưa vào phân tích one-way ANOVA với yếu tố là mức độ tập thể dục. Tuy nhiên rõ ràng giữa các bạn sinh viên này thì trước khi tham gia chương trình tập thể dục này các bạn đã có mức độ căng thẳng khác nhau rồi (đo thông qua pretest) nên nếu chúng ta không hiệu chỉnh giá trị này thì kết quả thu được từ phân tích phương sai sẽ bị ảnh hưởng (lỡ nhóm tập thể dục nhiều, theo lý thuyết sẽ giảm căng thẳng, nhưng vì các bạn sinh viên chọn ngẫu nhiên trong nhóm này có sự căng thẳng nền trước đó dẫn đến cho dù có tập thể dục nhiều thì điểm căng thẳng cũng không giảm). Đây là lý do vì sao chúng ta cần đưa covariate (gọi là hiệp biến) ở đây là yếu tố căng thẳng nền vào, hoặc có thể đưa thêm yếu tố độ tuổi vào cũng được, nghĩa là covariate có thể từ 1 trở lên để tác động đến biến y sau cùng, giúp điều chỉnh kết quả của y (postest) tương ứng với từng nhóm trong biến x (mức độ tập thể dục) được chính xác hơn.\nDữ liệu cụ thể\n\nanxiety &lt;- read.csv(\"ancova_example_1.csv\")\n\nanxiety \n\n   id group pretest posttest\n1   1  grp1    14.1     14.1\n2   2  grp1    14.5     14.3\n3   3  grp1    15.7     14.9\n4   4  grp1    16.0     15.3\n5   5  grp1    16.5     15.7\n6   6  grp1    16.9     16.2\n7   7  grp1    17.0     16.5\n8   8  grp1    17.0     16.6\n9   9  grp1    17.3     16.5\n10 10  grp1    17.3     16.7\n11 11  grp1    17.8     17.3\n12 12  grp1    17.9     17.5\n13 13  grp1    19.1     19.3\n14 14  grp1    19.4     19.0\n15 15  grp1    19.8     19.4\n16 16  grp2    13.7     12.7\n17 17  grp2    14.7     13.1\n18 18  grp2    14.9     13.6\n19 19  grp2    15.1     13.6\n20 20  grp2    15.8     14.2\n21 21  grp2    16.4     14.9\n22 22  grp2    16.6     16.1\n23 23  grp2    16.9     16.1\n24 24  grp2    16.9     16.3\n25 25  grp2    17.2     15.9\n26 26  grp2    17.8     17.4\n27 27  grp2    17.8     16.9\n28 28  grp2    18.2     17.1\n29 29  grp2    18.4     17.3\n30 30  grp2    19.3     17.7\n31 31  grp3    14.6     11.7\n32 32  grp3    15.0     11.9\n33 33  grp3    15.5     11.0\n34 34  grp3    15.7     12.1\n35 35  grp3    16.4     12.3\n36 36  grp3    16.9     13.6\n37 37  grp3    17.1     14.3\n38 38  grp3    17.3     14.2\n39 39  grp3    17.5     14.4\n40 40  grp3    17.6     13.8\n41 41  grp3    17.8     14.3\n42 42  grp3    17.9     13.8\n43 43  grp3    18.4     15.4\n44 44  grp3    18.5     15.1\n45 45  grp3    19.0     15.5\n\n\n\n\n11.0.3 Kiểm tra giả thuyết thống kê\n\n11.0.3.1 1. Linearity assumption\nThere was a linear relationship between pre-test and post-test anxiety score for each training group, as assessed by visual inspection of a scatter plot.\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(broom)\n\nggscatter(data = anxiety, x = \"pretest\", y = \"posttest\", color = \"group\", add = \"reg.line\") +\n  stat_regline_equation(\n    aes(label =  paste(..eq.label.., ..rr.label.., sep = \"~~~~~~~~~~\"),\n        color = group),\n    show.legend = NULL\n    )\n\n\n\n\n\n\n\n\n\n\n11.0.3.2 2. Homogeneity of regression slopes\nThis assumption checks that there is no significant interaction between the covariate and the grouping variable.\nThere was homogeneity of regression slopes as the interaction term was not statistically significant, F(2, 39) = 0.13, p = 0.88.\n\nanxiety %&gt;% anova_test(posttest ~ group*pretest)\n\nANOVA Table (type II tests)\n\n         Effect DFn DFd       F        p p&lt;.05   ges\n1         group   2  39 209.314 1.40e-21     * 0.915\n2       pretest   1  39 572.828 6.36e-25     * 0.936\n3 group:pretest   2  39   0.127 8.81e-01       0.006\n\n\n\n\n11.0.3.3 3. Normality of residuals\n\n# Fit the model, the covariate goes first\nmodel &lt;- lm(posttest ~ pretest + group, data = anxiety)\n\n# Inspect the model diagnostic metrics\nmodel.metrics &lt;- augment(model)[, c(1, 2, 3, 5, 8, 9)]\n\nmodel.metrics &lt;- as.data.frame(model.metrics)\n\nmodel.metrics\n\n   posttest pretest group       .resid      .cooksd   .std.resid\n1      14.1    14.1  grp1  0.549556955 1.008643e-01  1.457068239\n2      14.3    14.5  grp1  0.338455577 3.095139e-02  0.885202791\n3      14.9    15.7  grp1 -0.294848556 1.334801e-02 -0.749866153\n4      15.3    16.0  grp1 -0.203174590 5.675944e-03 -0.514543486\n5      15.7    16.5  grp1 -0.317051312 1.206505e-02 -0.799162006\n6      16.2    16.9  grp1 -0.228152690 5.919695e-03 -0.574088378\n7      16.5    17.0  grp1 -0.030928035 1.082522e-04 -0.077810670\n8      16.6    17.0  grp1  0.069071965 5.399278e-04  0.173775537\n9      16.5    17.3  grp1 -0.339254068 1.311360e-02 -0.853697710\n10     16.7    17.3  grp1 -0.139254068 2.209467e-03 -0.350418434\n11     17.3    17.8  grp1 -0.053130791 3.483819e-04 -0.134045731\n12     17.5    17.9  grp1  0.044093865 2.461007e-04  0.111341667\n13     19.3    19.1  grp1  0.610789731 7.558967e-02  1.572623744\n14     19.0    19.4  grp1  0.002463698 1.425655e-06  0.006392114\n15     19.4    19.8  grp1 -0.008637680 2.154133e-05 -0.022683279\n16     12.7    13.7  grp2  0.201780151 1.330855e-02  0.534203822\n17     13.1    14.7  grp2 -0.425973294 3.561620e-02 -1.095079357\n18     13.6    14.9  grp2 -0.131523983 3.095512e-03 -0.336670267\n19     13.6    15.1  grp2 -0.337074672 1.862872e-02 -0.859563007\n20     14.2    15.8  grp2 -0.456502083 2.661806e-02 -1.153075147\n21     14.9    16.4  grp2 -0.373154150 1.590854e-02 -0.939084242\n22     16.1    16.6  grp2  0.621295161 4.364296e-02  1.563046354\n23     16.1    16.9  grp2  0.312969127 1.119730e-02  0.787636564\n24     16.3    16.9  grp2  0.512969127 3.008104e-02  1.290968359\n25     15.9    17.2  grp2 -0.195356906 4.550936e-03 -0.492313232\n26     17.4    17.8  grp2  0.687991027 6.659086e-02  1.743825167\n27     16.9    17.8  grp2  0.187991027 4.971911e-03  0.476493837\n28     17.1    18.2  grp2 -0.023110351 8.781534e-05 -0.058939936\n29     17.3    18.4  grp2 -0.028661040 1.474391e-04 -0.073375382\n30     17.7    19.3  grp2 -0.553639140 8.575232e-02 -1.451061685\n31     11.7    14.6  grp3  0.620311647 9.507982e-02  1.613950448\n32     11.9    15.0  grp3  0.409210269 3.392908e-02  1.053609373\n33     11.0    15.5  grp3 -1.004666453 1.631872e-01 -2.560468115\n34     12.1    15.7  grp3 -0.110217142 1.812547e-03 -0.279990633\n35     12.3    16.4  grp3 -0.629644554 4.784434e-02 -1.587371864\n36     13.6    16.9  grp3  0.156478724 2.773679e-03  0.393690617\n37     14.3    17.1  grp3  0.650928035 4.795104e-02  1.637645152\n38     14.2    17.3  grp3  0.345377346 1.367987e-02  0.869284480\n39     14.4    17.5  grp3  0.339826657 1.360708e-02  0.856054572\n40     13.8    17.6  grp3 -0.362948688 1.581104e-02 -0.914851288\n41     14.3    17.8  grp3 -0.068499377 5.897635e-04 -0.172926642\n42     13.8    17.9  grp3 -0.671274721 5.820829e-02 -1.696230176\n43     15.4    18.4  grp3  0.414848556 2.642395e-02  1.055053126\n44     15.1    18.5  grp3  0.012073212 2.330621e-05  0.030755387\n45     15.5    19.0  grp3 -0.101803510 2.073307e-03 -0.261953948\n\n# Assess normality of residuals using shapiro wilk test\nshapiro_test(model.metrics$.resid)\n\n# A tibble: 1 × 3\n  variable             statistic p.value\n  &lt;chr&gt;                    &lt;dbl&gt;   &lt;dbl&gt;\n1 model.metrics$.resid     0.975   0.444\n\n\nThe Shapiro Wilk test was not significant (p &gt; 0.05), so we can assume normality of residuals.\n\n\n11.0.3.4 4. Homogeneity of variances\nANCOVA assumes that the variance of the residuals is equal for all groups. This can be checked using the Levene’s test.\nThe Levene’s test was not significant (p &gt; 0.05), so we can assume homogeneity of the residual variances for all groups.\n\nmodel.metrics %&gt;% levene_test(.resid ~ group)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to factor.\n\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     2    42      2.27 0.116\n\n\n\n\n11.0.3.5 5. Outliers\nThere were no outliers in the data, as assessed by no cases with standardized residuals greater than 3 in absolute value.\n\nmodel.metrics %&gt;% \n  filter(abs(.std.resid) &gt; 3) %&gt;%\n  as.data.frame()\n\n[1] posttest   pretest    group      .resid     .cooksd    .std.resid\n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\n\n\n11.0.4 Tính toán ANCOVA\nSau khi dataset đã thỏa các điều kiện để thực hiện ANCOVA, giờ ta đưa vào model để tính ra kết quả.\nAfter adjustment for pre-test anxiety score, there was a statistically significant difference in post-test anxiety score between the groups, F(2, 41) = 218.63, p &lt; 0.0001.\n\nres.aov &lt;- anxiety %&gt;% anova_test(posttest ~ pretest + group) # pretest là covariate phải đặt phía trước.\nget_anova_table(res.aov)\n\nANOVA Table (type II tests)\n\n   Effect DFn DFd       F        p p&lt;.05   ges\n1 pretest   1  41 598.321 4.48e-26     * 0.936\n2   group   2  41 218.629 1.35e-22     * 0.914\n\n\nThực hiện phân hạng Post-hoc test\nPairwise comparisons can be performed to identify which groups are different. The Bonferroni multiple testing correction is applied.\n\n# Pairwise comparisons\nlibrary(emmeans)\n\nWarning: package 'emmeans' was built under R version 4.3.3\n\npwc &lt;- anxiety %&gt;% \n  emmeans_test(\n    posttest ~ group, covariate = pretest,\n    p.adjust.method = \"bonferroni\"\n  )\npwc\n\n# A tibble: 3 × 9\n  term          .y.      group1 group2    df statistic        p    p.adj p.adj.signif\n* &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 pretest*group posttest grp1   grp2      41      4.24 1.26e- 4 3.77e- 4 ***         \n2 pretest*group posttest grp1   grp3      41     19.9  1.19e-22 3.58e-22 ****        \n3 pretest*group posttest grp2   grp3      41     15.5  9.21e-19 2.76e-18 ****        \n\n# Display the adjusted means of each group\n# Also called as the estimated marginal means (emmeans)\nget_emmeans(pwc)\n\n# A tibble: 3 × 8\n  pretest group emmean    se    df conf.low conf.high method      \n    &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       \n1    16.9 grp1    16.4 0.106    41     16.2      16.7 Emmeans test\n2    16.9 grp2    15.8 0.107    41     15.6      16.0 Emmeans test\n3    16.9 grp3    13.5 0.106    41     13.2      13.7 Emmeans test\n\n\n\n\n11.0.5 Trình bày kết quả\nAn ANCOVA was run to determine the effect of exercises on the anxiety score after controlling for basal anxiety score of participants.\nAfter adjustment for pre-test anxiety score, there was a statistically significant difference in post-test anxiety score between the groups, F(2, 41) = 218.63, p &lt; 0.0001.\nPost hoc analysis was performed with a Bonferroni adjustment. The mean anxiety score was statistically significantly greater in grp1 (16.4 +/- 0.15) compared to the grp2 (15.8 +/- 0.12) and grp3 (13.5 +/_ 0.11), p &lt; 0.001.\nTạm dịch: Sau khi thực hiện phép phân tích ANCOVA với việc hiệu chỉnh biến pretest thì ta thấy kết quả tập thể dục của các nhóm thật sự khác biệt nhau, trong đó nhóm tập thể dục nhiều (grp3) có chỉ số căng thẳng thấp nhất.\n\n# Visualization: line plots with p-values\npwc &lt;- pwc %&gt;% add_xy_position(x = \"group\", fun = \"mean_se\")\n\nggline(get_emmeans(pwc), x = \"group\", y = \"emmean\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) + \n  stat_pvalue_manual(pwc, hide.ns = TRUE, tip.length = FALSE) +\n  labs(\n    subtitle = get_test_label(res.aov, detailed = TRUE),\n    caption = get_pwc_label(pwc)\n  )\n\n\n\n\n\n\n\n\n\n11.0.5.1 Tài liệu tham khảo\n\nThe R Book - 2013\nLearning Statistics Concepts and Applications in R\nANCOVA in R\nStatistics PL 17 ANCOVA",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'><b>Phân tích ANCOVA trong R</b></span>"
    ]
  },
  {
    "objectID": "quy-trinh-phan-tich-logistic-regression.html",
    "href": "quy-trinh-phan-tich-logistic-regression.html",
    "title": "13  Quy trình phân tích logistic regression",
    "section": "",
    "text": "13.1 Example dataset\nSử dụng ví dụ ở chapter 10 trong cuốn sách này.\nhttps://studyr.netlify.app/ref/introductory_biostatistics_2016.pdf\ncancer &lt;- read.csv(\"prostatecancer.dat\", sep = \"&\")\ncancer\n\n   Xray Grade Stage Age Acid Nodes\n1     0     1     1  64   40     0\n2     0     0     1  63   40     0\n3     1     0     0  65   46     0\n4     0     1     0  67   47     0\n5     0     0     0  66   48     0\n6     0     1     1  65   48     0\n7     0     0     0  60   49     0\n8     0     0     0  51   49     0\n9     0     0     0  66   50     0\n10    0     0     0  58   50     0\n11    0     1     0  56   50     0\n12    0     0     1  61   50     0\n13    0     1     1  64   50     0\n14    0     0     0  56   52     0\n15    0     0     0  67   52     0\n16    1     0     0  49   55     0\n17    0     1     1  52   55     0\n18    0     0     0  68   56     0\n19    0     1     1  66   59     0\n20    1     0     0  60   62     0\n21    0     0     0  61   62     0\n22    1     1     1  59   63     0\n23    0     0     0  51   65     0\n24    0     1     1  53   66     0\n25    0     0     0  58   71     0\n26    0     0     0  63   75     0\n27    0     0     1  53   76     0\n28    0     0     0  60   78     0\n29    0     0     0  52   83     0\n30    0     0     1  67   95     0\n31    0     0     0  56   98     0\n32    0     0     1  61  102     0\n33    0     0     0  64  187     0\n34    1     0     1  58   48     1\n35    0     0     1  65   49     1\n36    1     1     1  57   51     1\n37    0     1     0  50   56     1\n38    1     1     0  67   67     1\n39    0     0     1  67   67     1\n40    0     1     1  57   67     1\n41    0     1     1  45   70     1\n42    0     0     1  46   70     1\n43    1     0     1  51   72     1\n44    1     1     1  60   76     1\n45    1     1     1  56   78     1\n46    1     1     1  50   81     1\n47    0     0     0  56   82     1\n48    0     0     1  63   82     1\n49    1     1     1  65   84     1\n50    1     0     1  64   89     1\n51    0     1     0  59   99     1\n52    1     1     1  68  126     1\n53    1     0     0  61  136     1",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'><b>Quy trình phân tích logistic regression</b></span>"
    ]
  },
  {
    "objectID": "quy-trinh-phan-tich-logistic-regression.html#logistic-regression-model",
    "href": "quy-trinh-phan-tich-logistic-regression.html#logistic-regression-model",
    "title": "13  Quy trình phân tích logistic regression",
    "section": "13.2 Logistic Regression Model",
    "text": "13.2 Logistic Regression Model\nEffect of Measurement Scale\n\nacid.glm &lt;- glm(Nodes ~ Acid, \n                data = cancer, \n                family = binomial(link = \"logit\"))\n# acid.glm\n\nsummary(acid.glm)\n\n\nCall:\nglm(formula = Nodes ~ Acid, family = binomial(link = \"logit\"), \n    data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -1.92703    0.92104  -2.092   0.0364 *\nAcid         0.02040    0.01257   1.624   0.1045  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 70.252  on 52  degrees of freedom\nResidual deviance: 67.116  on 51  degrees of freedom\nAIC: 71.116\n\nNumber of Fisher Scoring iterations: 4\n\nor.50acid &lt;- exp((100-50)*acid.glm$coefficients[2])\n\nor.50acid\n\n    Acid \n2.773301 \n\n\nTesting Hypotheses in Multiple Logistic Regression\n\nall.glm &lt;- glm(Nodes ~ Xray + Grade + Stage + Age + Acid, \n              data = cancer,\n              family = binomial(link = \"logit\"))\n\nsummary(all.glm)\n\n\nCall:\nglm(formula = Nodes ~ Xray + Grade + Stage + Age + Acid, family = binomial(link = \"logit\"), \n    data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  0.06180    3.45992   0.018   0.9857  \nXray         2.04534    0.80718   2.534   0.0113 *\nGrade        0.76142    0.77077   0.988   0.3232  \nStage        1.56410    0.77401   2.021   0.0433 *\nAge         -0.06926    0.05788  -1.197   0.2314  \nAcid         0.02434    0.01316   1.850   0.0643 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 70.252  on 52  degrees of freedom\nResidual deviance: 48.126  on 47  degrees of freedom\nAIC: 60.126\n\nNumber of Fisher Scoring iterations: 5\n\nchisq.LR &lt;- all.glm$null.deviance - all.glm$deviance\n\nchisq.LR\n\n[1] 22.12636\n\ndf.LR &lt;- all.glm$df.null - all.glm$df.residual\n\ndf.LR\n\n[1] 5\n\n1-pchisq(chisq.LR,df.LR)\n\n[1] 0.000495414\n\n\nStepwise\n\nlibrary(MASS)\nMASS::stepAIC(all.glm)\n\nStart:  AIC=60.13\nNodes ~ Xray + Grade + Stage + Age + Acid\n\n        Df Deviance    AIC\n- Grade  1   49.097 59.097\n- Age    1   49.615 59.615\n&lt;none&gt;       48.126 60.126\n- Acid   1   51.572 61.572\n- Stage  1   52.558 62.558\n- Xray   1   55.350 65.350\n\nStep:  AIC=59.1\nNodes ~ Xray + Stage + Age + Acid\n\n        Df Deviance    AIC\n- Age    1   50.660 58.660\n&lt;none&gt;       49.097 59.097\n- Acid   1   52.085 60.085\n- Stage  1   55.381 63.381\n- Xray   1   57.016 65.016\n\nStep:  AIC=58.66\nNodes ~ Xray + Stage + Acid\n\n        Df Deviance    AIC\n&lt;none&gt;       50.660 58.660\n- Acid   1   53.353 59.353\n- Stage  1   57.059 63.059\n- Xray   1   58.613 64.613\n\n\n\nCall:  glm(formula = Nodes ~ Xray + Stage + Acid, family = binomial(link = \"logit\"), \n    data = cancer)\n\nCoefficients:\n(Intercept)         Xray        Stage         Acid  \n   -3.57565      2.06179      1.75556      0.02063  \n\nDegrees of Freedom: 52 Total (i.e. Null);  49 Residual\nNull Deviance:      70.25 \nResidual Deviance: 50.66    AIC: 58.66\n\n\nROC curve\n\nlibrary(epiDisplay)\n\nLoading required package: foreign\n\n\nLoading required package: survival\n\n\n\nAttaching package: 'survival'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    cancer\n\n\nLoading required package: nnet\n\nall.glm.roc &lt;- lroc(all.glm, title = TRUE, auc.coords = c(0.5, 0.1))\n\n\n\n\n\n\n\nall.glm.roc\n\n$model.description\n[1] \"Nodes ~ Xray + Grade + Stage + Age + Acid\"\n\n$auc\n[1] 0.8454545\n\n$predicted.table\n predicted.prob Non-diseased Diseased\n         0.0341            1        0\n         0.0351            1        0\n         0.0358            1        0\n         0.0361            1        0\n         0.0521            1        0\n         0.0607            1        0\n         0.0645            1        0\n         0.0657            1        0\n         0.0723            1        0\n         0.0775            1        0\n         0.0929            1        0\n         0.0973            1        0\n         0.1002            1        0\n         0.1314            1        0\n         0.1372            1        0\n         0.1393            0        1\n         0.1463            1        0\n         0.1566            0        1\n         0.1795            1        0\n         0.1929            1        0\n         0.2004            0        1\n         0.2007            1        0\n         0.2181            0        1\n         0.2184            1        0\n         0.2551            1        0\n         0.2796            1        0\n         0.2988            0        1\n         0.3040            1        0\n         0.3213            1        0\n         0.3227            0        1\n         0.3314            1        0\n         0.3684            1        0\n         0.4514            1        0\n         0.4648            0        1\n         0.4710            1        0\n         0.5130            1        0\n         0.5176            0        1\n         0.5311            1        0\n         0.5359            0        1\n         0.5452            1        0\n         0.5801            1        0\n         0.6948            0        1\n         0.7260            0        1\n         0.7673            0        1\n         0.8030            0        1\n         0.8489            0        1\n         0.8676            1        0\n         0.8689            0        1\n         0.8782            0        1\n         0.8935            0        1\n         0.9207            0        1\n         0.9421            0        1\n         0.9498            0        1\n\n$diagnostic.table\n   1-Specificity Sensitivity\n      1.00000000        1.00\n&gt;     0.96969697        1.00\n&gt;     0.93939394        1.00\n&gt;     0.90909091        1.00\n&gt;     0.87878788        1.00\n&gt;     0.84848485        1.00\n&gt;     0.81818182        1.00\n&gt;     0.78787879        1.00\n&gt;     0.75757576        1.00\n&gt;     0.72727273        1.00\n&gt;     0.69696970        1.00\n&gt;     0.66666667        1.00\n&gt;     0.63636364        1.00\n&gt;     0.60606061        1.00\n&gt;     0.57575758        1.00\n&gt;     0.54545455        1.00\n&gt;     0.54545455        0.95\n&gt;     0.51515152        0.95\n&gt;     0.51515152        0.90\n&gt;     0.48484848        0.90\n&gt;     0.45454545        0.90\n&gt;     0.45454545        0.85\n&gt;     0.42424242        0.85\n&gt;     0.42424242        0.80\n&gt;     0.39393939        0.80\n&gt;     0.36363636        0.80\n&gt;     0.33333333        0.80\n&gt;     0.33333333        0.75\n&gt;     0.30303030        0.75\n&gt;     0.27272727        0.75\n&gt;     0.27272727        0.70\n&gt;     0.24242424        0.70\n&gt;     0.21212121        0.70\n&gt;     0.18181818        0.70\n&gt;     0.18181818        0.65\n&gt;     0.15151515        0.65\n&gt;     0.12121212        0.65\n&gt;     0.12121212        0.60\n&gt;     0.09090909        0.60\n&gt;     0.09090909        0.55\n&gt;     0.06060606        0.55\n&gt;     0.03030303        0.55\n&gt;     0.03030303        0.50\n&gt;     0.03030303        0.45\n&gt;     0.03030303        0.40\n&gt;     0.03030303        0.35\n&gt;     0.03030303        0.30\n&gt;     0.00000000        0.30\n&gt;     0.00000000        0.25\n&gt;     0.00000000        0.20\n&gt;     0.00000000        0.15\n&gt;     0.00000000        0.10\n&gt;     0.00000000        0.05\n&gt;     0.00000000        0.00",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'><b>Quy trình phân tích logistic regression</b></span>"
    ]
  },
  {
    "objectID": "khai-niem-bootstrap-qua-vi-du-tinh-trung-binh-mau.html",
    "href": "khai-niem-bootstrap-qua-vi-du-tinh-trung-binh-mau.html",
    "title": "14  Khái niệm về bootstrap qua ví dụ tính trung bình mẫu",
    "section": "",
    "text": "14.0.1 Định nghĩa: What is bootstrap?\nBootstrap is a resampling method where large numbers of samples of the same size are repeatedly drawn, with replacement, from a single original sample.\nThe basic bootstrapping procedure is as follows:\n\nTake k repeated replacement samples from a given dataset.\nCalculate the statistic of interest for each sample.\nThese yields k different estimates for a given statistic, which you can then use to calculate the statistic’s standard error and create a confidence interval.\n\nTạm dịch: Bootstrap là phương pháp tái lấy mẫu (cho phép lấy trùng) từ 1 mẫu gốc để tạo ra rất nhiều mẫu giả lập nhằm tính toán giá trị thống kê mà bạn quan tâm (ví dụ trung bình), rồi từ đó ta sẽ tính khoảng tin cậy hay sai số chuẩn trên các kết quả trung bình giả lập trong ý tưởng phân phối của dữ liệu mẫu lớn này sẽ là phân phối chuẩn (Law of large numbers).\n\n\n14.0.2 Bước 1: Mô tả ví dụ minh họa\nĐể hiểu khái niệm bootstrap một cách cơ bản nhất, ta sẽ xét qua ví dụ đo cân nặng của một đối tượng nghiên cứu nào đó rồi tính ra khoảng tin cậy. https://thongkesinhhoc.quarto.pub/khoang-tin-cay.html\nVí dụ một nhà nghiên cứu muốn biết cân nặng trung bình của người dân ở một tỉnh nào đó, thì thông thường ta có thể cân toàn bộ người dân trong tỉnh đó (với số dân khoảng 400000 người) sau đó cộng lại lấy trung bình, ta sẽ có được trung bình quần thể \\(\\mu\\) là con số chính xác tuyệt đối đại diện cho trung bình của toàn bộ người dân ở tỉnh đó.\nTuy nhiên vì không có kinh phí để đo đạc cùng lúc số lượng người lớn như vậy, mà nếu đo theo kiểu lần lượt thì cân nặng của dân số sẽ thay đổi (người đo đầu tiên với người đo thứ 1000 thì cân nặng của người đo đầu tiên đã khác ở thời điểm đó rồi) nên ngay cả cách tiếp cận đo khối lượng tổng thể dân số thì kết quả cũng không chính xác nếu việc đo khối lượng không diễn ra cùng một lúc.\nNhư vậy, nếu ta chỉ có thể đo một vài người dân trong tỉnh đó (tất nhiên sẽ phải lấy mẫu ngẫu nhiên) rồi tìm cách resampling hay là tái lấy mẫu trên chính số liệu của lần đo thực này thì ta sẽ có rất nhiều mẫu giả lập/simulation để tính ra khoảng tin cậy mà nếu lấy mẫu ở lần tiếp theo thì giá trị trung bình của mẫu đó sẽ dao động trong khoảng này.\n\nset.seed(123)\n\n## Giả sử ta đo 10  người\n\ncan_nang &lt;- c(60, 55, 71, 45, 89, 56, 73, 49, 69, 88)\n\n\n## Kết quả trung bình từ mẫu quan sát\n\nmean_mau_quan_sat &lt;- mean(can_nang)\n\nmean_mau_quan_sat\n\n[1] 65.5\n\n\nThực hiện bootstrap với 1000 lần lặp lại cho sample size là 10 cá thể\n\nsample_size &lt;- length(can_nang)\n\nn_boot &lt;- 1000 # số lần sẽ resampling với replacement là TRUE\n\ndata_boot &lt;- data.frame() # lưu kết quả tái lấy mẫu này trong data frame\n\nfor (i in 1:n_boot)\n{\n               cach_lay_mau &lt;- sample(1:length(can_nang), replace = TRUE)\n               \n               data_boot &lt;- rbind(data_boot, can_nang[cach_lay_mau])\n}\n\ncolnames(data_boot) &lt;- paste(\"Người thứ\", 1:length(can_nang)) \nrownames(data_boot) &lt;- paste(\"Lần lấy mẫu giả lập thứ\", 1:n_boot)\n\napply(X = data_boot, MARGIN = 1, FUN = mean) -&gt; ket_qua_trung_binh\n\ndata_boot$`Kết quả trung bình` &lt;- ket_qua_trung_binh\n\n# write.table(x = data_boot, file = \"data_boot.tsv\", \n#             row.names = F, sep = \"\\t\\t\", quote = FALSE)\n\nwrite.csv(data_boot, \"data_boot.csv\")\n\nlibrary(kableExtra)\nkable(data_boot, \"simple\") -&gt; ok\n\nwrite.table(ok, \"data_boot.txt\", quote = FALSE, row.names = FALSE)\n\n\ncat data_boot.txt | sed 1d &gt; data_boot_ok.txt # run dòng lệnh này trong bash để bỏ dòng đầu tiên\n\nKết quả sau khi chạy bootstrap ta có 1000 mẫu giả lập với kết quả trung bình tương ứng. View\n\n\n14.0.3 Bước 2: Phân tích kết quả\nĐây là tần số của các con số trung bình từ 1000 lần lấy mẫu, từ đây ta sẽ tính ra các chỉ số khác như khoảng tin cậy, độ lệch chuẩn, sai số chuẩn của giá trị trung bình nếu được lấy mẫu trong thực tế sẽ dao động trong vùng đồ thị này.\n\nhist(data_boot$Kết.quả.trung.bình)\n\n\n\n\n\n\n\n\nTa có thể thực hiện bootstrap bằng package boot\n\nlibrary(boot)\n\ncan_nang &lt;- c(60, 55, 71, 45, 89, 56, 73, 49, 69, 88)\n\ncan_nang_df &lt;- as.data.frame(can_nang)\n\nmeanfun &lt;- function(data, i){\n               d &lt;- data[i, ]\n               return(mean(d))   \n}\n\nset.seed(123)\nbo &lt;- boot(data = can_nang_df, statistic = meanfun, R = 1000)\n\nbo\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = can_nang_df, statistic = meanfun, R = 1000)\n\n\nBootstrap Statistics :\n    original  bias    std. error\nt1*     65.5  0.1241    4.508722\n\nplot(bo)\n\n\n\n\n\n\n\nboot.ci(bo, conf = 0.95, type = \"bca\")\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bo, conf = 0.95, type = \"bca\")\n\nIntervals : \nLevel       BCa          \n95%   (57.30, 75.78 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n14.0.4 Tài liệu tham khảo\n\nhttps://towardsdatascience.com/a-practical-guide-to-bootstrap-with-r-examples-bd975ec6dcea\nhttps://rpubs.com/evelynebrie/bootstrapping\nhttps://datasciencetut.com/how-to-perform-bootstrapping-in-r/\nhttps://bash-intro.rsquaredacademy.com/r-command-line.html\nBootstrapping Main Ideas!!!\n\n\nA lot of people ask “What happens when the original collection of measurements is not representative of the underlying distribution?” It’s important to remember that a confidence interval is not guaranteed to overlap the true, population mean. A 95% CI means that if we make a ton of CIs using the same method, 95% of them will overlap the true mean. This tells us that 5% of the time we’ll be off. So yes, a sample that is totally bonkers is possible, but rare. Understanding this risk of making the wrong decision, and managing it, is what statistics is all about. Also, at 5:55 I say there are up to 8^8 combinations of observed values and possible means, but this assumes that order matters, and it doesn’t. So 8^8 over counts the total number of useful combinations and the true number is 15 choose 8, which is 6435 (for details on this math, see: https://en.wikipedia.org/wiki/Multiset#Counting_multisets )\n\n\nWe take for granted all that went behind that idea of 95% CI that you stated - it was Jerzy Neyman’s who came up with that definition. Have you read “The Lady Tasting Tea”? A bit of a history of some incredible mathematicians, including Ronald Fisher and Jerzy Neyman. The 95% comes up on page 123. Thanks for all your valuable statistics videos!\n\n\nVideo chi tiết https://www.youtube.com/live/isEcgoCmlO0?feature=share Dùng bootstrap tính p-value https://youtu.be/N4ZQQqyIf6k",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'><b>Khái niệm về bootstrap qua ví dụ tính trung bình mẫu</b></span>"
    ]
  },
  {
    "objectID": "bo-tri-thi-nghiem-toi-uu-hoa-bang-r.html",
    "href": "bo-tri-thi-nghiem-toi-uu-hoa-bang-r.html",
    "title": "15  Bố trí thí nghiệm tối ưu hóa bằng R",
    "section": "",
    "text": "15.0.1 Cơ sở lý thuyết về bố trí thí nghiệm tối ưu hóa\nPhương pháp bề mặt đáp ứng (Response surface)\nhttps://xdulieu.com/thiet-ke-thi-nghiem/tn5-be-mat-dap-ung/index.html\nHướng dẫn cách sử dụng package rsm để xử lý thí nghiệm tối ưu hóa\nhttps://r-inthelab.net/2022/06/15/response-surface-designs-and-their-analysis-with-r/\n\n\n15.0.2 Tình huống thường gặp\nBạn làm việc trong lĩnh vực công nghệ vi sinh, muốn tìm ra công thức nuôi cấy tế bào vi khuẩn tối ưu bằng phương pháp bề mặt đáp ứng (bố trí theo kiểu Box-Behnken design) với các yếu tố lần lượt là nhiệt độ, glucose, peptone, thời gian. Bình thường nếu làm trên Statgraphics thì cũng được, tuy nhiên giờ bạn muốn làm trên R thì như thế nào, có dễ thực hiện hay không.\nBạn tham khảo cách làm như sau nhé.\n\n\n15.0.3 Cách thực hiện\nBước 1: Thiết kế thí nghiệm gồm 4 yếu tố, 3 mức để làm cơ sở cho bố trí thực nghiệm\n\nlibrary(rsm)\n\n# Box-Behnken Design\n\nbo_tri_thi_nghiem &lt;- bbd(\n    k  = 4,            # 4 yếu tố\n    n0 = 3,            # 3 điểm trung tâm\n    block = FALSE,     # No blocks \n    randomize = FALSE, # Not randomized\n    coding = list(\n        x1 ~ (nhiet_do - 40) / 5,\n        x2 ~ (glucose - 100)/ 30,\n        x3 ~ (peptone - 30) / 15,\n        x4 ~ (thoi_gian - 24) / 12\n    )\n)\n\nprint(bo_tri_thi_nghiem)\n\n   run.order std.order nhiet_do glucose peptone thoi_gian\n1          1         1       35      70      30        24\n2          2         2       45      70      30        24\n3          3         3       35     130      30        24\n4          4         4       45     130      30        24\n5          5         5       40     100      15        12\n6          6         6       40     100      45        12\n7          7         7       40     100      15        36\n8          8         8       40     100      45        36\n9          9         9       35     100      30        12\n10        10        10       45     100      30        12\n11        11        11       35     100      30        36\n12        12        12       45     100      30        36\n13        13        13       40      70      15        24\n14        14        14       40     130      15        24\n15        15        15       40      70      45        24\n16        16        16       40     130      45        24\n17        17        17       35     100      15        24\n18        18        18       45     100      15        24\n19        19        19       35     100      45        24\n20        20        20       45     100      45        24\n21        21        21       40      70      30        12\n22        22        22       40     130      30        12\n23        23        23       40      70      30        36\n24        24        24       40     130      30        36\n25        25        25       40     100      30        24\n26        26        26       40     100      30        24\n27        27        27       40     100      30        24\n\nData are stored in coded form using these coding formulas ...\nx1 ~ (nhiet_do - 40)/5\nx2 ~ (glucose - 100)/30\nx3 ~ (peptone - 30)/15\nx4 ~ (thoi_gian - 24)/12\n\n\nBước 2: Thí nghiệm thực tế và đưa dữ liệu vào R\n\n## Ở đây mình chạy số liệu mô phỏng về mật độ tế bào (log CFU/mL)\n\nset.seed(14)\nlog_te_bao &lt;- sample(seq(from = 3, to = 10, length.out= 1000), size = 27, replace = TRUE)\n\nbo_tri_thi_nghiem$log_te_bao &lt;- log_te_bao\n\nprint(bo_tri_thi_nghiem)\n\n   run.order std.order nhiet_do glucose peptone thoi_gian log_te_bao\n1          1         1       35      70      30        24   4.849850\n2          2         2       45      70      30        24   8.885886\n3          3         3       35     130      30        24   4.863864\n4          4         4       45     130      30        24   5.599600\n5          5         5       40     100      15        12   9.572573\n6          6         6       40     100      45        12   8.262262\n7          7         7       40     100      15        36   8.024024\n8          8         8       40     100      45        36   6.006006\n9          9         9       35     100      30        12   3.553554\n10        10        10       45     100      30        12   6.048048\n11        11        11       35     100      30        36   3.175175\n12        12        12       45     100      30        36   6.461461\n13        13        13       40      70      15        24   5.466466\n14        14        14       40     130      15        24   6.419419\n15        15        15       40      70      45        24   9.292292\n16        16        16       40     130      45        24   5.431431\n17        17        17       35     100      15        24   7.288288\n18        18        18       45     100      15        24   3.686687\n19        19        19       35     100      45        24   6.587588\n20        20        20       45     100      45        24   3.735736\n21        21        21       40      70      30        12   6.293293\n22        22        22       40     130      30        12   9.138138\n23        23        23       40      70      30        36   6.811812\n24        24        24       40     130      30        36   4.268268\n25        25        25       40     100      30        24   7.393393\n26        26        26       40     100      30        24   7.512513\n27        27        27       40     100      30        24   6.538539\n\nData are stored in coded form using these coding formulas ...\nx1 ~ (nhiet_do - 40)/5\nx2 ~ (glucose - 100)/30\nx3 ~ (peptone - 30)/15\nx4 ~ (thoi_gian - 24)/12\n\n\nBước 3: Tính toán model tối ưu hóa\n\nket_qua_model &lt;- rsm(log_te_bao ~ SO(x1, x2, x3, x4), \n                   data = bo_tri_thi_nghiem)\n\nsummary(ket_qua_model)\n\n\nCall:\nrsm(formula = log_te_bao ~ SO(x1, x2, x3, x4), data = bo_tri_thi_nghiem)\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  7.148148   1.061205  6.7359 2.086e-05 ***\nx1           0.341592   0.530603  0.6438   0.53183    \nx2          -0.489907   0.530603 -0.9233   0.37404    \nx3          -0.095179   0.530603 -0.1794   0.86063    \nx4          -0.676760   0.530603 -1.2755   0.22629    \nx1:x2       -0.825075   0.919031 -0.8978   0.38697    \nx1:x3        0.187437   0.919031  0.2040   0.84181    \nx1:x4        0.197948   0.919031  0.2154   0.83308    \nx2:x3       -1.203453   0.919031 -1.3095   0.21489    \nx2:x4       -1.347097   0.919031 -1.4658   0.16842    \nx3:x4       -0.176927   0.919031 -0.1925   0.85056    \nx1^2        -1.720512   0.795904 -2.1617   0.05155 .  \nx2^2        -0.147439   0.795904 -0.1852   0.85613    \nx3^2         0.159117   0.795904  0.1999   0.84489    \nx4^2        -0.110652   0.795904 -0.1390   0.89173    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMultiple R-squared:  0.5306,    Adjusted R-squared:  -0.01707 \nF-statistic: 0.9688 on 14 and 12 DF,  p-value: 0.528\n\nAnalysis of Variance Table\n\nResponse: log_te_bao\n                    Df Sum Sq Mean Sq F value  Pr(&gt;F)\nFO(x1, x2, x3, x4)   4  9.885  2.4713  0.7315 0.58767\nTWI(x1, x2, x3, x4)  6 16.197  2.6996  0.7990 0.58878\nPQ(x1, x2, x3, x4)   4 19.742  4.9354  1.4608 0.27431\nResiduals           12 40.542  3.3785                \nLack of fit         10 39.977  3.9977 14.1630 0.06771\nPure error           2  0.565  0.2823                \n\nStationary point of response surface:\n        x1         x2         x3         x4 \n 0.1775194 -0.4311620 -1.0998650  0.6045616 \n\nStationary point in original units:\n nhiet_do   glucose   peptone thoi_gian \n 40.88760  87.06514  13.50203  31.25474 \n\nEigenanalysis:\neigen() decomposition\n$values\n[1]  0.8592213  0.1237387 -0.9747800 -1.8276662\n\n$vectors\n         [,1]        [,2]       [,3]       [,4]\nx1  0.1472489  0.03064641  0.2349074 0.96031092\nx2 -0.6884443 -0.13747489 -0.6585456 0.27104034\nx3  0.5555084 -0.71986015 -0.4143418 0.03914888\nx4  0.4424620  0.67967846 -0.5826295 0.05298518\n\n\nBước 4: Vẽ đồ thị\nThể hiện toàn bộ tương quan giữa các yếu tố với output mật độ tế bào\n\npar(mfrow = c(2, 3))         # 2 x 3 pictures on one plot\npersp(\n    ket_qua_model,           # Our model\n    ~ x1 + x2 + x3 + x4,     # A formula to obtain the 6 possible graphs\n    col = topo.colors(100),  # Color palette\n    contours = \"colors\",     # Include contours with the same color palette\n    # xlabs = c(\"Nhiệt độ (°C)\", \n    #           \"Glucse (g/L)\", \n    #           \"Peptone (g/L)\", \n    #           \"Thời gian (giờ)\" ), \n    # zlab = \"Mật độ tế bào (log CFU/mL)\",\n    expand = 1,\n    cex = 0.8\n)\n\n\n\n\n\n\n\n\nĐồ thị tương quan giữa peptone và nhiệt độ\n\nok &lt;- persp(\n    ket_qua_model,            # Our model\n    ~ x1 + x3,    # A formula to obtain the 6 possible graphs\n    col = topo.colors(100), # Color palette\n    contours = \"colors\",     # Include contours with the same color palette\n    xlabs = c(\"\\n\\nNhiệt độ (°C)\", \n              \"\\n\\nPeptone (g/L)\"), \n    # zlab = \"\\n\\nMật độ tế bào (log CFU/mL)\", # Dùng \\n để cách hàng\n    cex.lab = 0.9,\n    expand = 0.8,\n    # theta = 30, phi = 30 # Xoay đồ thị,\n    ticktype = \"detailed\",\n    nticks = 4\n)\npar(xpd = NA, srt  = 95)  ## disable clipping and set string rotation\ntext(-0.28, 0.02,\"Mật độ tế bào (log CFU/mL)\")\n\n\n\n\n\n\n\n## trích xuất tọa độ x, y, z\nok$`x1 ~ x3`$x -&gt; x\nok$`x1 ~ x3`$y -&gt; y\nok$`x1 ~ x3`$z -&gt; z\n\nĐồ thị tương quan giữa glucose và nhiệt độ\n\npersp(\n    ket_qua_model,            # Our model\n    ~ x1 + x2,    # A formula to obtain the 6 possible graphs\n    col = topo.colors(100), # Color palette\n    contours = \"colors\",     # Include contours with the same color palette\n    xlabs = c(\"\\n\\nNhiệt độ (°C)\", \n              \"\\n\\nGlucose (g/L)\"), \n    # zlab = \"\\n\\nMật độ tế bào (log CFU/mL)\", # Dùng \\n để cách hàng\n    cex.lab = 0.9,\n    expand = 0.8,\n    # theta = 30, phi = 30 # Xoay đồ thị,\n    ticktype = \"detailed\",\n    nticks = 4\n)\npar(xpd = NA, srt  = 95)  ## disable clipping and set string rotation\ntext(-0.28, 0.02,\"Mật độ tế bào (log CFU/mL)\")\n\n\n\n\n\n\n\n\nĐồ thị đường đồng mức\n\npar(mfrow = c(2,3))       # 2 x 3 pictures on one plot\ncontour(\n  ket_qua_model,            # Our model\n  ~ x1 + x2 + x3 + x4,    # A formula to obtain the 6 possible graphs \n  image = TRUE,           # If image = TRUE, apply color to each contour\n  )\n\n\n\n\n\n\n\n\nTìm điểm tối ưu\n\nopt_point &lt;- summary(ket_qua_model)$canonical$xs\n# opt_point\n \nop_point_ru &lt;- code2val(\n    opt_point,                     # Optimal point in coded units\n    codings = codings(bo_tri_thi_nghiem)  # Formulas to convert to factor units\n)\nop_point_ru\n\n nhiet_do   glucose   peptone thoi_gian \n 40.88760  87.06514  13.50203  31.25474 \n\n\nDự đoán kết quả đầu ra từ điểm tối ưu\n\nopt_point_df &lt;- data.frame(  # predict() needs a data frame with the points \n    x1 = opt_point[1],         # to be predicted \n    x2 = opt_point[2],\n    x3 = opt_point[3],\n    x4 = opt_point[4]\n)\n\nbest_response &lt;- predict(\n    ket_qua_model,           # Our model\n    opt_point_df             # Data frame with points to be predicted \n)\n\nnames(best_response) &lt;- \"log_te_bao\"\nbest_response\n\nlog_te_bao \n  7.131852 \n\n\nKết quả trên có nghĩa là với điều kiện nuôi cấy ở nhiệt độ 40.1 (°C), thời gian 31.3 giờ, sử dụng môi trường nuôi cấy có glucose 87.1 g/L và peptone 13.5 g/L thì sẽ thu được kết quả tối ưu là 7.13 log CFU/mL hay là 1.3 × 107 CFU/mL.\n\n15.0.3.1 Tài liệu tham khảo\n\nhttps://cran.r-project.org/web/packages/plot3D/\nhttp://www.sthda.com/english/wiki/impressive-package-for-3d-and-4d-graph-r-software-and-data-visualization\nhttps://plotly.com/r/3d-surface-plots/",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'><b>Bố trí thí nghiệm tối ưu hóa bằng R</b></span>"
    ]
  },
  {
    "objectID": "workflow-phan-tich-thong-ke-qua-dataset-iris.html",
    "href": "workflow-phan-tich-thong-ke-qua-dataset-iris.html",
    "title": "16  Workflow phân tích thống kê qua dataset iris ",
    "section": "",
    "text": "16.1 Đặc điểm dataset iris\nKhi làm việc với R, ta thường hay gặp các dataset minh họa cách xử lý thống kê. Một trong số đó là dataset iris là kết quả đo đạc thực nghiệm (đơn vị cm) về chiều dài và chiều rộng của đài hoa Sepal.Length và Sepal.Width, cũng như chiều dài và chiều rộng của cánh hoa Petal.Length và Petal.Width của 3 loài hoa khác nhau thuộc chi Diên Vĩ lần lượt là Iris setosa, Iris versicolor, and Iris virginica.\nDataset này được công bố ở bài báo Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5.\nBài hướng dẫn sau sẽ giúp bạn tiếp cận quy trình phân tích thống kê một cách có hệ thống để làm chủ dần các lệnh phân tích thống kê trong R cũng như trả lời được các câu hỏi căn bản về một bộ dataset trước khi thực sự đi sâu vào các model thống kê cao hơn từ chính bộ dataset đó.",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'><b>Workflow phân tích thống kê qua dataset <code>iris</code> </b></span>"
    ]
  },
  {
    "objectID": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#đặc-điểm-dataset-iris",
    "href": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#đặc-điểm-dataset-iris",
    "title": "16  Workflow phân tích thống kê qua dataset iris ",
    "section": "",
    "text": "This famous (Fisher’s or Anderson’s) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'><b>Workflow phân tích thống kê qua dataset <code>iris</code> </b></span>"
    ]
  },
  {
    "objectID": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#bước-1-in-bộ-dữ-liệu",
    "href": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#bước-1-in-bộ-dữ-liệu",
    "title": "16  Workflow phân tích thống kê qua dataset iris ",
    "section": "16.2 Bước 1: In bộ dữ liệu",
    "text": "16.2 Bước 1: In bộ dữ liệu\n\nprint(iris) # in full dataset\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'><b>Workflow phân tích thống kê qua dataset <code>iris</code> </b></span>"
    ]
  },
  {
    "objectID": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#bước-2-đánh-giá-sơ-bộ-dataset",
    "href": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#bước-2-đánh-giá-sơ-bộ-dataset",
    "title": "16  Workflow phân tích thống kê qua dataset iris ",
    "section": "16.3 Bước 2: Đánh giá sơ bộ dataset",
    "text": "16.3 Bước 2: Đánh giá sơ bộ dataset\n\noptions(width = 200) # lệnh này giúp điều chỉnh độ rộng khi in kết quả ở dạng HTML \n\ndim(iris) # kiểm tra số hàng và số cột\n\n[1] 150   5\n\nstr(iris) # xem cấu trúc dataset\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(iris) # tóm tắt sơ bộ các biến trong dataset\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width          Species  \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100   setosa    :50  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300   versicolor:50  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300   virginica :50  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199                  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800                  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500                  \n\nsapply(iris, class) # kiểm tra class trong từng cột dataset\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n   \"numeric\"    \"numeric\"    \"numeric\"    \"numeric\"     \"factor\"",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'><b>Workflow phân tích thống kê qua dataset <code>iris</code> </b></span>"
    ]
  },
  {
    "objectID": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#bước-3-thống-kê-mô-tả",
    "href": "workflow-phan-tich-thong-ke-qua-dataset-iris.html#bước-3-thống-kê-mô-tả",
    "title": "16  Workflow phân tích thống kê qua dataset iris ",
    "section": "16.4 Bước 3: Thống kê mô tả",
    "text": "16.4 Bước 3: Thống kê mô tả\nĐồ thị boxplot\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n  geom_boxplot() +\n  geom_jitter() +\n  scale_x_discrete(name = \"Species\") +\n  scale_y_continuous(name = \"Sepal Length (cm)\") +\n  labs(title = \"Chiều dài đài hoa của các loài trong chi Iris\") +\n  stat_summary(fun = mean, colour = \"darkred\", geom = \"point\", shape = 18, size = 3, show.legend = TRUE) +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Species, y = Sepal.Width, color = Species)) +\n  geom_boxplot() +\n  geom_jitter() +\n  scale_x_discrete(name = \"Species\") +\n  scale_y_continuous(name = \"Sepal Width (cm)\") +\n  labs(title = \"Chiều rộng đài hoa của các loài trong chi Iris\") +\n  stat_summary(fun = mean, colour = \"darkred\", geom = \"point\", shape = 18, size = 3, show.legend = TRUE) +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Species, y = Petal.Length, color = Species)) +\n  geom_boxplot() +\n  geom_jitter() +\n  scale_x_discrete(name = \"Species\") +\n  scale_y_continuous(name = \"Petal Length (cm)\") +\n  labs(title = \"Chiều dài cánh hoa của các loài trong chi Iris\") +\n  stat_summary(fun = mean, colour = \"darkred\", geom = \"point\", shape = 18, size = 3, show.legend = TRUE) +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Species, y = Petal.Width, color = Species)) +\n  geom_boxplot() +\n  geom_jitter() +\n  scale_x_discrete(name = \"Species\") +\n  scale_y_continuous(name = \"Petal Width (cm)\") +\n  labs(title = \"Chiều rộng cánh hoa của các loài trong chi Iris\") +\n  stat_summary(fun = mean, colour = \"darkred\", geom = \"point\", shape = 18, size = 3, show.legend = TRUE) +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\nĐồ thị histogram\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Sepal.Length, color = Species, fill = Species)) +\n  geom_density(alpha = 0.5) +\n  scale_x_continuous(limits = c(3, 9), name = \"Sepal Length (cm)\") +\n  labs(title = \"Phân phối về chiều dài đài hoa giữa các loài trong chi Iris\") +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Sepal.Width, color = Species, fill = Species)) +\n  geom_density(alpha = 0.5) +\n  scale_x_continuous(limits = c(0, 6), name = \"Sepal Width (cm)\") +\n  labs(title = \"Phân phối về chiều rộng đài hoa giữa các loài trong chi Iris\") +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Petal.Length, color = Species, fill = Species)) +\n  geom_density(alpha = 0.5) +\n  scale_x_continuous(limits = c(0, 8), name = \"Petal Length (cm)\") +\n  labs(title = \"Phân phối về chiều dài cánh hoa giữa các loài trong chi Iris\") +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Petal.Width, color = Species, fill = Species)) +\n  geom_density(alpha = 0.5) +\n  scale_x_continuous(limits = c(0, 3), name = \"Petal Width (cm)\") +\n  labs(title = \"Phân phối về chiều rộng cánh hoa giữa các loài trong chi Iris\") +\n  theme_classic() +\n  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, \"cm\"))\n\n\n\n\n\n\n\n\n\n16.4.0.1 Tài liệu tham khảo\n\nhttps://www.sarfarazalam.com/post/r_ggplot_tutorial_barplot_boxplot/r_tutorial_barplot_boxplot",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'><b>Workflow phân tích thống kê qua dataset <code>iris</code> </b></span>"
    ]
  },
  {
    "objectID": "example-partial-least-squares-and-principal-component-regression.html",
    "href": "example-partial-least-squares-and-principal-component-regression.html",
    "title": "17  Example for Partial Least Squares and Principal Component Regression",
    "section": "",
    "text": "17.0.1 Bước 1: Import dữ liệu\nSử dụng các bộ dữ liệu:\nyarn A data set with 28 near-infrared spectra (NIR) of PET yarns, measured at 268 wavelengths, as predictors, and density as response (density). The data set also includes a logical variable train which can be used to split the data into a training data set of size 21 and test data set of size 7. View\noliveoil A data set with 5 quality measurements (chemical) and 6 panel sensory panel variables (sensory) made on 16 olive oil samples. View\ngasoline A data set consisting of octane number (octane) and NIR spectra (NIR) of 60 gasoline samples. Each NIR spectrum consists of 401 diffuse reflectance measurements from 900 to 1700 nm. View\nThể hiện dữ liệu thô\n\nlibrary(pls)\ndata(yarn)\ndata(oliveoil)\ndata(gasoline)\n\nwrite.csv(yarn, \"yarn.csv\")\nwrite.csv(oliveoil, \"oliveoil.csv\")\nwrite.csv(gasoline, \"gasoline.csv\") ## lý do phải export và import vì dataset gasoline bị nén cột lại ở dạng AsIs\n\nyarn &lt;- read.csv(\"yarn.csv\")\noliveoil &lt;- read.csv(\"oliveoil.csv\")\ngasoline &lt;- read.csv(\"gasoline.csv\")\n\n###\n\nlibrary(kableExtra)\n\nyarn %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \n                                        \"hover\", \n                                        \"condensed\", \n                                        \"bordered\", \n                                        \"responsive\")) %&gt;%\n    kable_classic(full_width = FALSE, html_font = \"arial\") -&gt; yarn_output\n\nsave_kable(yarn_output, file = \"yarn_output.html\")\n\noliveoil %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \n                                        \"hover\", \n                                        \"condensed\", \n                                        \"bordered\", \n                                        \"responsive\")) %&gt;%\n    kable_classic(full_width = FALSE, html_font = \"arial\") -&gt; oliveoil_output\n\nsave_kable(oliveoil_output, file = \"oliveoil_output.html\")\n\ngasoline %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \n                                        \"hover\", \n                                        \"condensed\", \n                                        \"bordered\", \n                                        \"responsive\")) %&gt;%\n    kable_classic(full_width = FALSE, html_font = \"arial\") -&gt; gasoline_output\n\nsave_kable(gasoline_output, file = \"gasoline_output.html\")\n\n\n\n17.0.2 Bước 2: Mô tả dữ liệu\ngasoline là dataset có các dòng là các hợp chất octane ở nồng độ khác nhau, tổng cộng có 60 hợp chất như vậy, mỗi hợp chất được bước sóng từ 900 nm đến 1700 nm. Như vậy, ta muốn vẽ một đồ thị mô tả biến thiên độ hấp thụ theo từng hợp chất (từng dòng, như vậy sẽ có 60 dòng) với trục y là độ hấp thụ và trục x là bước sóng thì ta cần transpose dữ liệu về dạng sau. View\n\nt(gasoline[, -c(1, 2)]) -&gt; matrix_gasoline\n\ngsub(\"\\\\.nm\", \"\", row.names(matrix_gasoline)) -&gt; ok_1\n\ngsub(\"NIR.\", \"\", ok_1) -&gt; ok_2\n\nas.numeric(ok_2) -&gt; row.names(matrix_gasoline)\n\npaste0(\"octane.\", gasoline$octane) -&gt; colnames(matrix_gasoline)\n\n\nmatrix_gasoline %&gt;%\n  kbl() %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \n                                      \"hover\", \n                                      \"condensed\", \n                                      \"bordered\", \n                                      \"responsive\")) %&gt;%\n  kable_classic(full_width = FALSE, html_font = \"arial\") -&gt; matrix_gasoline_output\n\nsave_kable(matrix_gasoline_output, file = \"matrix_gasoline_output.html\")\n\nVẽ đồ thị độ hấp thụ theo bước sóng và hợp chất octane\n\nmatplot(matrix_gasoline, type = \"l\", lty = 1, \n        ylab = \"Độ hấp thụ\", xlab = \"Bước sóng (nm)\", xaxt = \"n\", \n        col = 1:length(colnames(matrix_gasoline))) \n\nind &lt;- seq(from = 900, to = 1700, by = 100)\nind &lt;- ind[ind &gt;= 900 & ind &lt;= 1700]\nind &lt;- (ind - 898) / 2\n\naxis(1, \n     at = ind, \n     labels = row.names(matrix_gasoline)[ind])\n\nlegend(x = \"topleft\",\n       legend = colnames(matrix_gasoline),\n       cex = 1, \n       xpd = TRUE,\n       col = 1:length(colnames(matrix_gasoline)),\n       lty = 1, lwd = 1.5,\n       ncol = 4,\n       horiz = FALSE)\n\n\n\n\n\n\n\n\n\n\n17.0.3 Bước 3: Ráp code theo vignettes\nWe will do a PLSR on the gasoline data to illustrate the use of pls package.\n\noptions(digits = 4)\noptions(width = 200)\n\ndata(gasoline) ## vì các function bên dưới dùng cột NIR ở dạng AsIs nên ta gọi lại dataset này.\n\ngasTrain &lt;- gasoline[1:50, ]\n\ngasTest &lt;- gasoline[51:60, ]\n\n# A typical way of fitting a PLSR model is\n\ngas1 &lt;- plsr(octane ~ NIR, ncomp = 10, data = gasTrain, validation = \"LOO\")\n\nsummary(gas1)\n\nData:   X dimension: 50 401 \n    Y dimension: 50 1\nFit method: kernelpls\nNumber of components considered: 10\n\nVALIDATION: RMSEP\nCross-validated using 50 leave-one-out segments.\n       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps  9 comps  10 comps\nCV           1.545    1.357   0.2966   0.2524   0.2476   0.2398   0.2319   0.2386   0.2316   0.2449    0.2673\nadjCV        1.545    1.356   0.2947   0.2521   0.2478   0.2388   0.2313   0.2377   0.2308   0.2438    0.2657\n\nTRAINING: % variance explained\n        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps  9 comps  10 comps\nX         78.17    85.58    93.41    96.06    96.94    97.89    98.38    98.85    99.02     99.19\noctane    29.39    96.85    97.89    98.26    98.86    98.96    99.09    99.16    99.28     99.39\n\n\nThe validation results here are Root Mean Squared Error of Prediction (RMSEP).\nThere are two cross-validation estimates: CV is the ordinary CV estimate, and adjCV is a bias-corrected CV estimate.\nIt is often simpler to judge the RMSEPs by plotting them. This plots the estimated RMSEPs as functions of the number of components.\n\nplot(RMSEP(gas1), legendpos = \"topright\")\n\n\n\n\n\n\n\n\nOnce the number of components has been chosen, one can inspect different aspects of the fit by plotting predictions, scores, loadings, etc. The default plot is a prediction plot. This shows the cross-validated predictions with two components versus measured values.\n\nplot(gas1, ncomp = 2, asp = 1, line = TRUE)\n\n\n\n\n\n\n\nplot(gas1, plottype = \"scores\", comps = 1:3)\n\n\n\n\n\n\n\nexplvar(gas1)\n\n Comp 1  Comp 2  Comp 3  Comp 4  Comp 5  Comp 6  Comp 7  Comp 8  Comp 9 Comp 10 \n78.1708  7.4122  7.8242  2.6578  0.8768  0.9466  0.4922  0.4723  0.1688  0.1694 \n\n\n\nplot(gas1, \"loadings\", comps = 1:2, legendpos = \"topleft\", labels = \"numbers\", xlab = \"nm\")\nabline(h = 0)\n\n\n\n\n\n\n\n\nA fitted model is often used to predict the response values of new observations.\n\npredict(gas1, ncomp = 2, newdata = gasTest)\n\n, , 2 comps\n\n   octane\n51  87.94\n52  87.25\n53  88.16\n54  84.97\n55  85.15\n56  84.51\n57  87.56\n58  86.85\n59  89.19\n60  87.09\n\n\nBecause we know the true response values for these samples, we can calculate the test set RMSEP.\n\nRMSEP(gas1, newdata = gasTest)\n\n(Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps      6 comps      7 comps      8 comps      9 comps     10 comps  \n     1.5369       1.1696       0.2445       0.2341       0.3287       0.2780       0.2703       0.3301       0.3571       0.4090       0.6116  \n\n\nFor two components, we get 0.244, which is quite close to the cross-validated estimate above 0.2966.\n\n17.0.3.1 Tài liệu tham khảo\n\nhttps://cran.r-project.org/web/packages/pls/vignettes/pls-manual.pdf",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'><b>Example for Partial Least Squares and Principal Component Regression</b></span>"
    ]
  },
  {
    "objectID": "tai-lieu-phan-tich-pca.html",
    "href": "tai-lieu-phan-tich-pca.html",
    "title": "19  Tài liệu phân tích PCA",
    "section": "",
    "text": "Phân tích Principal Component Analysis (PCA) là kỹ thuật giảm chiều của dataset rút gọn còn 2 trục PC1 và PC2 (hay 3 trục PC1, PC2, PC3) nhằm giúp phân tách ra sự khác biệt giữa các nhóm (variables) hoặc giữa các cá thể/observation với nhau.\nhttps://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-princomp/\nThere are two general methods to perform PCA in R :\n\nSpectral decomposition which examines the covariances / correlations between variables\nSingular value decomposition which examines the covariances / correlations between individuals\n\nĐể tìm hiểu nhanh về kỹ thuật vẽ đồ thị PCA ta cần điểm qua các tài liệu sau:\n\nConcept chung về PCA theo cách ngắn gọn dễ hiểu. StatQuest: Principal Component Analysis (PCA), Step-by-Step. https://www.youtube.com/watch?v=FgakZw6K1QQ\nGS. Nguyễn Văn Tuấn. Bài giảng 83: Principal Component Analysis. https://www.youtube.com/watch?v=uEEp5WYNHVY\nAlboukadel Kassambara - Practical Guide to Principal Component Methods in R. https://studyr.netlify.app/ref/kassambara_principal_component_methods.pdf\nBiện luận đồ thị PCA. https://applyr.netlify.app/b1/Principal_component_analysis.pdf\nCơ sở toán học của phân tích PCA. https://applyr.netlify.app/b1/I.T.%20Jolliffe%20-%20Principal%20Component%20Analysis-Springer%20(2002).pdf\n\nKhi phân tích PCA sẽ có giai đoạn gom cụm dữ liệu. Bạn cần trang bị kiến thức về các thuật toán clustering ở đây.\n\nAdvances in K-means Clustering. https://applyr.netlify.app/b1/Advances%20in%20K-means%20Clustering.pdf\nAlboukadel Kassambara -Practical Guide To Cluster Analysis in R. https://applyr.netlify.app/b1/Practical%20Guide%20to%20Cluster%20Analysis%20in%20R.%20Unsupervised%20Machine%20Learning.pdf\nModel-Based Clustering, Classification, and Density Estimation Using mclust in R. https://applyr.netlify.app/b1/Model-Based%20Clustering.pdf",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'><b>Tài liệu phân tích PCA</b></span>"
    ]
  },
  {
    "objectID": "xay-dung-mo-hinh-GAM-trong-r.html",
    "href": "xay-dung-mo-hinh-GAM-trong-r.html",
    "title": "20  Xây dựng mô hình GAM trong R",
    "section": "",
    "text": "20.1 Import dataset\nCâu hỏi nghiên cứu: Đánh giá ảnh hưởng của các biến Income, Edu, Health đến kết quả học tập Overall.\n# https://raw.githubusercontent.com/m-clark/generalized-additive-models/master/data/pisasci2006.csv\npisa &lt;- read.csv('data_raw_1/pisasci2006.csv')\npisa\n\n                    Country Overall Issues Explain Evidence Interest Support Income Health   Edu   HDI\n1                   Albania      NA     NA      NA       NA       NA      NA  0.599  0.886 0.716 0.724\n2                 Argentina     391    395     386      385      567     506  0.678  0.868 0.786 0.773\n3                 Australia     527    535     520      531      465     487  0.826  0.965 0.978 0.920\n4                   Austria     511    505     516      505      507     515  0.835  0.944 0.824 0.866\n5                Azerbaijan     382    353     412      344      612     542  0.566  0.780    NA    NA\n6                   Belgium     510    515     503      516      503     492  0.831  0.935 0.868 0.877\n7                    Brazil     390    398     390      378      592     519  0.637  0.818 0.646 0.695\n8                  Bulgaria     434    427     444      417      523     527  0.663  0.829 0.778 0.753\n9                    Canada     534    532     531      542      469     501  0.840  0.951 0.902 0.897\n10                    Chile     438    444     432      440      591     564  0.673  0.923 0.764 0.780\n11                  ChinaHK     542    528     549      542      536     529  0.853  0.966 0.763 0.857\n12                 Colombia     388    402     379      383      644     546  0.616  0.829 0.624 0.683\n13                  Croatia     493    494     492      490      535     514  0.724  0.878 0.762 0.785\n14           Czech Republic     513    500     527      501      489     485  0.763  0.893 0.927 0.858\n15                  Denmark     496    493     501      489      463     483  0.838  0.914 0.911 0.887\n16                  Estonia     531    516     541      531      502     497  0.739  0.838 0.918 0.829\n17                  Finland     563    555     566      567      448     479  0.827  0.931 0.879 0.878\n18                   France     495    499     481      511      520     507  0.819  0.955 0.850 0.873\n19                  Germany     516    510     519      515      513     518  0.831  0.939 0.929 0.898\n20                   Greece     473    469     476      465      549     533  0.791  0.937 0.861 0.861\n21                  Hungary     504    483     518      497      522     512  0.733  0.842 0.855 0.808\n22                  Iceland     491    494     488      491      466     491  0.832  0.964 0.893 0.895\n23                Indonesia     393    393     395      386      608     521  0.484  0.748 0.535 0.579\n24                  Ireland     508    516     505      506      481     484  0.837  0.932 0.945 0.904\n25                   Israel     454    457     443      460      509     512  0.786  0.952 0.901 0.877\n26                    Italy     475    474     480      467      529     511  0.810  0.963 0.832 0.866\n27                    Japan     531    522     527      544      512     468  0.825  0.986 0.869 0.891\n28                   Jordan     422    409     438      405      609     555  0.552  0.832 0.679 0.678\n29               Kazakhstan      NA     NA      NA       NA       NA      NA  0.635  0.717 0.826 0.721\n30                    Korea     522    519     512      538      486     495     NA     NA    NA    NA\n31          Kyrgyz Republic     322    321     334      288      580     502  0.407  0.735 0.712 0.598\n32                   Latvia     490    489     486      491      504     494  0.711  0.820 0.855 0.793\n33            Liechtenstein     522    522     516      535      504     524  0.941  0.931    NA    NA\n34                Lithuania     488    476     494      487      544     541  0.717  0.813 0.871 0.798\n35               Luxembourg     486    483     483      492      515     522  0.901  0.931 0.764 0.863\n36              Macao-China     511    490     520      512      524     521     NA     NA    NA    NA\n37                   Mexico     410    421     406      402      611     536  0.695  0.880 0.684 0.748\n38               Montenegro     412    401     417      407      561     529  0.647  0.852 0.802 0.762\n39              Netherlands     525    533     522      526      452     447  0.848  0.942 0.903 0.897\n40              New Zealand     530    536     522      537      461     470  0.781  0.943 0.991 0.901\n41                   Norway     487    489     495      473      472     485  0.884  0.948 0.993 0.940\n42                   Panama      NA     NA      NA       NA       NA      NA  0.646  0.872 0.735 0.745\n43                     Peru      NA     NA      NA       NA       NA      NA  0.591  0.832 0.688 0.697\n44                   Poland     498    483     506      494      501     513  0.710  0.872 0.812 0.795\n45                 Portugal     474    486     469      472      571     538  0.765  0.919 0.704 0.791\n46                    Qatar     349    352     356      324      565     520  0.914  0.909 0.655 0.816\n47                  Romania     418    409     426      407      591     540  0.658  0.831 0.792 0.757\n48       Russian Federation     479    463     483      481      541     508  0.691  0.736 0.773 0.733\n49                   Serbia     436    431     441      425      523     520  0.642  0.848 0.770 0.749\n50           Shanghai-China      NA     NA      NA       NA       NA      NA     NA     NA    NA    NA\n51                Singapore      NA     NA      NA       NA       NA      NA  0.876  0.951 0.720 0.843\n52          Slovak Republic     488    475     501      478      522     497  0.734  0.859 0.864 0.817\n53                 Slovenia     519    517     523      516      505     502  0.788  0.916 0.877 0.858\n54                    Spain     488    489     490      485      534     529  0.805  0.950 0.836 0.862\n55                   Sweden     503    499     510      496      454     471  0.836  0.956 0.904 0.898\n56              Switzerland     512    515     508      519      504     510  0.857  0.970 0.856 0.893\n57 Taiwan Province of China     532    509     545      532      533     546     NA     NA    NA    NA\n58                 Thailand     421    413     420      423      642     569  0.603  0.842 0.569 0.661\n59      Trinidad and Tobago      NA     NA      NA       NA       NA      NA  0.769  0.772 0.685 0.741\n60                  Tunisia     386    384     383      382      590     534  0.597  0.846 0.608 0.675\n61                   Turkey     424    427     423      417      540     563  0.679  0.828 0.562 0.681\n62     United Arab Emirates      NA     NA      NA       NA       NA      NA  0.909  0.878 0.686 0.818\n63           United Kingdom     515    514     517      514      464     470  0.833  0.934 0.798 0.853\n64            United States     489    492     486      489      480     490  0.872  0.911 0.930 0.904\n65                  Uruguay     428    429     423      429      567     510  0.658  0.884 0.740 0.755",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'><b>Xây dựng mô hình GAM trong R</b></span>"
    ]
  },
  {
    "objectID": "xay-dung-mo-hinh-GAM-trong-r.html#summary-dữ-liệu-cho-các-cột-numeric",
    "href": "xay-dung-mo-hinh-GAM-trong-r.html#summary-dữ-liệu-cho-các-cột-numeric",
    "title": "20  Xây dựng mô hình GAM trong R",
    "section": "20.2 Summary dữ liệu cho các cột numeric",
    "text": "20.2 Summary dữ liệu cho các cột numeric\n\n# devtools::install_github('m-clark/tidyext')\nlibrary(tidyverse)\nlibrary(tidyext)\nlibrary(gt)\n\npisa |&gt; tidyext::num_by(vars(-Country)) |&gt; gt::gt()\n\n\n\n\n\n\n\n\nVariable\nN\nMean\nSD\nMin\nQ1\nMedian\nQ3\nMax\n% Missing\n\n\n\n\nOverall\n57\n473.1\n54.6\n322.0\n428.0\n489.0\n513.0\n563.0\n12\n\n\nIssues\n57\n469.9\n53.9\n321.0\n427.0\n489.0\n514.0\n555.0\n12\n\n\nExplain\n57\n475.0\n54.0\n334.0\n432.0\n490.0\n517.0\n566.0\n12\n\n\nEvidence\n57\n469.8\n61.7\n288.0\n423.0\n489.0\n515.0\n567.0\n12\n\n\nInterest\n57\n528.2\n49.8\n448.0\n501.0\n522.0\n565.0\n644.0\n12\n\n\nSupport\n57\n512.2\n26.1\n447.0\n494.0\n512.0\n529.0\n569.0\n12\n\n\nIncome\n61\n0.7\n0.1\n0.4\n0.7\n0.8\n0.8\n0.9\n6\n\n\nHealth\n61\n0.9\n0.1\n0.7\n0.8\n0.9\n0.9\n1.0\n6\n\n\nEdu\n59\n0.8\n0.1\n0.5\n0.7\n0.8\n0.9\n1.0\n9\n\n\nHDI\n59\n0.8\n0.1\n0.6\n0.7\n0.8\n0.9\n0.9\n9",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'><b>Xây dựng mô hình GAM trong R</b></span>"
    ]
  },
  {
    "objectID": "xay-dung-mo-hinh-GAM-trong-r.html#pairs-plot",
    "href": "xay-dung-mo-hinh-GAM-trong-r.html#pairs-plot",
    "title": "20  Xây dựng mô hình GAM trong R",
    "section": "20.3 Pairs plot",
    "text": "20.3 Pairs plot\n\nlibrary(GGally)\n\nbetter_smooth &lt;- function(data, mapping, ptcol, ptalpha=1, ptsize=1, linecol, ...) {\n  p &lt;- ggplot(data = data, mapping = mapping) +\n    geom_point(color = ptcol, alpha=ptalpha, size = ptsize) +\n    geom_smooth(color = linecol, ...)\n  p\n}\n\np &lt;- GGally::ggpairs(\n  pisa[, -c(1, 3:5)],\n  lower = list(\n    continuous = GGally::wrap(\n      better_smooth,\n      ptalpha = .25,\n      ptcol = '#D55E00',\n      ptsize = 1,\n      linecol = '#03b3ff',\n      method = 'loess',\n      se = FALSE,\n      lwd = .5\n    )\n  ),\n  diag = list(continuous = GGally::wrap(\n    'densityDiag', color = 'gray50', lwd = .5\n  )),\n  # upper=list(continuous=GGally::wrap(better_corr)),\n  axisLabels = \"none\"\n)\n\np",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'><b>Xây dựng mô hình GAM trong R</b></span>"
    ]
  },
  {
    "objectID": "xay-dung-mo-hinh-GAM-trong-r.html#fitting-model-gam",
    "href": "xay-dung-mo-hinh-GAM-trong-r.html#fitting-model-gam",
    "title": "20  Xây dựng mô hình GAM trong R",
    "section": "20.4 Fitting model GAM",
    "text": "20.4 Fitting model GAM\n\nlibrary(gamRR)\nlibrary(nlme)\nlibrary(mgcv)\nmod_gam2 = gam(Overall ~ s(Income) + s(Edu) + s(Health), data = pisa)\nsummary(mod_gam2)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nOverall ~ s(Income) + s(Edu) + s(Health)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  471.154      2.772     170   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n            edf Ref.df     F  p-value    \ns(Income) 7.593  8.415 8.826 1.29e-06 ***\ns(Edu)    6.204  7.178 3.308  0.00771 ** \ns(Health) 1.000  1.000 2.736  0.10679    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.863   Deviance explained = 90.3%\nGCV = 573.83  Scale est. = 399.5     n = 52\n\nplot(mod_gam2)",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'><b>Xây dựng mô hình GAM trong R</b></span>"
    ]
  },
  {
    "objectID": "xay-dung-mo-hinh-GAM-trong-r.html#thể-hiện-ảnh-hưởng-của-từng-biến-x-đầu-vào-lên-biến-y-đầu-ra",
    "href": "xay-dung-mo-hinh-GAM-trong-r.html#thể-hiện-ảnh-hưởng-của-từng-biến-x-đầu-vào-lên-biến-y-đầu-ra",
    "title": "20  Xây dựng mô hình GAM trong R",
    "section": "20.5 Thể hiện ảnh hưởng của từng biến x đầu vào lên biến y đầu ra",
    "text": "20.5 Thể hiện ảnh hưởng của từng biến x đầu vào lên biến y đầu ra\n\nlibrary(ggeffects)\nlibrary(gratia)\nplot(ggeffects::ggpredict(mod_gam2), facets = TRUE)\n\n\n\n\n\n\n\ngratia::draw(mod_gam2)",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'><b>Xây dựng mô hình GAM trong R</b></span>"
    ]
  },
  {
    "objectID": "xay-dung-mo-hinh-GAM-trong-r.html#cách-tính-relative-risk-trong-model-gam",
    "href": "xay-dung-mo-hinh-GAM-trong-r.html#cách-tính-relative-risk-trong-model-gam",
    "title": "20  Xây dựng mô hình GAM trong R",
    "section": "20.6 Cách tính relative risk trong model GAM",
    "text": "20.6 Cách tính relative risk trong model GAM\nCode này tham khảo theo package gamRR. Khi phân tích source code ta thấy relative risk được tính như sau:\n1/ Từ model GAM đã fitting ở trên mod_gam2\n2/ Ta chọn 1 vector tham chiếu, ở đây ví dụ là ref = c(Income = pisa$Income[1], Edu = pisa$Edu[1], Health = pisa$Health[1]) nghĩa là ngay dòng đầu tiên của dataset. Vai trò của vector tham chiếu này (1 điểm data point) là giúp làm mẫu số cho công thức tính relative risk.\n3/ Ta chọn 1 biến x để kiểm tra relative risk, như trong trường hợp này là biến Income.\n4/ Khi đó ta tạo dataframe với cột Income sẽ thay đổi theo dataset ban đầu nhưng hai cột Edu và Health sẽ không đổi (chính là điểm datapoint tham chiếu ở bước 2)\n5/ Thực hiện predict để tìm giá trị y predict cho điểm tham chiếu (ở bước 2).\n6/ Thực hiện predict để tìm các giá trị y predict cho dataframe (ở bước 4)\n7/ Relative risk là tỷ số giữa các giá trị y predict cho dataframe (ở bước 4) chia cho giá trị y predict (ở bước 2), trong trường hợp này là relative risk của biến Income.\nToàn bộ quy trình này được thể hiện qua đồ thị như bên dưới. Lưu ý là các thông tin sau chỉ là nhận định của cá nhân mình, để hiểu rõ thuật toán bạn sẽ liên hệ với tác giả package theo thông tin sau.\nhttps://cran.r-project.org/web/packages/gamRR/index.html\n\ngamRR::gamRR &lt;- function (fit, ref, est, data, n.points = 10, plot = TRUE, ylim = NULL) \n{\n  ref = data.frame(t(ref))\n  form = as.character(fit$formula)\n  x.list = strsplit(form[3], \"\\\\+\")[[1]]\n  x.list = gsub(\" \", \"\", x.list)\n  x.list = sapply(strsplit(x.list, \"\\\\,\"), \"[\", 1)\n  x.list = gsub(\"s\\\\(\", \"\", x.list)\n  x.list = gsub(\"as.factor\\\\(\", \"\", x.list)\n  x.list = gsub(\"factor\\\\(\", \"\", x.list)\n  x.list = gsub(\"offset\\\\(\", \"\", x.list)\n  x.list = gsub(\"log\\\\(\", \"\", x.list)\n  x.list = gsub(\"\\\\)\", \"\", x.list)\n  if (length(names(ref)) != length(x.list)) {\n    stop(\"The number of variables in the 'ref' argument is not equal to those in the model!\")\n  }\n  if (any(!(names(ref) %in% x.list))) {\n    stop(\"Some variables in the 'ref' argument are not in the model!\")\n  }\n  for (i in 1:length(x.list)) {\n    data = data[!is.na(data[, x.list[i]]), ]\n  }\n  rrref = predict(fit, type = \"response\", newdata = ref)\n  ndata = matrix(rep(0, nrow(data) * length(names(ref))), ncol = length(names(ref)))\n  ndata = data.frame(ndata)\n  names(ndata) = names(ref)\n  # 1 biến chạy, giữ nguyên các biến còn lại\n  ndata[, match(est, names(ndata))] = data[, match(est, names(data))]\n  ndata[, -match(est, names(ref))] = ref[, -match(est, names(ref))]\n  rr = predict(fit, type = \"response\", newdata = ndata)\n  # relative risk là kết quả y đầu ra (tiên lượng với 1 biến x chạy, và các biến kia giữ nguyên) chia cho điểm tham chiếu\n  rr = as.numeric(rr)/as.numeric(rrref)\n  ref_no_est = names(ref)[-match(est, names(ref))]\n  i = 1\n  ndata = matrix(rep(0, nrow(data) * length(names(ref))), ncol = length(names(ref)))\n  ndata = data.frame(ndata)\n  names(ndata) = names(ref)\n  ndata[, match(est, names(ndata))] = data[, match(est, names(data))]\n  for (j in 1:length(ref_no_est)) {\n    ndata[, ref_no_est[j]] = data[i, ref_no_est[j]]\n  }\n  rrn = predict(fit, type = \"response\", newdata = ndata)/as.numeric(rrref)\n  for (i in 2:nrow(data)) {\n    ndata = matrix(rep(0, nrow(data) * length(names(ref))), \n                   ncol = length(names(ref)))\n    ndata = data.frame(ndata)\n    names(ndata) = names(ref)\n    ndata[, match(est, names(ndata))] = data[, match(est, \n                                                     names(data))]\n    for (j in 1:length(ref_no_est)) {\n      ndata[, ref_no_est[j]] = data[i, ref_no_est[j]]\n    }\n    rrn = cbind(rrn, predict(fit, type = \"response\", newdata = ndata)/as.numeric(rrref))\n  }\n  se = apply(rrn, 1, FUN = \"sd\")/sqrt(nrow(data) - 1)\n  u = rr + 1.96 * se\n  l = rr - 1.96 * se\n  xy = data.frame(x = data[, est], rr = rr, u = u, l = l)\n  xy = xy[order(xy$x), ]\n  rangE = range(data[, est])\n  est.seq = seq(from = rangE[1], to = rangE[2], length.out = n.points)\n  seq.ind = which(abs(est.seq - as.numeric(ref[est])) == min(abs(est.seq - \n                                                                   as.numeric(ref[est]))))\n  est.seq[seq.ind] = as.numeric(ref[est])\n  nxy = matrix(rep(0, n.points * 4), ncol = 4)\n  nxy = data.frame(nxy)\n  names(nxy) = c(\"x\", \"rr\", \"u\", \"l\")\n  for (i in 1:n.points) {\n    ind = which(abs(xy$x - est.seq[i]) == min(abs(xy$x - \n                                                    est.seq[i])))\n    nxy[i, ] = xy[ind, ]\n  }\n  nxy[seq.ind, 2:4] = 1\n  if (plot) {\n    if (is.null(ylim)) {\n      ylim = c(min(xy$l), max(xy$u))\n    }\n    plot(spline(nxy$x, nxy$rr, xmax = as.numeric(ref[, est])), \n         type = \"l\", xlim = c(min(nxy$x), max(nxy$x)), ylim = ylim, \n         xlab = est, ylab = \"RR\")\n    lines(spline(nxy$x, nxy$l, xmax = as.numeric(ref[, est])), \n          lty = 2)\n    lines(spline(nxy$x, nxy$u, xmax = as.numeric(ref[, est])), \n          lty = 2)\n    lines(spline(nxy$x, nxy$rr, xmin = as.numeric(ref[, est])), \n          lty = 1)\n    lines(spline(nxy$x, nxy$l, xmin = as.numeric(ref[, est])), \n          lty = 2)\n    lines(spline(nxy$x, nxy$u, xmin = as.numeric(ref[, est])), \n          lty = 2)\n  }\n  return(nxy)\n}\n\n\ngamRR::gamRR(fit = mod_gam2,\n             ref = c(Income = pisa$Income[1],\n                     Edu = pisa$Edu[1],\n                     Health = pisa$Health[1]),\n             est = \"Income\",\n             data = pisa,\n             n.points = 10,\n             plot = TRUE,\n             ylim = NULL)\n\n\n\n\n\n\n\n\n       x        rr         u         l\n1  0.407 0.6838944 0.6944088 0.6733801\n2  0.484 0.8713265 0.8818409 0.8608122\n3  0.552 0.9970502 1.0075646 0.9865359\n4  0.599 1.0000000 1.0000000 1.0000000\n5  0.635 0.9529522 0.9634665 0.9424379\n6  0.691 1.0115245 1.0220389 1.0010102\n7  0.739 1.1412184 1.1517328 1.1307041\n8  0.805 1.1676452 1.1781595 1.1571308\n9  0.857 1.1974125 1.2079269 1.1868982\n10 0.914 0.9669727 0.9774871 0.9564584\n\ngamRR::gamRR(fit = mod_gam2,\n             ref = c(Income = pisa$Income[1],\n                     Edu = pisa$Edu[1],\n                     Health = pisa$Health[1]),\n             est = \"Edu\",\n             data = pisa,\n             n.points = 10,\n             plot = TRUE,\n             ylim = NULL)\n\n\n\n\n\n\n\n\n       x        rr         u         l\n1  0.535 0.9878204 1.0124750 0.9631658\n2  0.569 0.9450332 0.9696878 0.9203786\n3  0.646 0.8924675 0.9171221 0.8678129\n4  0.688 0.9458709 0.9705255 0.9212163\n5  0.716 1.0000000 1.0000000 1.0000000\n6  0.792 1.0169171 1.0415717 0.9922625\n7  0.836 1.0009779 1.0256325 0.9763233\n8  0.893 1.0115830 1.0362376 0.9869284\n9  0.945 1.0165534 1.0412080 0.9918988\n10 0.993 1.0657664 1.0904210 1.0411118\n\ngamRR::gamRR(fit = mod_gam2,\n             ref = c(Income = pisa$Income[1],\n                     Edu = pisa$Edu[1],\n                     Health = pisa$Health[1]),\n             est = \"Health\",\n             data = pisa,\n             n.points = 10,\n             plot = TRUE,\n             ylim = NULL)\n\n\n\n\n\n\n\n\n       x        rr         u         l\n1  0.717 1.0740251 1.1081999 1.0398504\n2  0.748 1.0604466 1.0946213 1.0262718\n3  0.772 1.0499341 1.0841089 1.0157594\n4  0.813 1.0319754 1.0661501 0.9978006\n5  0.838 1.0210249 1.0551996 0.9868501\n6  0.868 1.0078843 1.0420591 0.9737096\n7  0.886 1.0000000 1.0000000 1.0000000\n8  0.923 0.9837933 1.0179681 0.9496186\n9  0.956 0.9693387 1.0035135 0.9351640\n10 0.986 0.9561981 0.9903729 0.9220234",
    "crumbs": [
      "Cơ sở lý thuyết",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'><b>Xây dựng mô hình GAM trong R</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-convert-tu-csv-qua-tsv-trong-r.html",
    "href": "huong-dan-convert-tu-csv-qua-tsv-trong-r.html",
    "title": "21  Hướng dẫn convert từ file csv qua tsv trong R",
    "section": "",
    "text": "Ví dụ bạn có 1 file file_example_1.csv có cấu trúc như sau:\n\nGiờ bạn muốn convert thành dạng này, tức là thay thế dấu phân cách (delimiter) từ dấu phẩy , mặc định phân cách giữa các cột trong file csv (xem ở Notepad) thành khoảng trắng (tab) để giúp nhìn các cột rõ hơn như sau.\n\n## import file csv\n\nfile_example_1 &lt;- read.csv(\"file_example_1.csv\", sep = \",\")\n\nlibrary(crimeutils) # package giúp add trailing zeros\n\n## convert từng cột trong matrix để đủ zeros sau dấu thập phân\n\napply(X = file_example_1, MARGIN = 2, FUN = pad_decimals) -&gt; yes_1\n\n## xử lý cột đầu tiên để digits = 0\n\ncrimeutils::pad_decimals(as.numeric(yes_1[, 1]), digits = 0) -&gt; yes_1[, 1]\n\n## export ra file tsv với 2 tab\n\nwrite.table(x = yes_1, file = \"file_example_1.tsv\", row.names = FALSE, sep = \"\\t\\t\", quote = FALSE)\n\n\nLúc này bạn có thể upload file tsv hay txt lên website để thuận tiện thể hiện full dataset. Link",
    "crumbs": [
      "Kỹ thuật xử lý dữ liệu",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'><b>Hướng dẫn convert từ file <code>csv</code> qua <code>tsv</code> trong R</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-cach-lam-tron-so-trong-r.html",
    "href": "huong-dan-cach-lam-tron-so-trong-r.html",
    "title": "22  Hướng dẫn cách làm tròn số trong R",
    "section": "",
    "text": "Bài viết này làm rõ hơn cách làm tròn số trong R ở video CÁCH LÀM TRÒN SỐ TRONG R | Lệnh round(), signif() trong chuyên đề 1 Coding in R.\nGiả sử bạn có vector x như sau. Khi in ra console thì mặc định sẽ có giá trị rất dài như bên dưới vì mặc định digits = 7 và scipen = 0 trong R đã thiết lập format khi in ra con số (numeric) có số lượng số sau dấu thập phân như vậy.\n\nx &lt;- c(0.8992877, 0.023, -1.002, 1.236, 10.236000, 20.243, 10035.23)\nx\n\n[1]     0.8992877     0.0230000    -1.0020000     1.2360000    10.2360000    20.2430000 10035.2300000\n\n\nBây giờ bạn muốn thu được vector numeric x chỉ gồm các con số có 2 số sau dấu thập phân thì ta sẽ áp dụng 1 trong các cách sau.\nCách 1: Sử dụng function round() trong base R, kết quả thu được là numeric vector\n\nround(x, digits = 2) -&gt; x_1\nx_1\n\n[1]     0.90     0.02    -1.00     1.24    10.24    20.24 10035.23\n\n\nCách 2: Sử dụng function sprintf() trong base R, kết quả là character vector do đó cần convert qua vector numeric nếu cần dùng để tính toán tiếp theo.\n\nsprintf(\"%.2f\", x) -&gt; x_2 \nx_2\n\n[1] \"0.90\"     \"0.02\"     \"-1.00\"    \"1.24\"     \"10.24\"    \"20.24\"    \"10035.23\"\n\nas.numeric(x_2) ## convert qua dạng numeric vector\n\n[1]     0.90     0.02    -1.00     1.24    10.24    20.24 10035.23\n\n\nCách 3: Sử dụng function myround() trong package broman, kết quả là character vector\n\nlibrary(broman)\nbroman::myround(x, digits = 2) -&gt; x_3\nx_3\n\n[1] \"0.90\"     \"0.02\"     \"-1.00\"    \"1.24\"     \"10.24\"    \"20.24\"    \"10035.23\"\n\nas.numeric(x_3) ## convert qua dạng numeric vector\n\n[1]     0.90     0.02    -1.00     1.24    10.24    20.24 10035.23\n\n\nCả 3 cách này đều thu được kết quả y chang nhau.\n\nidentical(x_1, as.numeric(x_2))\n\n[1] TRUE\n\nidentical(x_1, as.numeric(x_3))\n\n[1] TRUE\n\nidentical(as.numeric(x_2), as.numeric(x_3))\n\n[1] TRUE",
    "crumbs": [
      "Kỹ thuật xử lý dữ liệu",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'><b>Hướng dẫn cách làm tròn số trong R</b></span>"
    ]
  },
  {
    "objectID": "huong-dan-show-all-data-tren-console.html",
    "href": "huong-dan-show-all-data-tren-console.html",
    "title": "23  Hướng dẫn show all data trên console",
    "section": "",
    "text": "Đối với data frame dài hơn 1000 dòng thì khi in trên console bạn sẽ bị truncated, vì mặc định RStudio chỉ thể hiện max là 1000 dòng. Do vậy để thể hiện toàn bộ dữ liệu trên console thì bạn sẽ thực hiện như sau.\nBước 1:\n\n\n\n\n\nBước 2:\n\noptions(max.print = 1000000) # số lượng ký tự in trên console (thực hiện trong mỗi session)\n\nlibrary(rstudioapi)\nrstudioapi::writeRStudioPreference(\"console_max_lines\", as.integer(5000)) # show 5000 dòng\n# khởi động lại RStudio thì sẽ show all data được (dòng lệnh này chỉ cần thực hiện 1 lần duy nhất)\n\n\n### các lệnh in data frame dạng bảng\n\nprint(mtcars)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\nkableExtra::kable(mtcars, \"pipe\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\nMerc 450SE\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\nMerc 450SL\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\nMerc 450SLC\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\nCadillac Fleetwood\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\nLincoln Continental\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\nChrysler Imperial\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\nFiat 128\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\nHonda Civic\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\nToyota Corolla\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\nToyota Corona\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n# kableExtra::kable(mtcars, \"simple\")\n# knitr::kable(mtcars)\n# kableExtra::kbl(mtcars) # file html\n\n\n23.0.1 Tham khảo\n\nCác thông số tùy chỉnh cho RStudio https://docs.posit.co/ide/server-pro/session_user_settings/session_user_settings.html",
    "crumbs": [
      "Kỹ thuật xử lý dữ liệu",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'><b>Hướng dẫn show all data trên console</b></span>"
    ]
  },
  {
    "objectID": "ky-thuat-reshape-du-lieu.html",
    "href": "ky-thuat-reshape-du-lieu.html",
    "title": "24  Kỹ thuật reshape dữ liệu",
    "section": "",
    "text": "24.1 Sử dụng lệnh reshape của base R\nLệnh stats::reshape này là căn bản của base R giúp chuyển dữ liệu từ long sang wide và ngược lại. Hạn chế là nếu dữ liệu unbalanced thì quá trình chuyển đổi sẽ phức tạp.\nLưu ý là khái niệm semi-long và semi-wide data là nói về các dạng dữ liệu ở trạng thái long và wide chưa triệt để. Còn long và wide nói về dạng dữ liệu ở trạng thái long và wide triệt để. Như vậy cùng 1 bộ dataset khi reshape sẽ có nhiều hơn 1 cách sắp xếp dữ liệu tùy vào nhu cầu phân tích của người dùng (chủ yếu để phù hợp với đặc điểm dữ liệu mà các function trong R yêu cầu khi vẽ đồ thị hay phân tích thống kê).",
    "crumbs": [
      "Kỹ thuật xử lý dữ liệu",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'><b>Kỹ thuật reshape dữ liệu</b></span>"
    ]
  },
  {
    "objectID": "ky-thuat-reshape-du-lieu.html#sử-dụng-lệnh-reshape-của-base-r",
    "href": "ky-thuat-reshape-du-lieu.html#sử-dụng-lệnh-reshape-của-base-r",
    "title": "24  Kỹ thuật reshape dữ liệu",
    "section": "",
    "text": "24.1.1 Áp dụng lệnh reshape của base R cho imbalanced dataset\nTa có dataset ở dạng long, ký hiệu là survey với thông tin như sau. Trong đây thì cột id là mã số người tham gia khảo sát, gender là giới tính, age là tuổi, income là thu nhập và year là năm.\n\nid &lt;- c(\"111\", \"111\", \"112\", \"112\", \"112\", \n        \"114\", \"315\", \"315\", \"315\", \"539\")\n\ngender &lt;- c(\"male\", \"male\", \"female\", \"female\", \"female\", \n            \"female\", \"male\", \"male\", \"male\", \"female\")\n\nage &lt;- c(56, 58, 29, 31, 33, \n         NA, 86, 88, 90, NA)\n\nincome &lt;- c(1000, 2500, NA, 400, 540, \n            200, 440, NA, NA, 300)\n\nyear &lt;- c(2012, 2014, 2012, 2014, 2016,\n          2016, 2012, 2014, 2016, 2016)\n\nsurvey &lt;- data.frame(id, gender, age, income, year)\n\nsurvey\n\n    id gender age income year\n1  111   male  56   1000 2012\n2  111   male  58   2500 2014\n3  112 female  29     NA 2012\n4  112 female  31    400 2014\n5  112 female  33    540 2016\n6  114 female  NA    200 2016\n7  315   male  86    440 2012\n8  315   male  88     NA 2014\n9  315   male  90     NA 2016\n10 539 female  NA    300 2016\n\n\nVì id và gender không thay đổi qua các năm ở cùng 1 cá nhân nên khi reshape từ long sang wide ta sẽ giữ lại 2 cột này.\n\nsurvey_wide_1 &lt;- reshape(survey, \n                         direction = \"wide\", # định vị kiểu spread dữ liệu dạng wide\n                         idvar = c(\"id\", \"gender\"), # giữ lại 2 cột này\n                         timevar = \"year\", # spread ra theo cột `year`\n                         v.names = c(\"age\", \"income\") # chọn 2 cột để spread dữ liệu\n                         ) \n\nsurvey_wide_1 # dữ liệu sau khi reshape\n\n    id gender age.2012 income.2012 age.2014 income.2014 age.2016 income.2016\n1  111   male       56        1000       58        2500       NA          NA\n3  112 female       29          NA       31         400       33         540\n6  114 female       NA          NA       NA          NA       NA         200\n7  315   male       86         440       88          NA       90          NA\n10 539 female       NA          NA       NA          NA       NA         300\n\nrow.names(survey_wide_1) &lt;- NULL\n\nattributes(survey_wide_1)$reshapeWide &lt;- NULL\n\n# dataset đã làm sạch attributes \n# có thể sắp xếp thứ tự cột cho chuẩn về 1 trật tự thuận tiện cho việc subset sau này\nsurvey_wide_1 \n\n   id gender age.2012 income.2012 age.2014 income.2014 age.2016 income.2016\n1 111   male       56        1000       58        2500       NA          NA\n2 112 female       29          NA       31         400       33         540\n3 114 female       NA          NA       NA          NA       NA         200\n4 315   male       86         440       88          NA       90          NA\n5 539 female       NA          NA       NA          NA       NA         300\n\n\nNhư vậy ta có dữ liệu ở dạng wide, giờ nếu chuyển về dạng long thì R sẽ chuyển về dạng long triệt để, rồi sau đó ta mới tìm cách chuyển về dạng semi-long như là dataset survey ban đầu.\n\nsurvey_long_1 &lt;- reshape(survey_wide_1, \n                         direction = \"long\", # định vị kiểu spread dữ liệu dạng long\n                         varying = list(3:8), # xác định các cột được rút lại khi reshape về dạng long\n                         v.names = \"value\", # tên cột mới chứa giá trị tương ứng\n                         timevar = \"variable\", # tên cột mới chứa tên của các cột được rút lại theo varying\n                         times = names(survey_wide_1)[3:8], # R căn cứ vào đây để đưa tên cột `variable`\n                         idvar = c(\"id\") # nếu trong dataset ban đầu có cột id thì chỉ định luôn, \n                         #nếu không thì ta cần đặt tên cột `sample_id` \n                         #để R chỉ ra vị trí các cột sau khi gather\n                      )\n\nrow.names(survey_long_1) &lt;- NULL\n\nattributes(survey_long_1)$reshapeLong &lt;- NULL\n\nsurvey_long_1\n\n    id gender    variable value\n1  111   male    age.2012    56\n2  112 female    age.2012    29\n3  114 female    age.2012    NA\n4  315   male    age.2012    86\n5  539 female    age.2012    NA\n6  111   male income.2012  1000\n7  112 female income.2012    NA\n8  114 female income.2012    NA\n9  315   male income.2012   440\n10 539 female income.2012    NA\n11 111   male    age.2014    58\n12 112 female    age.2014    31\n13 114 female    age.2014    NA\n14 315   male    age.2014    88\n15 539 female    age.2014    NA\n16 111   male income.2014  2500\n17 112 female income.2014   400\n18 114 female income.2014    NA\n19 315   male income.2014    NA\n20 539 female income.2014    NA\n21 111   male    age.2016    NA\n22 112 female    age.2016    33\n23 114 female    age.2016    NA\n24 315   male    age.2016    90\n25 539 female    age.2016    NA\n26 111   male income.2016    NA\n27 112 female income.2016   540\n28 114 female income.2016   200\n29 315   male income.2016    NA\n30 539 female income.2016   300\n\n\nTiếp tục chuyển survey_long_1 về dạng cấu trúc y chang dataset survey ban đầu bằng cách reshape qua dạng wide cho các biến age và income.\nBước 1: Tách ra thành các cột riêng\n\nstrsplit(survey_long_1$variable, split = \"\\\\.\") -&gt; ok\n\nok\n\n[[1]]\n[1] \"age\"  \"2012\"\n\n[[2]]\n[1] \"age\"  \"2012\"\n\n[[3]]\n[1] \"age\"  \"2012\"\n\n[[4]]\n[1] \"age\"  \"2012\"\n\n[[5]]\n[1] \"age\"  \"2012\"\n\n[[6]]\n[1] \"income\" \"2012\"  \n\n[[7]]\n[1] \"income\" \"2012\"  \n\n[[8]]\n[1] \"income\" \"2012\"  \n\n[[9]]\n[1] \"income\" \"2012\"  \n\n[[10]]\n[1] \"income\" \"2012\"  \n\n[[11]]\n[1] \"age\"  \"2014\"\n\n[[12]]\n[1] \"age\"  \"2014\"\n\n[[13]]\n[1] \"age\"  \"2014\"\n\n[[14]]\n[1] \"age\"  \"2014\"\n\n[[15]]\n[1] \"age\"  \"2014\"\n\n[[16]]\n[1] \"income\" \"2014\"  \n\n[[17]]\n[1] \"income\" \"2014\"  \n\n[[18]]\n[1] \"income\" \"2014\"  \n\n[[19]]\n[1] \"income\" \"2014\"  \n\n[[20]]\n[1] \"income\" \"2014\"  \n\n[[21]]\n[1] \"age\"  \"2016\"\n\n[[22]]\n[1] \"age\"  \"2016\"\n\n[[23]]\n[1] \"age\"  \"2016\"\n\n[[24]]\n[1] \"age\"  \"2016\"\n\n[[25]]\n[1] \"age\"  \"2016\"\n\n[[26]]\n[1] \"income\" \"2016\"  \n\n[[27]]\n[1] \"income\" \"2016\"  \n\n[[28]]\n[1] \"income\" \"2016\"  \n\n[[29]]\n[1] \"income\" \"2016\"  \n\n[[30]]\n[1] \"income\" \"2016\"  \n\ndo.call(rbind, ok) -&gt; ok_1\n\nok_1\n\n      [,1]     [,2]  \n [1,] \"age\"    \"2012\"\n [2,] \"age\"    \"2012\"\n [3,] \"age\"    \"2012\"\n [4,] \"age\"    \"2012\"\n [5,] \"age\"    \"2012\"\n [6,] \"income\" \"2012\"\n [7,] \"income\" \"2012\"\n [8,] \"income\" \"2012\"\n [9,] \"income\" \"2012\"\n[10,] \"income\" \"2012\"\n[11,] \"age\"    \"2014\"\n[12,] \"age\"    \"2014\"\n[13,] \"age\"    \"2014\"\n[14,] \"age\"    \"2014\"\n[15,] \"age\"    \"2014\"\n[16,] \"income\" \"2014\"\n[17,] \"income\" \"2014\"\n[18,] \"income\" \"2014\"\n[19,] \"income\" \"2014\"\n[20,] \"income\" \"2014\"\n[21,] \"age\"    \"2016\"\n[22,] \"age\"    \"2016\"\n[23,] \"age\"    \"2016\"\n[24,] \"age\"    \"2016\"\n[25,] \"age\"    \"2016\"\n[26,] \"income\" \"2016\"\n[27,] \"income\" \"2016\"\n[28,] \"income\" \"2016\"\n[29,] \"income\" \"2016\"\n[30,] \"income\" \"2016\"\n\nsurvey_long_1$chi_tieu_theo_doi &lt;- ok_1[, 1]\n\nsurvey_long_1$year &lt;- ok_1[, 2]\n\nsurvey_long_1\n\n    id gender    variable value chi_tieu_theo_doi year\n1  111   male    age.2012    56               age 2012\n2  112 female    age.2012    29               age 2012\n3  114 female    age.2012    NA               age 2012\n4  315   male    age.2012    86               age 2012\n5  539 female    age.2012    NA               age 2012\n6  111   male income.2012  1000            income 2012\n7  112 female income.2012    NA            income 2012\n8  114 female income.2012    NA            income 2012\n9  315   male income.2012   440            income 2012\n10 539 female income.2012    NA            income 2012\n11 111   male    age.2014    58               age 2014\n12 112 female    age.2014    31               age 2014\n13 114 female    age.2014    NA               age 2014\n14 315   male    age.2014    88               age 2014\n15 539 female    age.2014    NA               age 2014\n16 111   male income.2014  2500            income 2014\n17 112 female income.2014   400            income 2014\n18 114 female income.2014    NA            income 2014\n19 315   male income.2014    NA            income 2014\n20 539 female income.2014    NA            income 2014\n21 111   male    age.2016    NA               age 2016\n22 112 female    age.2016    33               age 2016\n23 114 female    age.2016    NA               age 2016\n24 315   male    age.2016    90               age 2016\n25 539 female    age.2016    NA               age 2016\n26 111   male income.2016    NA            income 2016\n27 112 female income.2016   540            income 2016\n28 114 female income.2016   200            income 2016\n29 315   male income.2016    NA            income 2016\n30 539 female income.2016   300            income 2016\n\n\nBước 2: Sắp xếp dataset gọn gàng trước khi reshape qua dạng wide. Ta thấy R đã chuẩn lại về cho ballance bộ dataset, tức là các giá trị id đều đầy đủ số liệu theo năm.\n\nlibrary(dplyr)\n\nsurvey_long_2 &lt;- survey_long_1[, -3]\n\nsurvey_long_2 |&gt; dplyr::arrange(id, year) -&gt; survey_long_2\n\nsurvey_long_2[, c(1, 2, 4, 3, 5)] -&gt; survey_long_2\n\nsurvey_long_2\n\n    id gender chi_tieu_theo_doi value year\n1  111   male               age    56 2012\n2  111   male            income  1000 2012\n3  111   male               age    58 2014\n4  111   male            income  2500 2014\n5  111   male               age    NA 2016\n6  111   male            income    NA 2016\n7  112 female               age    29 2012\n8  112 female            income    NA 2012\n9  112 female               age    31 2014\n10 112 female            income   400 2014\n11 112 female               age    33 2016\n12 112 female            income   540 2016\n13 114 female               age    NA 2012\n14 114 female            income    NA 2012\n15 114 female               age    NA 2014\n16 114 female            income    NA 2014\n17 114 female               age    NA 2016\n18 114 female            income   200 2016\n19 315   male               age    86 2012\n20 315   male            income   440 2012\n21 315   male               age    88 2014\n22 315   male            income    NA 2014\n23 315   male               age    90 2016\n24 315   male            income    NA 2016\n25 539 female               age    NA 2012\n26 539 female            income    NA 2012\n27 539 female               age    NA 2014\n28 539 female            income    NA 2014\n29 539 female               age    NA 2016\n30 539 female            income   300 2016\n\n\nBước 3: Reshape trở về dạng wide để giống như dataset survey ban đầu.\n\nsurvey_wide_ok &lt;- reshape(survey_long_2, \n                         direction = \"wide\", # định vị kiểu spread dữ liệu dạng wide\n                         idvar = c(\"id\", \"gender\", \"year\"), # giữ lại 3 cột này\n                         timevar = \"chi_tieu_theo_doi\", # spread ra theo cột `chi_tieu_theo_doi`\n                         v.names = c(\"value\") # chọn cột này để spread dữ liệu\n                         ) \n\nrow.names(survey_wide_ok) &lt;- NULL\n\nattributes(survey_wide_ok)$reshapeWide &lt;- NULL\n\nsurvey_wide_ok\n\n    id gender year value.age value.income\n1  111   male 2012        56         1000\n2  111   male 2014        58         2500\n3  111   male 2016        NA           NA\n4  112 female 2012        29           NA\n5  112 female 2014        31          400\n6  112 female 2016        33          540\n7  114 female 2012        NA           NA\n8  114 female 2014        NA           NA\n9  114 female 2016        NA          200\n10 315   male 2012        86          440\n11 315   male 2014        88           NA\n12 315   male 2016        90           NA\n13 539 female 2012        NA           NA\n14 539 female 2014        NA           NA\n15 539 female 2016        NA          300\n\n\nBước 4: Sửa lại tên cột.\n\nsurvey_wide_ok_1 &lt;- survey_wide_ok[, c(1, 2, 4, 5, 3)]\n\nnames(survey_wide_ok_1)[3] &lt;- \"age\"\nnames(survey_wide_ok_1)[4] &lt;- \"income\"\n\nsurvey_wide_ok_1\n\n    id gender age income year\n1  111   male  56   1000 2012\n2  111   male  58   2500 2014\n3  111   male  NA     NA 2016\n4  112 female  29     NA 2012\n5  112 female  31    400 2014\n6  112 female  33    540 2016\n7  114 female  NA     NA 2012\n8  114 female  NA     NA 2014\n9  114 female  NA    200 2016\n10 315   male  86    440 2012\n11 315   male  88     NA 2014\n12 315   male  90     NA 2016\n13 539 female  NA     NA 2012\n14 539 female  NA     NA 2014\n15 539 female  NA    300 2016\n\n\nBước 5: Loại bỏ missing value và kiểm tra identical với survey ban đầu.\n\ncomplete.cases(survey_wide_ok_1$age) -&gt; check_1\ncomplete.cases(survey_wide_ok_1$income) -&gt; check_2\n\ncheck_1 | check_2 -&gt; check_3 # dùng OR để chọn cả 2 FALSE\n# để loại missing value ở 2 cột `age` và `income`\n\nsurvey_wide_ok_1[check_3, ] -&gt; survey_wide_ok_2\n\nrow.names(survey_wide_ok_2) &lt;- NULL\n\n# lưu ý là cột `year` cần chuyển về numeric\nsurvey_wide_ok_2$year &lt;- as.numeric(survey_wide_ok_2$year)\n\n# setdiff(survey, survey_wide_ok_2)\n\nsurvey_wide_ok_2\n\n    id gender age income year\n1  111   male  56   1000 2012\n2  111   male  58   2500 2014\n3  112 female  29     NA 2012\n4  112 female  31    400 2014\n5  112 female  33    540 2016\n6  114 female  NA    200 2016\n7  315   male  86    440 2012\n8  315   male  88     NA 2014\n9  315   male  90     NA 2016\n10 539 female  NA    300 2016\n\nsurvey\n\n    id gender age income year\n1  111   male  56   1000 2012\n2  111   male  58   2500 2014\n3  112 female  29     NA 2012\n4  112 female  31    400 2014\n5  112 female  33    540 2016\n6  114 female  NA    200 2016\n7  315   male  86    440 2012\n8  315   male  88     NA 2014\n9  315   male  90     NA 2016\n10 539 female  NA    300 2016\n\n# nếu ở bước này nhìn dataset đã giống nhau rồi mà \n# identical vẫn false thì ta sắp xếp toàn bộ \n#các cột trong dataset về cùng 1 cấu trúc sau đó mới so sánh\nidentical(survey, survey_wide_ok_2)\n\n[1] TRUE\n\n\nBước 6 (nếu kỹ hơn): Chuẩn lại toàn bộ thứ tự thành phần trong dataset\n\nsurvey |&gt; dplyr::arrange(!!! rlang::syms(names(survey))) -&gt; survey_chuan\n\nsurvey_chuan\n\n    id gender age income year\n1  111   male  56   1000 2012\n2  111   male  58   2500 2014\n3  112 female  29     NA 2012\n4  112 female  31    400 2014\n5  112 female  33    540 2016\n6  114 female  NA    200 2016\n7  315   male  86    440 2012\n8  315   male  88     NA 2014\n9  315   male  90     NA 2016\n10 539 female  NA    300 2016\n\nsurvey_wide_ok_2 |&gt; dplyr::arrange(!!! rlang::syms(names(survey_wide_ok_2))) -&gt; survey_wide_ok_2_chuan\n\nidentical(survey_chuan, survey_wide_ok_2_chuan)\n\n[1] TRUE\n\n\n\n\n24.1.2 Tham khảo\n\nhttps://www.magesblog.com/post/2012-02-09-reshape-function/\nhttps://search.r-project.org/CRAN/refmans/splitstackshape/html/Reshape.html",
    "crumbs": [
      "Kỹ thuật xử lý dữ liệu",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'><b>Kỹ thuật reshape dữ liệu</b></span>"
    ]
  },
  {
    "objectID": "ky-thuat-kiem-tra-missing-value.html",
    "href": "ky-thuat-kiem-tra-missing-value.html",
    "title": "25  Kỹ thuật kiểm tra missing value NA",
    "section": "",
    "text": "Ta có 1 dataset gồm 30 dòng và 6 cột, trong đó có 1 số cột bị missing value. Để kiểm tra nhanh, ta sẽ dùng lệnh summary() tuy nhiên lệnh này không kiểm tra được các cột là character.\n\ndim(df)\n\n[1] 30  6\n\ndf\n\n                                   name school student revenue expenditure type\n1            RIO GRANDE CITY GRULLA ISD     15    9007   14409       12858 &lt;NA&gt;\n2                             KEENE ISD      5    1016   16272       11291 &lt;NA&gt;\n3                             BRYAN ISD     25   16005   14613          NA &lt;NA&gt;\n4                          GOODRICH ISD      3     244   18543       13730 &lt;NA&gt;\n5                       HALE CENTER ISD      3     597   15541          NA &lt;NA&gt;\n6                            LAMESA ISD      1    1602   18810          NA &lt;NA&gt;\n7      EVOLUTION ACADEMY CHARTER SCHOOL      3     669   12607          NA    I\n8                            MALONE ISD      1     153   17031          NA &lt;NA&gt;\n9                           RAMIREZ CSD      1      26   22447       17483 &lt;NA&gt;\n10     ST MARY'S ACADEMY CHARTER SCHOOL      1     401   13897       13384    I\n11                      BLOOMINGTON ISD      5     825   13999       13182 &lt;NA&gt;\n12                           LOMETA ISD      2     317   22798          NA &lt;NA&gt;\n13 DR M L GARZA-GONZALEZ CHARTER SCHOOL      1     166   14006          NA    I\n14                 HARDIN-JEFFERSON ISD      5    2602   11022          NA &lt;NA&gt;\n15                ROSCOE COLLEGIATE ISD      4    3076   29616          NA &lt;NA&gt;\n16                       WESTPHALIA ISD      1     155   14312          NA &lt;NA&gt;\n17                         HEMPHILL ISD      3     901   16550          NA &lt;NA&gt;\n18                            MOODY ISD      4     687   15586          NA &lt;NA&gt;\n19                          PEWITT CISD      3     866   13718          NA &lt;NA&gt;\n20                  CORRIGAN-CAMDEN ISD      3     817   17796       15432 &lt;NA&gt;\n21                   PATTON SPRINGS ISD      1      86   29806       25965 &lt;NA&gt;\n22                        WINNSBORO ISD      4    1532   21267       11859 &lt;NA&gt;\n23                      PAINT CREEK ISD      1      95   29940       22333 &lt;NA&gt;\n24                    LIBERTY-EYLAU ISD      4    2131   19971       12415 &lt;NA&gt;\n25                     GOOSE CREEK CISD     31   23833   14213       12111 &lt;NA&gt;\n26             TEXAS PREPARATORY SCHOOL      2     120   16009       16096    I\n27                    TULOSO-MIDWAY ISD      6    3745   15313       10669 &lt;NA&gt;\n28                   NUECES CANYON CISD      2     254   16804       15142 &lt;NA&gt;\n29                         MISSION CISD     23   13838   15204       12062 &lt;NA&gt;\n30                           UNITED ISD     50   39243   12654       11226 &lt;NA&gt;\n\nsapply(df, class)\n\n       name      school     student     revenue expenditure        type \n\"character\"   \"numeric\"   \"numeric\"   \"numeric\"   \"numeric\" \"character\" \n\nsummary(df)\n\n     name               school         student           revenue       expenditure        type          \n Length:30          Min.   : 1.00   Min.   :   26.0   Min.   :11022   Min.   :10669   Length:30         \n Class :character   1st Qu.: 1.25   1st Qu.:  246.5   1st Qu.:14238   1st Qu.:12062   Class :character  \n Mode  :character   Median : 3.00   Median :  821.0   Median :15798   Median :13182   Mode  :character  \n                    Mean   : 7.10   Mean   : 4167.0   Mean   :17492   Mean   :14543                     \n                    3rd Qu.: 5.00   3rd Qu.: 2484.2   3rd Qu.:18743   3rd Qu.:15432                     \n                    Max.   :50.00   Max.   :39243.0   Max.   :29940   Max.   :25965                     \n                                                                      NA's   :13                        \n\n\nDo vậy để kiểm tra nhanh toàn bộ dataset df này có bao nhiêu giá trị missing value ở tất cả các cột (gồm character và numeric) thì ta dùng function md.pattern() trong package mice.\n\nThis function is useful for investigating any structure of missing observations in the data.\n\n\nlibrary(mice)\nmice::md.pattern(df, plot = TRUE, rotate.names = TRUE)\n\n\n\n\n\n\n\n\n   name school student revenue expenditure type   \n2     1      1       1       1           1    1  0\n15    1      1       1       1           1    0  1\n2     1      1       1       1           0    1  1\n11    1      1       1       1           0    0  2\n      0      0       0       0          13   26 39\n\n\nỞ đây ta phân tích kỹ các con số từ đồ thị này để đánh giá tình hình missing value trong bộ dữ liệu. Cụ thể:\n\nGiá trị nằm ngang dưới cùng (0, 0, 0, 0, 13, 26 và 39) lần lượt là số lượng missing value trong từng cột, còn số 39 nghĩa là trong toàn bộ dataset df (gồm 30 dòng và 6 cột, tạo thành tổng cộng 180 ô dữ liệu) có 39 ô bị giá trị trống. Được tính theo công thức: \\(0 + 0 + 0 + 0 + 13 + 26 = 39\\).\nGiá trị nằm bên trái (2, 15, 2, 11) tương ứng với các con số bên phải (0, 1, 1, 2) có ý nghĩa là:\n\n\n### số 2 là dataset chỉ còn 2 dòng (hàng) dữ liệu sau khi na.omit() toàn bộ các cột\n### nghĩa là lúc này dataset không (số 0) còn cột nào có giá trị missing value\n\ndf_clean_all_column &lt;- na.omit(df)\n\nrow.names(df_clean_all_column) &lt;- NULL\n\ndim(df_clean_all_column)\n\n[1] 2 6\n\ndf_clean_all_column\n\n                              name school student revenue expenditure type\n1 ST MARY'S ACADEMY CHARTER SCHOOL      1     401   13897       13384    I\n2         TEXAS PREPARATORY SCHOOL      2     120   16009       16096    I\n\n\n\n### số 15 là dataset có 15 dòng (hàng) dữ liệu đầy đủ tất cả thông tin (từ cột đầu tiên đến cột expenditure) \n### ngoại trừ cột type (màu đỏ), lúc này toàn bộ giá trị ở cột type là NA.\n\ndf_clean_1 &lt;- df[complete.cases(df$name, df$school, df$student, df$revenue, df$expenditure), ]\n\ndf_clean_1a &lt;- df_clean_1[is.na(df_clean_1$type), ] \n\nrow.names(df_clean_1a) &lt;- NULL\n\ndim(df_clean_1a) \n\n[1] 15  6\n\ndf_clean_1a\n\n                         name school student revenue expenditure type\n1  RIO GRANDE CITY GRULLA ISD     15    9007   14409       12858 &lt;NA&gt;\n2                   KEENE ISD      5    1016   16272       11291 &lt;NA&gt;\n3                GOODRICH ISD      3     244   18543       13730 &lt;NA&gt;\n4                 RAMIREZ CSD      1      26   22447       17483 &lt;NA&gt;\n5             BLOOMINGTON ISD      5     825   13999       13182 &lt;NA&gt;\n6         CORRIGAN-CAMDEN ISD      3     817   17796       15432 &lt;NA&gt;\n7          PATTON SPRINGS ISD      1      86   29806       25965 &lt;NA&gt;\n8               WINNSBORO ISD      4    1532   21267       11859 &lt;NA&gt;\n9             PAINT CREEK ISD      1      95   29940       22333 &lt;NA&gt;\n10          LIBERTY-EYLAU ISD      4    2131   19971       12415 &lt;NA&gt;\n11           GOOSE CREEK CISD     31   23833   14213       12111 &lt;NA&gt;\n12          TULOSO-MIDWAY ISD      6    3745   15313       10669 &lt;NA&gt;\n13         NUECES CANYON CISD      2     254   16804       15142 &lt;NA&gt;\n14               MISSION CISD     23   13838   15204       12062 &lt;NA&gt;\n15                 UNITED ISD     50   39243   12654       11226 &lt;NA&gt;\n\n\n\n### số 2 là dataset có 2 dòng (hàng) dữ liệu đầy đủ tất cả thông tin (từ cột đầu tiên đến cột type) \n### ngoại trừ cột expenditure (màu đỏ), lúc này toàn bộ giá trị ở cột expenditure là NA.\n\ndf_clean_2 &lt;- df[complete.cases(df$name, df$school, df$student, df$revenue, df$type), ]\n\ndf_clean_2a &lt;- df_clean_2[is.na(df_clean_2$expenditure), ] \n\nrow.names(df_clean_2a) &lt;- NULL\n\ndim(df_clean_2a) \n\n[1] 2 6\n\ndf_clean_2a\n\n                                  name school student revenue expenditure type\n1     EVOLUTION ACADEMY CHARTER SCHOOL      3     669   12607          NA    I\n2 DR M L GARZA-GONZALEZ CHARTER SCHOOL      1     166   14006          NA    I\n\n\n\n### số 11 là dataset có 11 dòng (hàng) dữ liệu đầy đủ tất cả thông tin (từ cột đầu tiên đến cột revenue) \n### ngoại trừ cột expenditure và type (màu đỏ), lúc này toàn bộ giá trị ở cột expenditure và type là NA.\n\ndf_clean_3 &lt;- df[complete.cases(df$name, df$school, df$student, df$revenue), ]\n\ndf_clean_3a &lt;- df_clean_3[is.na(df_clean_3$type), ] \n\ndf_clean_3b &lt;- df_clean_3a[is.na(df_clean_3a$expenditure), ] \n\nrow.names(df_clean_3b) &lt;- NULL\n\ndim(df_clean_3b) \n\n[1] 11  6\n\ndf_clean_3b\n\n                    name school student revenue expenditure type\n1              BRYAN ISD     25   16005   14613          NA &lt;NA&gt;\n2        HALE CENTER ISD      3     597   15541          NA &lt;NA&gt;\n3             LAMESA ISD      1    1602   18810          NA &lt;NA&gt;\n4             MALONE ISD      1     153   17031          NA &lt;NA&gt;\n5             LOMETA ISD      2     317   22798          NA &lt;NA&gt;\n6   HARDIN-JEFFERSON ISD      5    2602   11022          NA &lt;NA&gt;\n7  ROSCOE COLLEGIATE ISD      4    3076   29616          NA &lt;NA&gt;\n8         WESTPHALIA ISD      1     155   14312          NA &lt;NA&gt;\n9           HEMPHILL ISD      3     901   16550          NA &lt;NA&gt;\n10             MOODY ISD      4     687   15586          NA &lt;NA&gt;\n11           PEWITT CISD      3     866   13718          NA &lt;NA&gt;",
    "crumbs": [
      "Kỹ thuật xử lý dữ liệu",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'><b>Kỹ thuật kiểm tra missing value <code>NA</code></b></span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Tài liệu tham khảo",
    "section": "",
    "text": "Crawley, Michael J. 2015. Statistics - an Introduction in r (2nd\nEdition). 2nd ed. Wiley. https://studyr.netlify.app/ref/crawley_2015_statistics_an_introduction_in_r_2nd_edition.pdf#page=77.\n\n\nLam, Nguyen Van. n.d. “Khoảng Tin Cậy (Confidence Interval) Là\nGì?” https://youtu.be/TqOeMYtOc1w.\n\n\nStarmer, Josh. n.d. “Confidence Intervals, Clearly\nExplained!!!” https://youtu.be/TqOeMYtOc1w.",
    "crumbs": [
      "Tài liệu tham khảo"
    ]
  }
]