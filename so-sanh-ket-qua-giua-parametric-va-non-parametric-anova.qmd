# <b>So sánh kết quả giữa phân tích parametric và non-parametric ANOVA</b> 

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width = 8, fig.height = 4, warning = FALSE, message = FALSE)
```

### **Bước 1: Đặt vấn đề**

Khi bộ dataset của bạn không thỏa các điều kiện cho ANOVA như ở [link này](https://thongkesinhhoc.quarto.pub/phan-tich-anova-2-yeu-to-trong-r.html) thì bạn cần thực hiện phân tích non-parametric ANOVA.

Quy trình chọn test thống kê phù hợp với đặc điểm dataset. Tham khảo [`mcelreath_2020_statistical_rethinking`](https://applyr.netlify.app/ref/mcelreath_2020_statistical_rethinking.pdf)

![](aov.jpg)

<span style="color:blue">**Để làm rõ về quy trình phân tích theo hai hướng parametric (có các tham số như trung bình và phương sai của phân bố chuẩn) và non-parametric (không có các tham số cho phân bố chuẩn) ta sẽ xét cách làm trên cùng 1 bộ dataset.**</span>

**Dataset minh họa: Dữ liệu đo khối lượng cây ở các nghiệm thức khác nhau.**

**Giả thuyết:**


* ${H_0}$ : Giữa các nghiệm thức *không khác nhau* về khối lượng cây

* ${H_\alpha }$ : Giữa các nghiệm thức *khác nhau* về khối lượng cây

```{r}
library(tidyverse)
library(ggpubr)
library(rstatix)

### sửa lại dữ liệu từ dataset PlantGrowth để trở thành dữ liệu không có phân bố chuẩn.
PlantGrowth -> df
df[1, 1] <- 6.39
df[2, 1] <- 6.14
df[3, 1] <- 7.39
df[4, 1] <- 7.55
df[5, 1] <- 9.32
df[6, 1] <- 8.39
df[21, 1] <- 1.39
df[22, 1] <- 1.14
df[23, 1] <- 1.39
df[24, 1] <- 0.55
df[25, 1] <- 1.32
df[12, 1] <- 2.39
df[13, 1] <- 1.14
df[14, 1] <- 1.39
df[15, 1] <- 0.55
df[16, 1] <- 1.32
df
sapply(df, class)

df %>%
  group_by(group) %>%
  summarise(
    count = n(),
    mean = mean(weight, na.rm = TRUE),
    sd = sd(weight, na.rm = TRUE),
    median = median(weight, na.rm = TRUE),
    IQR = IQR(weight, na.rm = TRUE)
  )


df %>%
  group_by(group) %>%
  ggpubr::get_summary_stats(weight, type = "common")
```

### **Bước 2: Phân tích ANOVA 1 yếu tố cho trường hợp parametric**

Tham khảo: `https://www.statsmadeasy.com/tutorial-4-inferential-stats-test-of-difference/one-way-anova-parametric-non-parametric`

<mark>**Bước 2.1: Parametric One-Way ANOVA Assumptions**</mark>

* Independence: Your observations in each sample should be independent. $\Rightarrow$ <mark style="background-color: #FFFF00">OK</mark>

* Independent Variable: This variable must have 3 or more outcomes. (mỗi chỉ tiêu cần đo lặp lại ít nhất 3 lần) $\Rightarrow$ <mark style="background-color: #FFFF00">OK</mark>

* Random Sampling: Your data should be a random sample of the target population. $\Rightarrow$ <mark style="background-color: #FFFF00">OK</mark>

* Equal Variance (Homogeneity): Both groups should have approximately the same variance.

* Normality: Your Dependent variable should be approximately normally distributed.

<mark>**Bước 2.2: Kiểm tra giả thuyết**</mark>

```{r}
# Kiểm tra giả thuyết Normality
res.aov <- aov(weight ~ group, data = df)
aov_residuals <- residuals(object = res.aov)
shapiro.test(x = aov_residuals) 
```

Kết quả Shapiro-Wilk normality test cho thấy p-value là 0.00432 nhỏ hơn 0.05. Do đó bộ dataset này KHÔNG phân bố chuẩn. $\Rightarrow$ <mark style="background-color: #eb4034">VIOLATE</mark> 

```{r}
# Kiểm tra giả thuyết Normality qua Q-Q plot
mod <- lm(weight ~ group, data = df)

plot(mod, 2)
```

Nhìn đồ thị Q-Q lot ta thấy các giá trị không có phân bố chuẩn.

```{r}
# Kiểm tra giả thuyết Equal Variance (Homogeneity)
library(car)
leveneTest(weight ~ group, data = df)  
```

Kết quả Levene's test cho thấy p-value là 0.02356 nhỏ hơn 0.05. Do đó bộ dataset này có sự khác biệt về phương sai giữa các tổ hợp các mức khác nhau của 2 biến $\Rightarrow$ <mark style="background-color: #eb4034">VIOLATE</mark> 

`It’s also possible to use Bartlett’s test or Levene’s test to check the homogeneity of variances.`

<mark>**Bước 2.3: Mô tả đặc điểm dữ liệu qua đồ thị**</mark>

```{r}
library(lattice)
histogram( ~ weight | group, data =df,
           type = "density",
           panel = function(x, ...) {
             panel.histogram(x, ...)
             panel.mathdensity(dmath = dnorm, col = "black",
                               args = list(mean=mean(x),sd=sd(x)))
           } )

###

ggpubr::ggboxplot(df, x = "group", y = "weight")

ggpubr::ggline(df, x = "group", y = "weight", order = c("ctrl", "trt1", "trt2"), add = c("mean_sd", "dotplot"))

###

df$group <- reorder(df$group, df$weight, decreasing = FALSE) 
boxplot(weight ~ group, data = df, frame = TRUE,
        horizontal = TRUE, las = 1,
        axisnames = TRUE)
```

<mark>**Bước 2.4: Thực hiện ANOVA 1 yếu tố**</mark>

<span style="color:red">Cho dù đã vi phạm giả thuyết, nếu ta vẫn tiếp tục thực hiện ANOVA 1 yếu tố như bình thường thì kết quả sẽ như sau.</span>

```{r}
res.aov <- aov(weight ~ group, data = df)
anova(res.aov)
```

<span style="color:red">Kết quả cho thấy p-value = 0.0008834 nhỏ hơn 0.05 nên có ý nghĩa thống kê, dù rằng dataset này đã vi phạm giả thuyết về phân bố chuẩn!</span>

**Tham khảo thêm:**

**`ANOVA test with no assumption of equal variances`**

```{r}
oneway.test(weight ~ group, data = df)
```

**`Pairwise t-tests with no assumption of equal variances`**

```{r}
pairwise.t.test(df$weight, df$group,
                 p.adjust.method = "BH", pool.sd = FALSE)
```

<mark>**Bước 2.5: Phân hạng trong trường hợp parametric**</mark>

**Cách 1: Sử dụng function trong base R**

```{r}
TukeyHSD(res.aov) -> tukey_yes
plot(tukey_yes)
```

**Cách 2: Sử dụng function trong package `agricolae`**

```{r}
library(agricolae)
HSD.test(res.aov, "group", console = TRUE) -> tukey_ok
plot(tukey_ok)
```

<span style="color:red">Kết quả cho thấy vẫn thực hiện được phân hạng theo Tukey như bình thường, dù rằng dataset này đã vi phạm giả thuyết về phân bố chuẩn!</span>

**Cách 4: Sử dụng function trong package `multcomp`**

```{r}
library(multcomp)
summary(glht(res.aov, linfct = mcp(group = "Tukey")))
```

**Cách 5: Thể hiện phân hạng qua đồ thị boxplot**

`https://statsandr.com/blog/kruskal-wallis-test-nonparametric-version-anova/`

```{r, fig.width = 8, fig.height = 8}
library(dplyr)
library(ggstatsplot)

df$group <- factor(df$group, levels = c("ctrl", "trt1", "trt2"))

ggbetweenstats(
  data = df,
  x = group,
  y = weight,
  type = "parametric",
  plot.type = "box",
  pairwise.comparisons = TRUE,
  pairwise.display = "significant",
  centrality.plotting = TRUE,
  bf.message = TRUE
) 
```

### **Bước 3: Phân tích ANOVA 1 yếu tố cho trường hợp non-parametric**

Tham khảo: `https://www.statsmadeasy.com/tutorial-4-inferential-stats-test-of-difference/one-way-anova-parametric-non-parametric`

<mark>**Bước 3.1: Non-parametric One-Way ANOVA Assumptions**</mark>

* Independence: Your observations in each sample should be independent. $\Rightarrow$ <mark style="background-color: #FFFF00">OK</mark>

* Independent Variable: This variable must have 3 or more outcomes. (mỗi chỉ tiêu cần đo lặp lại ít nhất 3 lần) $\Rightarrow$ <mark style="background-color: #FFFF00">OK</mark>

* Random Sampling: Your data should be a random sample of the target population. $\Rightarrow$ <mark style="background-color: #FFFF00">OK</mark>

<mark>**Bước 3.2: Kiểm tra giả thuyết**</mark>

Thực tế cả 3 giả thuyết cho non-parametric thì bộ dataset này đã đáp ứng đủ nên không cần làm bước này.

<mark>**Bước 3.3: Thực hiện ANOVA 1 yếu tố non-parametric**</mark>

```{r}
# kruskal.test(weight ~ group, data = df)

res.kruskal <- df %>% rstatix::kruskal_test(weight ~ group)
res.kruskal
```
<span style="color:red">Kết quả cho thấy p-value = 0.00265 nhỏ hơn 0.05 nên có ý nghĩa thống kê. Đây cũng trùng hợp với kết quả từ ANOVA parametric ở trên!</span>

> Về lý thuyết, Kruskal-Wallis test có thể áp dụng cho two groups. Nhưng trong thực tế ta sẽ dùng the Mann-Whitney test for two groups and Kruskal-Wallis for three or more groups.

<mark>**Bước 3.4: Tính effect size**</mark>

`https://www.datanovia.com/en/lessons/kruskal-wallis-test-in-r/`

>The eta squared, based on the H-statistic, can be used as the measure of the Kruskal-Wallis test effect size. It is calculated as follow : eta2[H] = (H - k + 1)/(n - k); where H is the value obtained in the Kruskal-Wallis test; k is the number of groups; n is the total number of observations (M. T. Tomczak and Tomczak 2014).

>The eta-squared estimate assumes values from 0 to 1 and multiplied by 100 indicates the percentage of variance in the dependent variable explained by the independent variable.

>The interpretation values commonly in published literature are: 0.01- < 0.06 (small effect), 0.06 - < 0.14 (moderate effect) and >= 0.14 (large effect).

```{r}
df |> rstatix::kruskal_effsize(weight ~ group)
```

**Ý nghĩa của effect size**

`https://lbecker.uccs.edu/glm_effectsize`

<mark>**Bước 3.5: Phân hạng trong trường hợp non-parametric**</mark>

<span style="color:blue">Lưu ý: Phân hạng theo parametric (Tukey's test) thì ta căn cứ vào mean nên tính được diff mean (sự khác biệt giữa các trung bình) nên có thể phân ra theo từng hạng a, b, c, ... còn phân hạng theo non-parametric ta căn cứ vào median nên chỉ phân hạng theo từng cặp, theo sign test +/- cho thấy sự khác biệt giữa các cặp nghiệm thức với nhau.</span>

**Cách 1: Pairwise comparisons using Dunn's test** (most common post-hoc test)

```{r}
pwc <- df %>% rstatix::dunn_test(weight ~ group, p.adjust.method = "bonferroni") 
pwc
```

**Kết quả so sánh theo cặp theo Dunn's test cho thấy cặp nghiệm thức `trt1-trt2` không khác nhau về mặt ý nghĩa thống kê p-value là *ns*. Còn lại giữa 2 cặp nghiệm thức `ctrl-trt1` và `ctrl-trt2` khác biệt có ý nghĩa thống kê vì p-value nhỏ hơn 0.05.**

**Cách 2: Pairwise comparisons using Dunn's test trong package `FSA`**

```{r}
library(FSA)

FSA::dunnTest(weight ~ group,
  data = df,
  method = "holm"
)

# Note that there are other p-value adjustment methods. See ?dunnTest for more options
```

> It is the last column (the adjusted p-values, adjusted for multiple comparisons) that is of interest. These p-values should be compared to your desired significance level (usually 5%).

> Based on the output, we conclude that:

> `ctrl` and `trt1` differ significantly (p < 0.05)

> `ctrl` and `trt2` differ significantly (p < 0.05)

> `trt1` and `trt2` NOT differ significantly (p > 0.05)

> Therefore, based on the Dunn's test, we can now conclude that only `ctrl-trt1` and `ctrl-trt2` differ in terms of weight.

**Cách 3: Pairwise comparisons using Wilcoxon's test**

```{r}
pwc2 <- df %>% rstatix::wilcox_test(weight ~ group, p.adjust.method = "bonferroni")
pwc2
```

**Kết quả so sánh theo cặp theo Wilcoxon's test cho thấy cặp nghiệm thức `trt1-trt2` không khác nhau về mặt ý nghĩa thống kê p-value là *ns*. Còn lại giữa 2 cặp nghiệm thức `ctrl-trt1` và `ctrl-trt2` khác biệt có ý nghĩa thống kê vì p-value nhỏ hơn 0.05.**

**Cách 3: Thể hiện phân hạng qua đồ thị boxplot**

```{r}
## Dunn's test

pwc <- pwc %>% add_xy_position(x = "group")

ggboxplot(df, x = "group", y = "weight") +
  stat_pvalue_manual(pwc, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.kruskal, detailed = TRUE),
    caption = get_pwc_label(pwc)
    )

# Wilcoxon's test
pwc2 <- pwc2 %>% add_xy_position(x = "group")

ggboxplot(df, x = "group", y = "weight") +
  stat_pvalue_manual(pwc2, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.kruskal, detailed = TRUE),
    caption = get_pwc_label(pwc2)
    )
```

```{r, fig.width = 8, fig.height = 8}
ggbetweenstats(
  data = df,
  x = group,
  y = weight,
  type = "nonparametric",
  plot.type = "box",
  pairwise.comparisons = TRUE,
  pairwise.display = "significant",
  centrality.plotting = TRUE,
  bf.message = TRUE
)
```


### Tài liệu tham khảo

1. `https://bookdown.org/mike/data_analysis/nonparametric-anova.html`

2. `https://jbhender.github.io/Stats506/F18/GP/Group3.html`

3. `https://www.datanovia.com/en/lessons/kruskal-wallis-test-in-r/`

4. `https://influentialpoints.com/Training/Kruskal-Wallis_ANOVA_use_and_misuse.htm#:~:text=The%20Kruskal%2DWallis%20one%2Dway,test%20of%20dominance%20between%20distributions.`

5. `https://statsandr.com/blog/hypothesis-test-by-hand/`


